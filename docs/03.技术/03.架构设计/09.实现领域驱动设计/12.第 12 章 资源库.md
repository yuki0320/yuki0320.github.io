---
title: 第 12 章 资源库
date: 2021-01-07 16:25:13
permalink: /pages/51fb98/
categories:
  - 技术
  - 技术文档
  - 实现领域驱动设计
tags:
  - 
---
# 第 12 章 资源库

Your eyes are the same color as my storage unit.

> 此地无银三百两，隔壁王二不曾偷。

—Overheard at a redneck bar

A repository commonly refers to a storage location, usually considered a place of safety or preservation of the items stored in it. When you store something in a repository and later return to retrieve it, you expect that it will be in the same state as it was in when you put it there. At some point you may choose to remove the stored item from the repository.

> 资源库通常表示一个安全的存储区域，并且对其中所存放的物品起保护作用。当你从资源库中取出一个物品时，你希望该物品和其先前存放时的状态是一样的。有时，你有可能会从资源库中移除某些物品。

This basic set of principles applies to a DDD Repository. Placing an Aggregate (10) instance in its corresponding Repository, and later using that Repository to retrieve the same instance, yields the expected whole object. If you alter a preexisting Aggregate instance that you retrieve from the Repository, its changes will be persisted. If you remove the instance from the Repository, you will be unable to retrieve it from that point forward.

> 这个基本的原则对于 DDD 的资源库（Repository）来说也是适用的。通常我们将聚合（10）实例存放在资源库中，之后再通过该资源库来获取相同的实例。如果你修改了某个聚合，那么这种改变将被资源库所持久化。如果你从资源库中移除了某个实例，那么从那以后你将无法重新获取该实例。

For each type of object that needs global access, create an object that can provide the illusion of an in-memory collection of all objects of that type. Set up access through a well-known global interface. Provide methods to add and remove objects. . . . Provide methods that select objects based on some criteria and return fully instantiated objects or collections of objects whose attribute values meet the criteria. . . . Provide repositories only for aggregates. . . . [Evans, p. 151]

> 对于每种需要进行全局访问的对象，我们都应该创建另一个对象来作为这些对象的提供方，就像是在内存中访问这些对象的集合一样。为这些对象创建一个全局接口以供客户端访问。为这些对象创建添加和删除方法……此外，我们还应该提供能够按照某种指定条件来查询这些对象的方法……只为聚合创建资源库……[Evans，p.151]

These collection-like objects are all about persistence. Every persistent Aggregate type will have a Repository. Generally speaking, there is a one-to-one relationship between an Aggregate type and a Repository. However, sometimes when two or more Aggregate types share an object hierarchy, the types may share a single Repository. Both of these approaches are discussed in this chapter.

> 这些像集合一样的对象都是和持久化相关的。每一种聚合类型都将拥有一个资源库。通常来说，聚合类型和资源库之间存在着一对一的关系。然而有时，当两个或多个聚合位于同一个对象层级中时，它们可以共享同一个资源库。在本章中，我们将分别对这两种情况进行讨论。

Road Map to This Chapter 本章学习路线图

- Learn about the two different kinds of Repositories and why to use one or the other.
- See how to implement Repositories for Hibernate, TopLink, Coherence, and MongoDB.
- Understand why you might need additional behavior on a Repository’s interface. Consider how transactions play into the use of Repositories.
- Become familiar with the challenges of designing Repositories for type hierarchies.
- Look at some fundamental differences between Repositories and Data Access Objects [Crupi et al.].
- Consider some ways to test Repositories and how to test using Repositories.

---

> - 学习资源库的两种类型以及如何选用。
> - 学习如何通过 Hibernate、TopLink、Coherence 和 MongoDB 来实现资源库。
> - 学习为什么需要向资源库添加额外的行为。
> - 学习为类型层级设计资源库时所面临的挑战。
> - 学习资源库和数据访问对象（DAO）[Crupi et al.]之间的基本区别。
> - 学习测试资源库的不同方法，以及如何利用资源库来进行测试。

Strictly speaking, only Aggregates have Repositories. If you are not using Aggregates in a given Bounded Context (2), the Repository pattern may be less useful. If you are retrieving and using Entities (5) directly in an ad hoc fashion rather than crafting Aggregate transactional boundaries, you may prefer to avoid Repositories. However, those less concerned with the tenets of DDD, only using some of its patterns in a technical way, may prefer Repositories over Data Access Objects. Still others will think that direct use of a persistence mechanism’s Session or Unit of Work [P of EAA] makes more sense. This is not to suggest that you should avoid the use of Aggregates. In fact, the opposite is true. Still, it is an option that some will employ.

> 严格来讲，只有聚合才拥有资源库。如果一个限界上下文（2）中没有使用聚合，那么使用资源库也没有多大意义。如果你只是随机地、直接地获取和使用实体（5），而不用考虑聚合的事务边界，那么你可以不考虑使用资源库。然而，对于那些不怎么关心 DDD 原则的人来说，他们可能只是从技术上使用 DDD 模式，此时他们可能会采用资源库，而不是 DTO。此外，有些人会考虑直接使用持久化机制的 Session 或者 Unit of Work [P of EAA]。这些并不是建议你避免使用聚合，而事实上恰恰相反。当然，这也只是一个选择问题。

In my estimation there are two kinds of Repository designs, a collection-oriented design and a persistence-oriented design. There are circumstances under which a collection-oriented design will work for you, and circumstances when it is best to use a persistence-oriented design. I first discuss when to use and how to create a collection-oriented Repository and follow that with a treatment of persistence-oriented ones.

> 在我看来，存在两种类型的资源库设计，即面向集合（collection-oriented）的设计和面向持久化（persistence-oriented）的设计。有时，面向集合的设计方式可能是你所需的，而有时面向持久化的设计则是最好的方式。在本章中，我将首先讲到面向集合的资源库，然后再讲面向持久化的资源库。

## 12.1 COLLECTION-ORIENTED REPOSITORIES 面向集合资源库

We can consider a collection-oriented design a traditional approach because it adheres to the basic ideas presented in the original DDD pattern. These very closely mimic a collection, simulating at least some of its standard interface. Here you design a Repository interface that does not hint in any way that there is an underlying persistence mechanism, avoiding any notion of saving or persisting data to a store.

> 我们可以将面向集合的资源库看成是一种传统的方式，因为它体现了原生 DDD 资源库模式的基本思想。这种资源库模拟了一个集合，或者至少模拟了集合上的标准接口。此时，从资源库的接口来看，我们根本看不出其背后还存在着持久化机制，也感觉不到我们是在向存储区域中保存数据。

Because this design approach requires some specific capabilities of the underlying persistence mechanism, it’s possible that it won’t work for you. If your persistence mechanism prevents or hampers your ability to design with a collection perspective, see the following subsection. I address the conditions under which I think collection-oriented design works best. To do so I need to establish some foundational background.

> 面向集合资源库需要持久化机制提供一些特殊的功能，因此，它有可能并不适合你。如果你的持久化机制无法满足面向集合资源库这种设计方式，那么请参考后面一节内容。我将讨论到在什么情况下，使用面向集合的资源库是最佳的方式。但是，首先我们需要了解一些背景知识。

Consider how a standard collection works. In Java, C#, or most any other object-oriented language, objects are added to a collection, and they remain in the collection until they are removed. There is no need to do anything special to get the collection to recognize changes to the objects that it contains, other than to ask the collection to hand you a reference to a specific object and then ask that object to do something to itself, which modifies its own state. The same object is still held by the collection, and now the state of that contained object is different from what it was prior to the modification.

> 考虑一个标准集合的工作方式。在 Java 或 C#中，或者其他多数面向对象语言中，我们都可以将对象添加到集合中，这些对象将一直驻留在集合里，直到被删除为止。要对集合中的对象元素进行修改，我们只需要从集合中获得一个对象的引用，然后让对象自己修改自身的状态。在这个过程中，我们并没有在集合本身上做特殊的操作。修改之后的对象依然位于集合之中，但此时该对象的状态和它先前在集合中状态已经不同了。

Let’s look at this a bit closer by stepping through a few examples. Using java.util.Collection as an example, here, in part, is the standard interface:

> 让我们再通过几个例子来进一步理解。比如，对于 java.util.Collection，以下是该类的部分定义：

```java
package java.util;

public interface Collection ... {
    public boolean add(Object o);
    public boolean addAll(Collection c);
    public boolean remove(Object o);
    public boolean removeAll(Collection c);
    ...
}
```

If we want to add an object to a collection, we use add(). If we want to remove the same object, we pass its reference to remove(). The following test assumes a newly instantiated collection of some kind that can contain Calendar instances:

> 如果我们希望向集合中添加一个对象，我们可以使用 add（）方法。之后，如果我们想删除该对象，可以调用 remove（）方法，同时将该对象的引用作为参数传入。在下面的测试中，对于某种新建的集合，我们希望它能够用来存放 Calendar 实例：

```java
assertTrue(calendarCollection.add(calendar));

assertEquals(1, calendarCollection.size());

assertTrue(calendarCollection.remove(calendar));

assertEquals(0, calendarCollection.size());
```

Simple enough. One special kind of collection, java.util.Set, and its implementing java.util.HashSet, provides the kind of collection that a Repository mimics. Every object added to a Set must be unique. If you attempt to add an object already contained by the Set, it will not be added because it is already contained. Thus, you never need to add the same object twice, as if adding it again somehow saves changes that you have asked the object to make to itself. The following test assertions prove that adding the same object more than once has no effect, positive or negative:

> 上面的例子已经足够简单了。在 Java 中，java.util.Set 及其实现类 java.util.HashSet 可作为资源库所模拟的集合。每个添加到 Set 中的对象都必须是唯一的。如果你向 Set 中添加一个已经存在的对象，那么该对象将不会被添加。因此，我们根本不需要重复地添加相同的对象。在下面的测试中，我们验证了向集合中重复添加相同的对象是没有效果的：

```java
Set<Calendar> calendarSet = new HashSet<Calendar>();

assertTrue(calendarSet.add(calendar));

assertEquals(1, calendarSet.size());

assertFalse(calendarSet.add(calendar));

assertEquals(1, calendarSet.size());
```

All of these assertions succeed because, although the same Calendar instance is added twice, the second attempt to add the object does not change the state of the Set. The same goes for a Repository designed using a collection orientation. If we add the Aggregate instance calendar to a CalendarRepository designed with a collection orientation, adding calendar a second time is benign. Each Aggregate has a globally unique identity that is associated with the Root Entity (5, 10). It is this unique identity that allows the Set-like Repository to prevent adding the same Aggregate instances more than once.

> 以上的所有的断言都能够通过，因为即使同一个 Calendar 实例被添加了两次，在第二次添加时，它并不会修改 Set 的状态，这对于面向集合的资源库来说也是如此。对于一个面向集合的资源库 CalendarRepository，如果我们先后两次向其中添加同一个 Calendar 聚合实例，那么第二次添加并不会对该资源库产生影响。每一个聚合都拥有一个全局的唯一标识，该标识位于根实体（5，10）中。正是由于该唯一标识，类似于 Set 的资源库才能避免对同一个聚合实例的多次添加。

It is important to understand the kind of collection—a Set—that a Repository should mimic. Whatever the backing implementation with a specific persistence mechanism, you must not allow instances of the same object to be added twice.

> 对于资源库所模拟的 Set 集合来说，理解它的工作方式是重要的。无论使用了那种类型的持久化机制，我们都不允许将同一个聚合实例多次添加到资源库中。

Another key takeaway is that you don’t need to “re-save” modified objects already held by the Repository. Consider again how you’d go about modifying an object that is held by a collection. It’s really simple, actually. You’d just retrieve from the collection the reference to the object you desire to modify, and then ask the object to execute some state-transitioning behavior by invoking a command method.

> 此外，如果要对资源库中的一个对象进行修改，我们并不需要“重新保存”该对象。重新考虑集合的情形，要修改其中的一个对象，我们只需要先从集合中获取到该对象的引用，然后在该对象上执行行为方法即可。

Take-aways for Collection-Oriented Repositories 面向集合资源库精要

A Repository should mimic a Set collection. Whatever the backing implementation with a specific persistence mechanism, you must not allow instances of the same object to be added twice. Also, when retrieving objects from a Repository and modifying them, you don’t need to “re-save” them to the Repository.

> 一个资源库应该模拟一个 Set 集合。无论采用什么类型的持久化机制，我们都不应该允许多次添加同一个聚合实例。另外，当从资源库中获取到一个对象并对其进行修改时，我们并不需要“重新保存”该对象到资源库中。

To illustrate, say we extend (subclass) a standard java.util.HashSet and create a method on the new type that allows us to find a specific object instance by unique identity. We’ll give the extending class a name that identifies it as a Repository, but it’s just an in-memory HashSet:

> 作为演示，让我们对 java.util.HashSet 进行扩展，并向扩展类中添加一个方法，该方法根据唯一标识查找对象实例。我们将该扩展类命名成 CalendarRepository，在本质上它只是一个内存中的 HashSet：

```java
public class CalendarRepository extends HashSet {
    private Set<CalendarId, Calendar> calendars;

    public CalendarRepository() {
        this.calendars = new HashSet<CalendarId, Calendar>();
    }

    public void add(Calendar aCalendar) {
        this.calendars.add(aCalendar.calendarId(), aCalendar);
    }

    public Calendar findCalendar(CalendarId aCalendarId) {
        return this.calendars.get(aCalendarId);
    }
}
```

We don’t normally subclass HashSet in order to create a typical Repository. Here we do so just for the sake of example. So, back to the example. Now we can add a Calendar instance to the specialized Set and later find the instance and ask it to modify itself:

> 通常来说，我们并不会因为要创建一个资源库而去扩展 HashSet 类，这里我们只是举一个例子而已。在该例中，我们可以将一个 Calendar 实例添加到一个特定的 Set 中，之后再对其进行查找和修改：

```java
CalendarId calendarId = new CalendarId(...);
Calendar calendar =
    new Calendar(calendarId, "Project Calendar", ...);
CalendarRepository calendarRepository = new CalendarRepository();
calendarRepository.add(calendar);

// later ...
Calendar calendarToRename =
    calendarRepository.findCalendar(calendarId);
calendarToRename.rename("CollabOvation Project Calendar");

// even later still ...
Calendar calendarThatWasRenamed =
    calendarRepository.findCalendar(calendarId);
assertEquals("CollabOvation Project Calendar",
    calendarThatWasRenamed.name());
```

Note that the instance of Calendar, referenced by calendarToRename, is modified by asking it to rename itself. Much later, after the rename is performed, the name is still what it was changed to. This was accomplished without asking the HashSet subclass CalendarRepository to save changes to the Calendar instance, which wouldn’t make any sense. CalendarRepository doesn’t have a save() method because there is no need for one. There is no reason to save changes to the Calendar instance that calendarToRename references, because the collection still holds a reference to the object being modified, and the modifications are made directly on that object.

> 请注意这里的 calendarToRename 实例，在修改该实例时，我们调用了它自身的 rename（）方法。之后，当我们再次从资源库中获取该实例时，它的名字也随之变成了先前修改之后的名字。这里，我们并没有让 CalendarRepository 去保存对 Calendar 实例的修改。CalendarRespository 中并不存在一个 save（）方法，因为这没有必要。我们没有理由去保存对 calendarToRename 实例的修改，因为此时的集合依旧维护了对该实例的引用，而修改将直接作用在该实例上。

The bottom line, then, is that a traditional collection-oriented Repository truly mimics a collection in that no parts of the persistence mechanisms are surfaced to the client by its public interface. Therefore, it is our goal to design and implement such a collection-oriented Repository with the characteristics demonstrated by a HashSet, but with a persistent data store instead.

> 当然，这也是有底线的，即一个面向集合的资源库应该真正地模拟一个集合，而不应该让持久化机制通过公有接口泄漏到客户端中。因此，我们的目标应该是设计并实现一个类似于 HashSet 的面向集合资源库，但是采用的不再是内存的 java.util.Hashset，而是真正的持久化数据存储。

As you can imagine, this requires some specific capabilities of the backing persistence mechanism. The persistence mechanism must in some way support the ability to implicitly track changes made to each persistent object that it manages. This may be accomplished in various ways, including the following two:

> 正如你所想，这需要背后的持久化机制提供一些特殊的功能支持。此时的持久化机制必须能够隐式地跟踪发生在每个持久化对象上的改变。有多种方法都可以达到这样的目的，包括：

1. Implicit Copy-on-Read [Keith & Stafford]: The persistence mechanism implicitly copies each persistent object on read when it is reconstituted from the data store and compares its private copy to the client’s copy on commit. Stepping through this, when you ask the persistence mechanism to read an object from the data store, it does so and immediately makes a copy of the entire object (minus any lazy-loaded parts, which also may be loaded and copied later). When a transaction created through the persistence mechanism is committed, the persistence mechanism checks for modifications on the copied objects it has loaded (or reattached to) by comparing them. All objects with detected changes are flushed to the data store.
2. Implicit Copy-on-Write [Keith & Stafford]: The persistence mechanism manages all loaded persistent objects through a proxy. As each object is loaded from the data store, a thin proxy is created and handed to the client. Clients unknowingly invoke behavior on the proxy object, which reflects the behavior onto the real object. When the proxy first receives a method invocation, it makes a copy of the managed object. The proxy tracks changes made to the state of the managed object and marks it dirty. When a transaction created through the persistence mechanism is committed, it checks for dirty objects and all such are flushed to the data store.

---

> 1. 隐式读时复制（Implicit Copy-on-Read）[Keith & Stafford]：在从数据存储中读取一个对象时，持久化机制隐式地对该对象进行复制，在提交时，再将该复制对象与客户端中的对象进行比较。详细过程如下：当客户端请求持久化机制从数据存储中读取一个对象时，该持久化机制一方面将获取到的对象返回给客户端，一方面立即创建一份该对象的备份（除去延迟加载部分，这些部分可以在之后实际加载时再进行复制）。当客户端提交事务时，持久化机制把该复制对象与客户端中的对象进行比较。所有的对象修改都将更新到数据存储中。
> 2. 隐式写时复制 Implicit Copy-on-Write）[Keith & Stafford]：持久化机制通过委派来管理所有被加载的持久化对象。在加载每个对象时，持久化机制都会为其创建一个微小的委派并将其交给客户端。客户端并不知道自己调用的是委派对象中的行为方法，委派对象会调用真实对象中的行为方法。当委派对象首次接收到方法调用时，它将创建一份对真实对象的备份。委派对象将跟踪发生在真实对象上的改变，并将其标记为“肮脏的”（dirty）。当事务提交时，该事务检查所有的“肮脏”对象并将对它们的修改更新到数据存储中。

The advantages and differences between these approaches may vary, and if your system stands to suffer the negative consequences of choosing one over the other, you should measure them carefully. Of course, you can decide to go with your favorite rather than doing your homework, but that may not be the safest decision.

> 以上两种方式之间的优势和区别可能会根据具体情况而不同。对于你的系统来说，如果两种方案都存在各自的优缺点，那么此时你便需要慎重考虑了。当然，你可以选择自己最喜欢的方式，但是这不见得是最安全的选择。

Still, the overall advantage to either of these approaches is that persistent object changes are tracked implicitly, requiring no explicit client knowledge or intervention to make changes known to the persistence mechanism. The bottom line here is that using a persistence mechanism like this, such as Hibernate, allows you to employ a traditional, collection-oriented Repository.

> 无论如何，这两种方式都有一个相同的优点，即它们都可以隐式地跟踪发生在持久化对象中的变化，而不需要客户端自行处理。这里的底线是，持久化机制，比如 Hibernate，能够允许我们创建一个传统的、面向集合的资源库。

That said, it is possible even if you have the latitude to use such an implicit-copying change-tracking persistence mechanism, such as Hibernate, that it may be undesirable or inappropriate to use. If your requirements demand a very high-performance domain with many, many objects in memory at any given time, this sort of mechanism is going to add gratuitous overhead, in both memory and execution. You will have to consider and decide carefully whether or not this works for you. Certainly there are many domains in which Hibernate does work. So don’t take my call to attention as an attempt to declare a taboo. The use of any tool should be with full awareness of trade-offs.

> 另一方面，即便我们能够使用诸如 Hibernate 这样的持久化机制来创建面向集合的资源库，我们依然会遇到一些不合适的场景。如果你的领域对性能要求非常高，并且在任何一个时候内存中都存在大量的对象，那么持久化机制将会给系统带来额外的负担。此时，你需要考虑并决定这样的持久化机制是否适合于你。当然，在很多情况下，Hibernate 都是可以工作得很好的。因此，虽然我是在提醒大家这些持久化机制有可能带来的问题，但这并不意味着你就不应该采用它们。对任何工具的使用都需要多方位权衡。

Cowboy Logic 牛仔的逻辑

LB: “When my dog got a case of worms, the veterinarian prescribed some repositories.”

> LB：“当我的狗长了肠虫时，我的兽医便会给它开一些 Repository。”[1]

Image

This could lead you to consider the use of a more optimally performing object-relational mapping tool that can support a collection-oriented Repository. One such tool is Oracle’s TopLink, and its nearest relative, EclipseLink. TopLink provides a Unit of Work, which is not entirely unlike Hibernate’s Session. However, TopLink’s Unit of Work does not make an implicit copy-on-read. Instead, it makes an Explicit Copy-before-Write [Keith & Stafford]. Here the term explicit means that the client must inform the Unit of Work that changes are about to take place. This gives the Unit of Work the opportunity to clone the given domain object in preparation for modifications (what it calls edits, discussed later in this chapter). The key point is that TopLink consumes memory only when it must.

> 此时，你可以考虑使用另外一些高性能的 ORM 工具来创建面向集合资源库，其中一种工具便是 Oracle 的 TopLink，此外还有 EclipseLink。TopLink 提供了 Unit ofWork 的功能，这和 Hibernate 的 Session 并非全然不同。然而，TopLink 的 Unit ofWork 并不提供隐式读时复制功能，而是采用了显式写前复制（ExplicitCopy-before-Write）[Keith & Stafford]。这里的“显式”表示，在修改对象之前，客户端必须通知 Unit of Work。在接到通知之后，Unit of Work 便会克隆相应的领域对象以做好修改准备（Unit of Work 称为“编辑（edit）”，本章后面将讨论到）。这种方式的好处在于，TopLink 只有在需要的时候才会占用内存。.

### 12.1.1 Hibernate Implementation Hibernate 实现

There are two primary steps to creating either orientation of a Repository. You need to define a public interface and at least one implementation.

> 不管是对于面向集合的资源库，还是面向持久化的资源库，在创建的时候都有两个主要的步骤。首先，我们需要定义公有接口；其次，我们至少需要提供一种实现。

Specifically in the case of a collection-oriented design, in the first step you define an interface that mimics a collection. The second step provides an implementation that addresses the use of the backing primary storage mechanism, such as Hibernate. The interface, like a collection, will often have common methods such as are found in the following example:

> 对于面向集合的资源库来说，我们首先需要定义能够模拟集合的接口，然后再使用一种持久化机制来实现该接口，比如 Hibernate。接口的定义通常与下面的 CalendarEntryRepository 相似：

```java
package com.saasovation.collaboration.domain.model.calendar;

public interface CalendarEntryRepository  {
    public void add(CalendarEntry aCalendarEntry);
    public void addAll(
            Collection<CalendarEntry> aCalendarEntryCollection);
    public void remove(CalendarEntry aCalendarEntry);
    public void removeAll(
            Collection<CalendarEntry> aCalendarEntryCollection);
    ...
}
```

Place the interface definition in the same Module (9) as the Aggregate type that it stores. In this case interface CalendarEntryRepository is placed in the same Module (Java package) as CalendarEntry. The implementation class goes in a separate package, as discussed later.

> 将接口定义与它将存储的聚合放在相同的模块（9）中。在本例中，CalendarEntryRepository 与 CalendarEntry 放在相同的模块（Java 包）中。实现类将被放置在另外的包中，对此，我们将之后讨论。

Interface CalendarEntryRepository has methods that are very much like those provided by collections, such as the standard java.util.Collection. One new CalendarEntry may be added to this Repository using add(). Multiple new instances may be added using addAll(). Once the instances have been added, they will be persisted to some sort of data store and be retrievable by unique identity from that point forward. The antithesis of those methods is remove() and removeAll(), allowing for the removal of one or multiple instances from the collection.

> CalendarEntryRepository 中的方法与集合（比如 java.util.Collection）提供的方法非常相似。要添加一个新的 CalendarEntry 实例，我们可以调用该资源库的 add（）方法。多个 CalendarEntry 实例可以通过 addAll（）方法予以添加。在 CalendarEntry 实例被添加之后，它们将被保存到数据存储中。之后，我们便可以通过唯一标识重新获取这些实例。与 add（）和 addAll（）方法相对应的是 remove（）和 removeAll（）方法，它们用于从集合中删除一个或多个实例。

I personally don’t like these methods to answer Boolean results as do full-fledged collections. That’s because in some cases answering true to an add-type operation does not guarantee success. The true results may still be subject to a transaction commit on the data store. Thus, void may be the more accurate return type in the case of a Repository.

> 就个人来讲，我并不喜欢使这些方法返回 Boolean 类型的结果，因为对于一个添加方法来说，有时返回 true 并不能保证对实例的成功添加。因此，对于资源库来说，返回 void 可能是更好的方式。

There may be cases where adding and/or removing multiple Aggregate instances in one transaction isn’t appropriate. When that is true of a given case in your domain, don’t include methods addAll() and removeAll(). However, these methods are provided only for convenience. A client can always use a loop to invoke add() or remove() multiple times when iterating over a collection on its own. So eliminating the addAll() and removeAll() methods is only symbolic of a policy that can’t actually be enforced by design, unless you also build in a means to detect adding and removing multiple objects in a single transaction. Doing so would likely require such a Repository to be instantiated for every transaction, which is a potentially costly proposal. I won’t discuss this further.

> 有时，在单个事务中对多个聚合实例进行添加或删除并不合适。在这样的情况下，请不要使用 addAll（）和 removeAll（）方法。这些方法只是为了使用上的方便而已。对客户端来说，它可以通过循环调用 add（）或 remove（）的方式来添加或删除多个聚合实例。因此，去除 addAll（）和 removeAll（）并不能真正达到我们的目的，除非我们创建某种机制，能够在单个事务中检查到对多个实例的添加或删除。这样做需要我们在每次事务中重新初始化资源库，这样的成本是很高的，因此，我不会对此做进一步讨论。

It is possible that instances of some Aggregate types must never be removed through normal application use cases. It may be necessary to retrain the instance long after it is no longer usable in the application, possibly for referential and/or historical purposes. Referentially it may actually be very difficult or impossible to remove some objects. From a business perspective it may be unwise, ill advised, or even illegal to remove some objects. In those cases you may decide to simply mark the Aggregate instance disabled, unusable, or, in some other domain-specific way, logically removed. If so, you may determine not to include any removal methods on the Repository public interface, or you may decide to implement the removal methods to set the unusable state of the Aggregate instance. You may instead prevent full object removal through code reviews, where clients are carefully inspected to ensure that no such uses of removal behavior exist. It’s a decision to ponder, but you may find it easier to disallow removal altogether. After all, any methods on public interfaces are generally considered available for use. If removal is publicly available when logically disallowed, you probably want to consider implementing logical rather than physical removal.

> 有时，对于有些类型的聚合实例来说，我们不允许在正常的用例中进行删除。此外，我们也可能需要将那些不再使用的对象实例保留更久的时间，比如用作参考或者出于历史原因。因此，要从系统中删除一些对象可能是非常困难的，甚至是不可能的。从业务角度来讲，删除对象是不明智的，而有时甚至是非法的。在这样的情况下，你可以将聚合实例标记为失活的（disabled）、不可用的（unusable），或者从领域的角度对其进行逻辑删除。此时，你可以不把那些删除方法放在资源库的公有接口中，或者可以在删除方法中只将聚合实例设置成不可用的。另外，你还可以通过代码检查（code review）来避免对聚合实例的删除，此时，你将对客户端代码进行仔细的检查，并保证其中不包含对删除方法的调用。当然，这只是一个选择问题，但是前一种方法要简单得多。毕竟，公有接口中的所有方法都是可用的。如果我们在逻辑上不允许进行删除操作，但是公有接口中却提供了删除方法，那么此时我们应该实现逻辑删除，而不是物理删除。

Another important part of the Repository interface is the definition of finder methods:

> 资源库接口的另一个重要方面是查找方法：

```java
public interface CalendarEntryRepository  {
    ...
    public CalendarEntry calendarEntryOfId(
            Tenant aTenant,
            CalendarEntryId aCalendarEntryId);

    public Collection<CalendarEntry> calendarEntriesOfCalendar(
            Tenant aTenant,
            CalendarId aCalendarId);

    public Collection<CalendarEntry> overlappingCalendarEntries(
            Tenant aTenant,
            CalendarId aCalendarId,
            TimeSpan aTimeSpan);
}
```

The first method definition, calendarEntryOfId(), allows you to retrieve a specific instance of the CalendarEntry Aggregate by unique identity. This type uses an explicit identity type, namely, CalendarEntryId. The second method definition, calendarEntriesOfCalendar(), allows you to retrieve a collection of all CalendarEntry instances for a specific Calendar by its unique identity. Finally, the third finder method definition, overlapping-CalendarEntries(), provides a collection of all CalendarEntry instances for a specific Calendar over a specific TimeSpan. In particular, this method supports retrieving what is scheduled over a particular contiguous period of dates and times.

> 在上例中，calendarEntryOfId（）方法允许我们通过唯一标识来获取相应的 CalendarEntry 聚合实例。该方法使用了显式的标识类型，即 CalendarEntryId。接下来是 calendarEntriesOfCalendar（）方法，该方法通过传入的 Calendar 唯一标识查找出该 Calendar 中的所有 CalendarEntry 实例。最后是 overlappingCalendarEntries（）方法，该方法在 calendarEntriesOfCalendar（）方法的基础之上筛选出那些位于一个时间范围之内的 CalendarEntry 实例（时间范围通过 TimeSpan 表示）。

Finally, you may be wondering how a CalendarEntry is assigned its globally unique identity. This also can be conveniently provided by the Repository:

> 最后，你可能会问：CalendarEntry 的全局唯一标识是如何设置的？该功能也可以通过资源库的公共接口来完成：

```java
public interface CalendarEntryRepository  {
    public CalendarEntryId nextIdentity();
    ...
}
```

Any code responsible for instantiating new CalendarEntry instances uses nextIdentity() to get a new instance of CalendarEntryId:

> 任何需要创建新 CalendarEntry 实例的方法都将使用 nextIdentiy（）来获取该新实例的 CalendarEntryId：

```java
CalendarEntry calendarEntry =
    new CalendarEntry(tenant, calendarId,
            calendarEntryRepository.nextIdentity(),
            owner, subject, description, timeSpan, alarm,
            repetition, location, invitees);
```

See Entities (5) for an exhaustive discussion of identity creation techniques, the use of domain-specific and surrogate identities, and the importance of properly timing the assignment of identity.

> 对于实体唯一标识的创建，请参考实体（5），其中包含了如何创建领域标识和委派标识，另外还讨论了标识创建时间的重要性。

Let’s now look at the implementation class for this traditional Repository. There are a few options for selecting the Module in which to place the class. Some like to use a Module (Java package) directly under the Aggregate and Repository Module. In this case that would mean

> 现在，让我们来看看该资源库的实现。对于资源库的实现类来说，我们可以将其放在另外的模块中。有些人喜欢在聚合和资源库的模块之下新创建一个模块（Java 包），即：

```java
package com.saasovation.collaboration.domain.model.calendar.impl;

public class HibernateCalendarEntryRepository
        implements CalendarEntryRepository  {
    ...
}
```

Placing the class here allows you to manage the implementation in the Domain Layer, but in a special package for implementations. That way you keep the domain concepts cleanly separated from those that directly deal with persistence. This style of declaring interfaces in a richly named package, and their implementations in a sub-package named impl directly under it, is widely practiced in Java projects. However, in the case of the Collaboration Context the team has chosen to locate all technical implementation classes in the Infrastructure Layer:

> 这种方式使得我们可以在领域层中对资源库实现类进行管理，但是此时的实现类需要位于一个特殊的包中。这样，你可以将领域概念与持久化相关概念分离开来。在上例中，我们将资源库接口定义放在了与聚合相同的包中，而将资源库的实现类放在了 impl 子包中，这种方式被大量的 Java 项目所采用。然而，在协作上下文中，团队成员们将实现类放在了基础设施层中：

```java
package com.saasovation.collaboration.infrastructure.persistence;

public class HibernateCalendarEntryRepository
        implements CalendarEntryRepository  {
    ...
}
```

This uses the Dependency Inversion Principle (4), or DIP, for layering infrastructure concerns. The Infrastructure Layer is logically above all others, making references unidirectional and downward to the Domain Layer.

> 这种方式使用了依赖倒置原则（4）。此时，从逻辑上讲，基础设施层位于所有层之上，并且向下单向地引用领域层。

Class HibernateCalendarEntryRepository is a registered Spring bean. It has a zero-argument constructor and has another infrastructure bean object dependency injected:

> 这里的 HibernateCalendarEntryRepository 是一个 Spring 中的 Bean，它拥有一个无参构造函数，此外它还依赖于另一个基础设施层的对象，该对象是被注入进来的：

```java
import com.saasovation.collaboration.infrastructure
        .persistence.SpringHibernateSessionProvider;

public class HibernateCalendarEntryRepository
        implements CalendarEntryRepository  {
    public HibernateCalendarEntryRepository() {
        super();
    }
    ...
    private SpringHibernateSessionProvider sessionProvider;

    public void setSessionProvider(
            SpringHibernateSessionProvider aSessionProvider) {
        this.sessionProvider = aSessionProvider;
    }

    private org.hibernate.Session session() {
        return this.sessionProvider.session();
    }
}
```

Class SpringHibernateSessionProvider is also housed in the Infrastructure Layer in the com.saasovation.collaboration.infrastructure.persistence Module and is injected into each Hibernate-based Repository. Each method that uses Hibernate’s Session object self-invokes method session() to get it. Method session() uses the dependency-injected sessionProvider instance to get the thread-bound Session instance (seen later in this chapter).

> 这里的 SpringHibernateSessionProvider 类也位于基础设施层的 com.saasovation.collaboration.infrastructure.persistence 模块中，它将被注入到每一个基于 Hibernate 的资源库中。每个需要使用 Hibernate 的 Session 对象的方法都将调用 session（）来获取 Session 对象；而 session（）方法则使用注入进来的 sessionProvider 来获得一个线程绑定的 Session 实例（请参考本章后续内容）。

Methods add(), addAll(), remove(), and removeAll() are implemented as follows:

> 以下是对 add（）、addAll（）、remove（）和 removeAll（）方法的实现：

```java
package com.saasovation.collaboration.infrastructure.persistence;

public class HibernateCalendarEntryRepository
        implements CalendarEntryRepository  {
    ...
    @Override
    public void add(CalendarEntry aCalendarEntry) {
        try {
            this.session().saveOrUpdate(aCalendarEntry);
        } catch (ConstraintViolationException e) {
            throw new IllegalStateException(
                    "CalendarEntry is not unique.", e);
        }
    }

    @Override
    public void addAll(
            Collection<CalendarEntry> aCalendarEntryCollection) {
        try {
            for (CalendarEntry instance : aCalendarEntryCollection) {
                this.session().saveOrUpdate(instance);
            }
        } catch (ConstraintViolationException e) {
            throw new IllegalStateException(
                    "CalendarEntry is not unique.", e);
        }
    }

    @Override
    public void remove(CalendarEntry aCalendarEntry) {
        this.session().delete(aCalendarEntry);
    }

    @Override
    public void removeAll(
            Collection<CalendarEntry> aCalendarEntryCollection) {
        for (CalendarEntry instance : aCalendarEntryCollection) {
            this.session().delete(instance);
        }
    }
    ...
}
```

These methods have rather simplistic implementations. Each method self-invokes session() to get its Hibernate Session instance (as just previously explained).

> 这些方法的实现都非常简单，每个方法都通过调用 session（）来获取 Hibernate 的 Session 实例（正如前面所讨论的一样）。

Perhaps curiously, methods add() and addAll() use the Session’s method saveOrUpdate(). This is further support for Set-like adds. If a client happens to add the same CalendarEntry more than once, the saveOr-Update() behavior makes it appear as a benign no-op. In fact, since Hibernate version 3 any form of update is a no-op since, as previously noted, updates are tracked implicitly by object state modifications. Therefore, unless the objects added by these two methods are entirely new, the behavior does nothing.

> 你可能会感到好奇的是，add（）和 addAll（）使用了 Session 的 saveOrUpdate（）方法。如果在客户端发生了多次添加同一个 CalendarEntry 的情况，这里的 saveOrUpdate（）方法给人一种确实在更新既有对象的感觉，但这却是一种假象。事实上，从 Hibernate 3 之后，任何形式的显式更新都是没有效果的。原因在于，正如上文所讲，更新是随着对象状态的变化而隐式完成的。因此，除非所添加的对象是全新的，不然该 saveOrUpdate（）方法是没有任何效果的。

Adding can cause a ConstraintViolationException. Rather than allowing Hibernate exceptions to trickle out to clients, those exceptions are caught and wrapped by the more client-friendly IllegalStateException. We could also declare domain-specific exceptions and throw those. That is a choice for each project team. The main point is that since we are going to the trouble of abstracting away the implementation details of the underlying persistence framework, we want to insulate clients from all such details, including exceptions.

> 添加对象的方法可能会产生 ConstraintViolationException 异常，此时我们捕获了该异常并且将其封装成一个对客户更友好的 IllegalStateException 异常。当然，我们也可以创建一个具有领域含义的异常，这只是一个选择问题。这里的关键在于隐藏底层的持久化细节，我们希望把客户端与这些细节隔离开来，包括异常。

Methods remove() and removeAll() are quite simple. They only need to use the Session delete() to facilitate removal from the underlying data store. There is one additional detail regarding the removal of Aggregates that use one-to-one mappings, which is true in one case in the Identity and Access Context. Because you cannot cascade changes on such relationships, you will need to explicitly delete objects on both sides of the association:

> 此外，remove（）和 removeAll（）方法便非常简单了，我们只需要调用 Seesion 的 delete（）方法即可。但是，在身份与访问上下文中，存在一个一对一映射的例子，此时我们应该小心了。对于这种关系，我们并不能级联式地进行删除，因此必须同时显式地删除位于关联关系两端的对象：

```java
package com.saasovation.identityaccess.infrastructure.persistence;

public class HibernateUserRepository implements UserRepository  {
    ...
    @Override
    public void remove(User aUser) {
        this.session().delete(aUser.person());
        this.session().delete(aUser);
    }

    @Override
    public void removeAll(Collection<User> aUserCollection) {
        for (User instance : aUserCollection) {
            this.session().delete(instance.person());
            this.session().delete(instance);
        }
    }
    ...
}
```

The inner Person object must first be deleted, and then the User Aggregate Root. If you do not delete the inner Person object, it will be orphaned in its corresponding database table. In general this is a good reason to avoid one-to-one associations and instead use a constrained singular many-to-one unidirectional association. However, I chose to implement the one-to-one bidirectional association purposely in order to demonstrate what working with the more troublesome mappings involves.

> 在上例中，一个 User 包含了一个 Person。首先，我们应该删除 Person 对象，然后再删除聚合根 User 对象。如果只删除了 User，而没有删除 Person，那么在相应的数据库表中，Person 将变成“孤儿（Orphan）”。因此，通常来说，我们应该避免使用一对一关联，而应该使用多对一的单向关联。然而，我故意地使用了一对一的双向关联，是因为我想向大家展示这种关联关系所带来的更大的麻烦。

Note that there are different preferred approaches for dealing with such situations. Some may choose to depend on ORM life cycle events to cause part object cascading deletes. I have purposely avoided such approaches because I am a strong opponent of Aggregate-managed persistence, and I strongly advocate Repository-only persistence. The arguments are passionate and never-ending, ad nauseam. You should make an informed choice, but understand that DDD experts avoid Aggregate-managed persistence as a rule of thumb.

> 需要注意的是，我们有多种方式都可以处理这种情况。有人可能会依赖于 ORM 所提供的生命周期事件来完成对象的级联删除。我刻意地没有使用这种方式，因为我强烈反对由聚合来管理持久化，同时我强烈地提倡只使用资源库来处理持久化。当然，有关这两者的争论非常激烈，并且还在继续。因此，在选择时，你需要多方权衡。但是请记住，DDD 专家是不会首先考虑使用聚合来管理持久化的。

Now back to HibernateCalendarEntryRepository and its finder method implementations:

> 回到 HibernateCalendarEntryRepository，其中的查找方法的实现如下：

```java
public class HibernateCalendarEntryRepository
        implements CalendarEntryRepository {
    ...
    @Override
    @SuppressWarnings("unchecked")
    public Collection<CalendarEntry> overlappingCalendarEntries(
        Tenant aTenant, CalendarId aCalendarId, TimeSpan aTimeSpan) {
        Query query =
            this.session().createQuery(
                "from CalendarEntry as _obj_ " +
                "where _obj_.tenant = :tenant and " +
                  "_obj_.calendarId = :calendarId and " +
                  "((_obj_.repetition.timeSpan.begins between " +
                      ":tsb and :tse) or " +
                  " (_obj_.repetition.timeSpan.ends between " +
                      ":tsb and :tse))");
        query.setParameter("tenant", aTenant);
        query.setParameter("calendarId", aCalendarId);
        query.setParameter("tsb", aTimeSpan.begins(), Hibernate.DATE);
        query.setParameter("tse", aTimeSpan.ends(), Hibernate.DATE);
        return (Collection<CalendarEntry>) query.list();
    }

    @Override
    public CalendarEntry calendarEntryOfId(
            Tenant aTenant,
            CalendarEntryId aCalendarEntryId) {
        Query query =
            this.session().createQuery(
               "from CalendarEntry as _obj_ " +
               "where _obj_.tenant = ? and _obj_.calendarEntryId = ?");
        query.setParameter(0, aTenant);
        query.setParameter(1, aCalendarEntryId);
        return (CalendarEntry) query.uniqueResult();
    }

    @Override
    @SuppressWarnings("unchecked")
    public Collection<CalendarEntry> calendarEntriesOfCalendar(
        Tenant aTenant, CalendarId aCalendarId) {
        Query query =
            this.session().createQuery(
                "from CalendarEntry as _obj_ " +
                "where _obj_.tenant = ? and _obj_.calendarId = ?");
        query.setParameter(0, aTenant);
        query.setParameter(1, aCalendarId);
        return (Collection<CalendarEntry>) query.list();
    }
    ...
}
```

Each of the three finders creates a Query through its Session. As is common with Hibernate queries, the team uses HQL to describe the criteria and then loads up the parameter objects. The query is then run, asking for either a singular, unique result or a list collection of objects. The more sophisticated of the thread queries is that of overlappingCalendarEntries(), in which case we must find all CalendarEntry instances that overlap a specific date and time range, or TimeSpan.

> 以上 3 个查找方法都通过 Session 来创建 Query 对象。对于 Hibernate 来讲，我们通常使用 HQL 来进行查询，因此，团队成员们也采用了这种方式来创建查询条件。在执行查询时，它要么返回单个对象，要么返回一个对象集合。这里相对复杂的是 overlappingCalendarEntries（）方法，该方法返回位于一个时间范围之内（以 TimeSpan 表示）的所有 CalendarEntry 实例。

Last we look at the implementation of method nextIdentity():

> 最后是 nextIdentity（）方法的实现：

```java
public class HibernateCalendarEntryRepository
        implements CalendarEntryRepository  {
    ...
    public CalendarEntryId nextIdentity() {
        return new CalendarEntryId(
                UUID.randomUUID().toString().toUpperCase());
    }
    ...
}
```

This particular implementation does not use the persistence mechanism or data store to generate a unique identity. Rather, the relatively fast and very reliable UUID generator is used.

> 该方法并没有使用持久化机制或者数据存储来生产唯一标识，而是采用了相对较快并且可靠的 UUID 生成器。

### 12.1.2 Considerations for a TopLink Implementation TopLink 实现

TopLink has both a Session and a Unit of Work. This differs somewhat from Hibernate in that Hibernate’s Session is also a Unit of Work.1 Let’s look at a perspective on the use of Unit of Work as separate from Session, and then ease into how to use them in a Repository implementation.

> TopLink 同时提供了 Session 和 Unit of Work。但是，这和 Hibernate 是不同的，即 Hibernate 的 Session 同时也是一个 Unit of Work[2]。让我们先看看如何单独地使用 TopLink 中的 Unit of Work，然后再看如何将其使用在资源库中。

1. I am not measuring TopLink’s value in terms of Hibernate. In fact, TopLink has a very long history of success, which was established long before Oracle picked up the product as a result of the WebGain debacle and subsequent “fire sale.” Top is an acronym for “The Object People,” which was the original company behind the tool that is approaching two decades of proven success. Here I am merely contrasting the way the two tools work.

Without the benefit of a Repository abstraction, you’d use TopLink in this way:

> 在没有资源库时，我们可以通过以下方式来使用 TopLink：

```java
Calendar calendar = session.readObject(...);

UnitOfWork unitOfWork = session.acquireUnitOfWork();

Calendar calendarToRename = unitOfWork.registerObject(calendar);

calendarToRename.rename("CollabOvation Project Calendar");

unitOfWork.commit();
```

The UnitOfWork provides a much more efficient use of memory and processing power since you must explicitly inform the UnitOfWork that you intend to modify the object. It is not until that time that a clone, or editing copy, of your Aggregate is made. As shown previously, method registerObject() answers a clone of the original Calendar instance. It is this clone object, referenced by calendarToRename, that must be edited/modified. As you cause modifications on the object, TopLink is able to track the changes that occur. When method commit() on UnitOfWork is invoked, all modified objects are committed to the database.2

> 在修改对象时，我们必须显式地通知 UnitOfWork，因此，这种方式将更加高效。上例中的 registerObject（）方法返回一个对原有 Calendar 实例的备份。在进行编辑/修改操作时，我们事实上是在操作该复制对象，即上例中的 calendarToRename。这样一来，TopLink 便能够对修改进行跟踪。当 UnitOfWork 中的 commit（）方法执行时，所有发生在对象上的修改都将提交到数据库中[3]。

2. This assumes that the Unit of Work is not nested inside a parent. If it is nested inside a parent Unit of Work, changes from the committed Unit of Work are merged with its parent. Ultimately the outermost is committed to the database.

Adding new objects to a TopLink Repository can be facilitated easily enough:

> 要向 TopLink 资源库中添加新对象是非常简单的：

```java
...
public void add(Calendar aCalendar) {
    this.unitOfWork().registerNewObject(aCalendar);
}
...
```

The use of registerNewObject() stipulates that aCalendar is a new instance. This would enforce failure if add() was invoked with aCalendar that is actually preexisting. We could also use the vanilla registerObject() here, which would be similar to using Hibernate’s saveOrUpdate() method (discussed earlier). Either way we satisfy the need for a workable collection-oriented interface.

> 在上例中，所使用的 registerNewObject（）方法表明 aCalendar 是一个新实例。此时，如果 aCalendar 是一个已经存在的实例，那么 add（）方法将失败。当然，我们也可以使用 registerObject（）方法，该方法与 Hibernate 的 saveOrUpdate（）方法具有相似的功能（请参考前文）。不管采用哪种方式，我们都能实现面向集合的资源库。

But we still need a way to acquire a clone when we have to modify a preexisting Aggregate. The trick is to find a convenient way to register such an Aggregate instance with a UnitOfWork. So far our discussion hasn’t provided a Repository interface to do that because we’ve been trying to mimic a Set and avoid any inference to persistence in the interface. Still, we could accomplish this in a way that doesn’t necessarily influence a persistence frame of mind. Consider using one of two approaches:

> 但是，当我们要修改一个已有的聚合实例时，我们依然需要先对该实例进行复制。要达到这样的目的，我们需要找到一种简便的方式将该聚合实例注册到 UnitOfWork 中。但是到目前为止，我们还没有为其提供相应的资源库接口，因为我们不希望在资源库接口中包含与持久化相关的信息。此时，我们可以采用以下两种方式：

```java
public Calendar editingCopy(Calendar aCalendar);

// or

public void useEditingMode();
```

With the first approach editingCopy() would acquire a UnitOfWork, register the given Calendar instance, get its clone, and answer it:

> 在第一种方式中，editingCopy（）方法首先获取到一个 UnitOfWork，然后注册 Calendar 实例，最后返回对该实例的备份：

```java
...
public Calendar editingCopy(Calendar aCalendar) {
    return (Calendar) this.unitOfWork().registerObject(aCalendar);
}
...
```

This reflects the underlying registerObject() way of doing things. Understandably this may not be desirable, but it is a clean approach and doesn’t reflect a persistence frame of mind.

> 这也向我们展示了 registerObject（）方法的工作原理。当然，这种方式可能并不是你所期望的，但是它的确没有在资源库接口中透露与持久化相关的信息，并且是一种非常清晰的做法。

The second approach is to place the Repository into editing mode with useEditingMode(). After this is done, all subsequent finder methods will automatically register all objects they query with a backing UnitOfWork and answer the clones. It does more or less lock the Repository into use for Aggregate modifications. That is, nonetheless, how Repositories tend to be used, either read-only or read for modification. It also reflects the use of a Repository for Aggregates that have well-crafted boundaries that reflect a bias toward transactional success.

> 在第二种方式中，我们通过 useEditingMode（）方法将资源库转到编辑模式。在该方法执行之后，所有的查找方法都会自动地将所查找到的对象注册到一个 UnitOfWork 中，然后返回复制对象。此时，我们使用资源库似乎只是为了对聚合进行修改一样。但是，这正是使用资源库的正确方法——要么只读，要么读取就是为了修改。同时，这种方式也反映出，资源库所处理的聚合拥有良好的边界，并且倾向于事务一致性。

There may be other ways to design a collection-oriented repository for TopLink, but this provides a few options worth considering.

> 要使用 TopLink 来实现面向集合资源库有很多种方式，但以上是最值得使用的方式。

## 12.2 PERSISTENCE-ORIENTED REPOSITORIES 面向持久化资源库

For times when a collection-oriented style doesn’t work, you will need to employ a persistence-oriented, save-based Repository. This will be the case when your persistence mechanism doesn’t implicitly or explicitly detect and track object changes. This happens to be the case when using an in-memory Data Fabric (4), or by any other name a NoSQL key-value data store. Every time you create a new Aggregate instance or change a preexisting one, you will have to put it into the data store by using save() or a save-like Repository method.

> 如果持久化机制不支持对对象变化的跟踪，无论是显式的还是隐式的，那么采用面向集合资源库便不再适用了。此时，我们可以考虑使用面向持久化资源库，这是一种基于保存操作的资源库。在使用内存数据网织（4）或者 NoSQL 键值对存储时，每次新建聚合或修改聚合之后，我们都需要调用资源库中的 save（）方法或者与之类似的方法。

There is another consideration for choosing a persistence-oriented approach, even if you are using an object-relational mapper that supports a collection-oriented approach. What would happen if you designed collection-oriented Repositories and then decided to swap out your relational database with a key-value store? You’d have a lot of ripple through your Application Layer as it would have to be changed to use save() in all places where Aggregate updates occur. You’d also want to rid your Repositories of add() and addAll(), because those would no longer pertain. In cases where it is a very realistic possibility that your persistence mechanism will shift in the future, it might be best to design with the more flexible interface in mind. The downside is that your current object-relational mapper may cause you to leave out necessary uses of save() that you may catch only later when there is no longer a backing Unit of Work.3 The upside is that the Repository pattern will allow you to completely replace your persistence mechanism with potentially little impact on your application.

> 即便你所使用的 ORM 工具提供了对面向集合资源库的支持，我们依然有理由使用面向持久化的资源库。如果你使用的是面向集合资源库，但之后你决定从关系型数据库转向键值对存储，你应该怎么办呢？此时你不得不大规模地修改自己的应用层，在所有更新聚合的地方，你都得改成使用 save（）方法。另外，资源库中的 add（）和 addAll（）方法也没用了，因此你可能还会删除掉此两方法。如果你所选用的持久化机制在将来很有可能进行更换，那么请设计更加灵活的接口以备将来之需。这样做的风险在于，你当前的 ORM 工具可能会诱使你忘却使用 save（）方法，因为该方法只有在更改了持久化机制之后才是必需的[4]。另一方面，它的好处便是：在将来你可以非常方便地更换持久化机制。

3. You could create Application Service (14) tests that account for updating saves as necessary. An in-memory Repository implementation (see the main text later in the chapter) could be designed to audit the thoroughness of saves.

Take-aways for Persistence-Oriented Repositories 面向持久化资源库精要

We must explicitly put() both new and changed objects into the store, effectively replacing any value previously associated with the given key. Using these kinds of data stores greatly simplifies the basic writes and reads of Aggregates. For this reason they are sometimes called Aggregate Stores or Aggregate-Oriented Databases.

> 在向数据存储中添加新建对象或修改既有对象时，我们都必须显式地调用 put（）方法，该方法将以新的值来替换先前关联在某个键上的原值。这种类型的数据存储可以极大地简化对聚合的读写。正因如此，这种数据存储也称为聚合存储（Aggregate Store）或面向聚合数据库（Aggregate-Oriented Database）。

When using an in-memory Data Fabric, such as GemFire or Oracle Coherence, the storage is an in-memory Map implementation mimicking java.util.HashMap, where each mapped element is considered an entry. Similarly, when using a NoSQL store such as MongoDB or Riak, object persistence gives the illusion of something like a collection, instead of tables, rows, and columns. These store key-value pairs. This is effectively a Map-like store, but it uses disk rather than memory as its primary persistence medium.

> 在使用内存数据网织时，比如 GemFire 或 Oracle 的 Coherence，内存中使用的是一个类似于 java.unit.HashMap 的 Map 实现，其中的每一个元素都被称为一个条目（entry）。相似地，在使用 NoSQL 数据存储时，比如 MongoDB 或 Riak，我们更像是在使用集合，而不是数据库中的表、行或列。它们以键值对的方式存储数据，也具有 Map 的特征，但是它们使用的是磁盘而不是内存来做存储介质。

Although both of these styles of persistence mechanisms roughly mimic a Map collection, we must unfortunately explicitly put() both new and changed objects into the store, effectively replacing the value previously associated with the given key. That’s true even when a changed object is logically the same object that is already stored, because these typically don’t provide a Unit of Work to track changes or support transaction demarcation to control atomic writes. Rather, each put() and putAll() represents a separate logical transaction.

> 虽然这里提到的两种持久化机制都大致地模拟了 Map 集合，但是在保存新建对象或修改既有对象时，我们都必须显式地调用 put（）方法，该方法将以新的值来替换先前关联在某个键上的原值。即便被修改的对象和既有的对象在逻辑上表示同一个对象，这样的替换依然会发生，因为这些持久化机制通常不会提供 Unit of Word，或者并不提供事务边界以对原子的写操作进行控制。相反，每一个 put（）和 putAll（）方法都表示一个单独的逻辑事务。

Using either of these kinds of data stores greatly simplifies the basic writes and reads of Aggregates. For example, consider the simplicity of adding this Product (Agile Project Management Context) to a Coherence data grid, and then reading it back again:

> 这些数据存储可以极大地简化对聚合的基本读写操作。比如，如果要将一个 Product（敏捷项目管理上下文）添加到 Coherence 中，然后再进行读取，我们可以采用以下方式：

```java
cache.put(product.productId(), product);

// later ...

product = cache.get(productId);
```

Here the Product instance is automatically serialized to the Map using standard Java serialization. This simplistic interface can be a bit deceptive, however. If you want really high-performing domains, there is a bit more to do. Coherence supports standard Java serialization when a custom serialization provider is not registered. Using the standard Java serialization is not generally the best option. It requires a premium of bytes to represent each object, and it performs relatively poorly.4 You don’t want to purchase a high-performance Data Fabric and then hamstring it by reducing the number of objects it can cache and reduce the overall throughput using slow serialization. So keep in mind that when using a Data Fabric, for example, distribution is introduced into your system. That will often bring a new force into domain model design, namely, custom or at least specialized serialization. That can cause you to make different decisions, at least at an implementation level.

> 这里的 Product 实例将通过 Java 标准的序列化机制自动地序列化到 Coherence 的 Map 中。但是，这个简单的接口可能是具有欺骗性的。如果你对性能有很高的要求，那么你还需要多做一点事情。在没有向 Coherence 注册定制化的持久化机制时，Coherence 将默认使用 Java 标准的序列化机制，但通常来说这并不是一个好的选择，因为在序列化时，Java 会向每一个对象添加额外的字节，同时它的性能也相对较低[5]。因此，即便你购买了一套非常高性能的数据网织产品，但是由于采用了劣质的序列化机制，那么你不得不降低数据网织所能缓存对象的数目，此时你已经享受不到该数据网织所带给你的高性能了。因此请记住，在使用数据网织时，分布式也随之被引入到了系统中。此时，在设计领域模型时，我们不得不将新的因素考虑在内，即我们需要使用一个定制化的序列化机制。这样一来，你至少需要在实现层面上做出不同的选择。

4. It also limits your Coherence clients to Java only, when .NET and C++ clients could also use the grid data if you were to provide Portable Object Format (POF) serialization.

So when using the GemFire or Coherence caches, the MongoDB or Riak key-value stores, or some other kind of NoSQL persistence, you will probably want to use a fast and compact means to convert Aggregates to their serialized/document form and then back again to their object form. Granted, attacking these challenges isn’t that difficult. For instance, creating an optimal serialization for an Aggregate persisted by GemFire or Coherence is no more challenging than creating mapping descriptions for an object-relational mapper. But it’s not as easy as just using put() and get() on a Map.

> 因此，在使 GemFire、Coherence、MongoDB 或者 Riak 时，我们需要一种快速且紧凑的持久化机制在聚合对象和序列化数据之间相互转换。需要肯定的是，要实现这样的目标并不困难。比如，要为 GemFire 或 Coherence 创建一个优化的序列化机制就像在 ORM 中添加映射配置信息这样简单。当然，这也并不是只调用 Map 中的 put（）和 get（）方法这么简单。

Next, I demonstrate how a persistence-oriented Repository can be created for Coherence, and following that I highlight some techniques for doing the same for MongoDB.

> 接下来，让我们来看看如何通过 Coherence 来实现面向持久化资源库，之后我还会谈及到 MongoDB。

### 12.2.1 Coherence Implementation Coherence 实现

As we did with the collection-oriented Repository, we first define an interface and then its implementation. Here’s a persistence-oriented interface that defines save-based methods that are used for the Oracle Coherence data grid:

> 和面向集合资源库一样，我们首先需要定义接口，然后才是实现。在下面的面向持久化资源库接口中，我们定义了一些基于保存操作的方法，这些方法将用于 Oracle 的 Coherence 数据网格：

```java
package com.saasovation.agilepm.domain.model.product;

import java.util.Collection;
import com.saasovation.agilepm.domain.model.tenant.Tenant;

public interface ProductRepository  {
    public ProductId nextIdentity();
    public Collection<Product> allProductsOfTenant(Tenant aTenant);
    public Product productOfId(Tenant aTenant, ProductId aProductId);
    public void remove(Product aProduct);
    public void removeAll(Collection<Product> aProductCollection);
    public void save(Product aProduct);
    public void saveAll(Collection<Product> aProductCollection);
}
```

This ProductRepository is not entirely unlike the CalendarEntryRepository from the previous section. It differs only in the way it allows Aggregate instances to be included in the mimicked collection. In this case we have save() and saveAll() methods rather than add() and addAll() methods. Both method styles logically do similar things. The main difference is how the client uses the methods. To reiterate, when using a collection-oriented style, Aggregate instances are added only when they are created. When using a persistence-oriented style, Aggregate instances must be saved both when they are created and when they are modified:

> 这里的 ProductRepository 并非与前面的 CalendarEntryRepository 全然不同。它们之间的不同之处在于保存聚合的方式。在本例中，我们使用了 save（）和 saveAll（）方法，而不是 add（）和 addAll（）方法。但是从逻辑上来说，它们都完成相似的功能。最大的不同在于客户端对这些方法的使用。在使用面向集合风格时，聚合实例只有在新创建的时候才会使用 add（）或 addAll（）方法；然而在使用面向持久化风格时，无论是创建聚合还是修改聚合，我们都必须使用 save（）或 saveAll（）方法：

```java
Product product = new Product(...);
productRepository.save(product);

 // later ...
Product product =
    productRepository.productOfId(tenantId, productId);
product.reprioritizeFrom(backlogItemId, orderOfPriority);
productRepository.save(product);
```

Other than that, the details are in the implementation. So let’s dive right into that. First take a look at the Coherence infrastructure we need to make the leap to the data grid cache:

> 除此之外，具体的细节都在实现中。因此，让我们看看以 Coherence 实现的资源库：

```java
package com.saasovation.agilepm.infrastructure.persistence;

import com.tangosol.net.CacheFactory;
import com.tangosol.net.NamedCache;

public class CoherenceProductRepository
        implements ProductRepository {
    private Map<Tenant,NamedCache> caches;
    public CoherenceProductRepository() {
        super();
        this.caches = new HashMap<Tenant,NamedCache>();
    }
    ...
    private synchronized NamedCache cache(TenantId aTenantId) {
        NamedCache cache = this.caches.get(aTenantId);
        if (cache == null) {
            cache = CacheFactory.getCache(
                    "agilepm.Product." + aTenantId.id(),
                    Product.class.getClassLoader());
            this.caches.put(aTenantId, cache);
        }
        return cache;
    }
    ...
}
```

In the case of the Agile Project Management Context, the team has chosen to place Repository technical implementations in the Infrastructure Layer.

> 在敏捷项目管理上下文中，开发团队决定将资源库的技术实现放在基础设施层中。

Along with a simple zero-argument constructor, there is the Coherence linchpin, the NamedCache. Among other imports, note those that are specific to creating or attaching to and using a cache, CacheFactory and NamedCache. Both of these classes are in package com.tangosol.net.

> 在无参构造函数中，出现了 Coherence 的一个关键类，NamedCache。请注意 import 语句中的 CacheFactory 和 NamedCache 类，它们都是与创建和使用缓存相关的。这两个类同时位于 com.tangosol.net 包中。

The private method cache() is the means by which a NamedCache is obtained. The method lazily gets the cache on the Repository’s first attempt to use it. This is primarily because each cache is named for the specific Tenant and the Repository must wait for a public method to be invoked before it has access to a TenantId. There are various Coherence named cache strategies that could be designed. In this case the team has chosen to cache using the following namespace:

> 上例中的私有方法 cache（）用于获取 NamedCache。该方法使用了延迟创建的方式，即在第一次调用该方法时，才现场创建一个 NamedCache 予以返回。这主要是因为，每一个 Tenant 都有属于它自己的 NameCache，而只有当资源库中某个公有方法被调用之后，该资源库才能访问到对应的 TenantId。对于 Coherence 来说，存在着多种命名缓存的设计策略。在本例中，开发团队决定采用以下命名空间来命名一个 NamedCache：

1. First level by the Bounded Context short name: agilepm
2. Second level by the Aggregate simple name: Product
3. Third level by the unique identity of each tenant: TenantId

---

> 1. 第一层采用限界上下文的简称：agilepm
> 2. 第二层是聚合名：Product
> 3. 第三层是每个 Tenant 的唯一标识：TenantId

This has a few benefits. First, the model of each Bounded Context, Aggregate, and tenant that is managed by Coherence can be tuned and scaled separately. Also, each tenant is completely segregated from all others, so there is no way that queries for one tenant can accidentally include the objects of other tenants. This is the same motivation used when “striping” each entity table with the tenant identity in a MySQL persistence solution, yet it is even cleaner in this case. Further, anytime a finder method is required to answer all Aggregate instances for a given tenant, there is actually no query required. The finder method just asks Coherence for all entries in the cache. You’ll see this optimization later with the implementation of allProductsOfTenant().

> 这是有很多好处的。首先，对于由 Coherence 管理的每一个限界上下文、聚合和 Tenant，我们都可以对其进行单独地优化与伸缩。另外，多个 Tenant 之间相互完全分离，因此在查询时，一个 Tenant 不会意外地包含另一个 Tenant 中的数据。这和在 MySQL 表中为每个 Tenant 创建唯一的标识具有相同的效果，而在本例中效果更加明显。再者，当需要查找某个 Tenant 下所有的聚合实例时，我们并不需要进行查询，而只需要从 Coherence 缓存中返回所有的条目即可，请参考下文中的 allProductOfTenant（）方法。

As each NamedCache is created or attached to, it is placed into the Map associated with the caches instance variable. This allows each cache to be looked up quickly by TenantId on all uses subsequent to the first.

> 每一个 NamedCache 都被存放在名为 caches 的 Map 中，之后在获取该 NamedCache 时，我们只需要传入相应的 TenantId 即可。

There are far too many Coherence configuration and tuning considerations to address here. It’s an entire discussion on its own, and the literature already goes into this. I’ll leave it to Aleks SeoviImage to cover this topic [SeoviImage]. Now on with the implementation:

> 关于 Coherence 的配置和优化，还有很多需要讲的，请参考[Seovic]。我们继续资源库的实现：

```java
public class CoherenceProductRepository
        implements ProductRepository {
    ...
    @Override
    public ProductId nextIdentity() {
        return new ProductId(
                java.util.UUID.randomUUID()
                    .toString()
                    .toUpperCase());
    }
    ...
}
```

The nextIdentity() method of the ProductRepository is implemented in the same fashion as that of the CalendarEntryRepository. It grabs a UUID and uses it to instantiate a ProductId, which it then answers:

> 这里的 nextIdentity（）方法与 CalendarEntryRepository 中的 nextIdentity（）采用了相同的实现方式，即通过一个 UUID 来实例化一个 ProductId。该 ProductId 将进一步用于 Coherence 缓存：

```java
public class CoherenceProductRepository
        implements ProductRepository {
    ...
    @Override
    public void save(Product aProduct) {
        this.cache(aProduct.tenantId())
                .put(this.idOf(aProduct), aProduct);
    }

    @Override
    public void saveAll(Collection<Product> aProductCollection) {
        if (!aProductCollection.isEmpty()) {
            TenantId tenantId = null;
            Map<String,Product> productsMap =
                new HashMap<String,Product>(aProductCollection.size());
            for (Product product : aProductCollection) {
                if (tenantId == null) {
                    tenantId = product.tenantId();
                }
                productsMap.put(this.idOf(product), product);
            }
            this.cache(tenantId).putAll(productsMap);
        }
    }
    ...
    private String idOf(Product aProduct) {
        return this.idOf(aProduct.productId());
    }

    private String idOf(ProductId aProductId) {
        return aProductId.id();
    }
}
```

To persist a single new or modified Product instance to the data grid, use save(). The save() method uses cache() to get the NamedCache instance for the TenantId of the Product. It then puts the Product instance into the NamedCache. Note the use of method idOf(), which has two editions, one for a Product and the other for a ProductId. In both cases these methods answer the String form of the Product’s unique identity, or ProductId. So the put() method of the NamedCache, which implements java.util.Map, is given a String-based key and the Product instance as the value.

> 通过 save（）方法，我们向数据网格中保存一个新建的或修改后的 Product 实例。该方法将先通过 cache（）方法获得 Tenant 所对应的 NamedCache，再将 Product 实例存放到该 NamedCache 中。请注意 idOf（）方法，该方法具有两个版本，一个以 Product 为参数，一个以 ProductId 为参数。两个 idOf（）方法都以 String 的形式返回 Product 的唯一标识，即 ProductId。因此这里的 NamedCache 是一个以 String 为键，以 Product 为值的 Map，它实现了 java.util.Map 接口。

Method saveAll() may be a bit more complex than you expected. Why not just iterate over aProductCollection, invoking save() for each element? We could do so. However, depending on the specific Coherence cache in use, each invocation of put() requires a network request. Therefore, it’s best to batch up all Product instances to be persisted in a simple local HashMap and submit them with putAll() instead. This reduces the network latency to the lowest possible delay by using a single request, which is the most optimal.

> 另外，saveAll（）方法可能比你想象的要复杂一点。为什么不直接遍历 aProductCollection，然后对每一个元素调用 save（）方法呢？我们是可以这么做的，但是对于这里的 Coherence 缓存来说，每次调用 NamedCache 的 put（）方法都需要一次网络通信。因此，最好的方式是先将所有的 Product 实例存放在一个本地的 HashMap 中，再通过 putAll（）方法一次性地提交。这样，我们只需要进行一次网络通信，从而达到了优化的目的。

```java
public class CoherenceProductRepository
        implements ProductRepository {
    ...
    @Override
    public void remove(Product aProduct) {
        this.cache(aProduct.tenant()).remove(this.idOf(aProduct));
    }

    @Override
    public void removeAll(Collection<Product> aProductCollection) {
        for (Product product : aProductCollection) {
            this.remove(product);
        }
    }
    ...
}
```

The implementation of remove() works exactly as expected. However, given the implementation of saveAll(), removeAll() may be as big a surprise. After all, isn’t there a way to remove a batch of entries? Well, no, the standard java.util.Map interface doesn’t provide that, and thus neither does Coherence. So in this case we do just iterate over aProductCollection and use remove() for each element. Considering the possible consequences of removing only some of the given collection due to Coherence failure, this may seem dangerous. Of course, you will have to weigh the forces of providing a removeAll(), but remember that a major strength of Data Fabrics such as GemFire and Coherence is redundancy and high availability.

> 以上的 remove（）方法并无特别之处。但是，对于 removeAll（）方法来说，你可能会认为我们也应该像 saveAll（）一样一次性完成操作。然而，这样做是不行的，因为标准的 java.util.Map 并不提供这样的功能，进而 Coherence 也无法做到这一点。因此，我们不得不规规矩矩地遍历 aProductCollection，然后对其中的每一个元素调用 remove（）方法。这种方式的风险在于，在删除的过程中，如果 Coherence 失效，那么我们无法删除 aProductCollection 中的所有元素。此时，你可能会思考着是否应该提供 removeAll（）方法。我认为这是多虑的，因为像 GemFire 和 Coherence 这样的数据网织已经具备了很好的可用性和冗余机制。

Finally, we arrive at interface method implementations that provide a few ways of finding Product instances:

> 最后，让我们看看查找方法：

```java
public class CoherenceProductRepository
        implements ProductRepository {
    ...
    @SuppressWarnings("unchecked")
    @Override
    public Collection<Product> allProductsOfTenant(Tenant aTenant) {
        Set<Map.Entry<String, Product>> entries =
            this.cache(aTenant).entrySet();
        Collection<Product> products =
            new HashSet<Product>(entries.size());
        for (Map.Entry<String, Product> entry : entries) {
            products.add(entry.getValue());
        }
        return products;
    }

    @Override
    public Product productOfId(Tenant aTenant, ProductId aProductId) {
       return (Product) this.cache(aTenant).get(this.idOf(aProductId));
    }
    ...
}
```

Method productOfId() only has to do a basic get() on the NamedCache, providing the identity of the Product instance being requested.

> 这里的 productOfId（）只需要调用 NamedCache 中的 get（）便可以获取到相应的 Product 实例。

Method allProductsOfTenant() is the one I previously referred to. Rather than having to employ a more sophisticated Coherence filter entry process, all it needs to do is ask the data grid for all Product instances in the specific NamedCache. Because each cache is segregated down to the individual tenant, every Aggregate instance in the cache satisfies the query.

> 在上文中，我们已经提到了 allProductsOfTenant（）方法。在该方法中，我们需要做的只是从 NamedCache 中取出所有的 Product 实例即可，不存在什么过滤条件。由于每个 Tenant 都拥有属于自己的缓存，因此我们并不需要进行查询操作。

That wraps up class CoherenceProductRepository. This implementation shows how an abstract interface is fulfilled using Coherence as a client to persist data on the grid cache and then find it later. It doesn’t show everything involved in configuring and tuning Coherence, or what it takes to create indexes for each cache, or design a compacting, high-performance serializer for each domain object. That’s not the Repository’s responsibility. See [SeoviImage] for extensive coverage of those topics.

> 以上便是 CoherenceProductRepository 的实现。我们使用了 Coherence 将数据保存在网格缓存中，然后再对所保存的数据进行获取。我们并没有讨论到与 Coherence 相关的配置、缓存索引、高性能序列化机制等问题，因为这些不属于资源库的职责，如果读者对此感兴趣，请参考[Seovic]。

### 12.2.2 MongoDB Implementation MongoDB 实现

As with the other Repository implementations, there are some basic implementation considerations. The MongoDB implementation is actually similar to the Coherence version. Here is the high-level overview of what we need:

> 和其他资源库实现一样，在使用 MongoDB 时我们也需要做出一些基本的考虑。事实上，MongoDB 实现和 Coherence 相似。在使用 MongoDB 时，我们主要考虑以下几点：

1. A means to serialize Aggregate instances to the MongoDB format, and then deserialize from that format and reconstitute the Aggregate instance. MongoDB uses a special form of JSON called BSON, which is a binary JSON format.
2. A unique identity generated by MongoDB and assigned to the Aggregate.
3. A reference to the MongoDB node/cluster.
4. A unique collection in which to store each Aggregate type. All instances of each Aggregate type must be stored as a set of serialized documents (key-value pairs) in their own collection.

---

> 1. 将聚合实例序列化成 MongoDB 格式，再将 MongoDB 格式数据反序列化成聚合实例。MongoDB 使用了一种特殊的 JSON 格式：BSON，这是一种二进制的 JSON 格式。
> 2. 由 MongoDB 生成唯一标识，再将其赋给聚合。
> 3. 获取到 MongoDB 的节点/集群。
> 4. 对每种类型的聚合使用一个单独的集合。某种聚合的所有实例必须以序列化文档（键值对）的形式保存在属于它们自己的集合中。

Let’s take this step by step as we look through a Repository implementation. Since we’ll use the ProductRepository again, you can compare the implementation to that for Coherence (previous section).

> 接下来，让我们一步一步来实现 MongoDB 资源库。这里，我们将再次采用 ProductRepository，此时你可以将其与 Coherence 的实现进行比较。

```java
public class MongoProductRepository
        extends MongoRepository<Product>
        implements ProductRepository {
    public MongoProductRepository() {
        super();
        this.serializer(new BSONSerializer<Product>(Product.class));
    }
    ...
}
```

This implementation holds an instance of a BSONSerializer, which is used to serialize and deserialize all Product instances (actually held by superclass MongoRepository). I won’t go into deep detail about BSONSerializer. It’s a custom-developed solution for producing MongoDB DBObject instances from Product instances (and any other Aggregate types) and back to Product instances. This class is provided along with other sample code.

> MongoProductRepository 维护了一个 BSONSerializer 实例，它用于序列化和反序列化所有的 Product 实例（Product 由超类 MongoRepository 持有）。我并不会对 BSONSerializer 做详细的讨论。总的来说，BSONSerializer 是一个定制化的序列化类，它负责在 MongoDB 的 DBObject 实例和 Product 实例之间进行相互转换。

There are a few notable things you can do with a BSONSerializer. Basic serialization and deserialization are handled using direct field access. This frees your domain objects from having to implement JavaBean getters and setters, which tends to steer you away from an Anemic Domain Model [Fowler, Anemic]. Since you won’t use methods to access fields, you will at some point need to migrate from one version of an Aggregate type to another version. To do so you can specify override mappings for each field on deserialization:

> 在基本的序列化和反序列化中，BSONSerializer 将直接访问对象的字段属性。这样，我们的领域对象不用实现 JavaBean 所规定的 setter 和 getter 方法，从而避免了导致贫血领域对象[Fowler，Anemic]。由于我们不会通过方法来访问对象字段，在有些情况下我们可能需要将一个版本的聚合迁移到另一个版本。此时，我们可以在反序列化时通过覆盖原有字段映射的方式予以解决：

```java
public class MongoProductRepository
        extends MongoRepository<Product>
        implements ProductRepository {
    public MongoProductRepository() {
        super();
        this.serializer(new BSONSerializer<Product>(Product.class));
        Map<String, String> overrides = new HashMap<String, String>();
        overrides.put("description", "summary");
        this.serializer().registerOverrideMappings(overrides);
    }
    ...
}
```

In this example we’ll assume that a previous version of class Product had a field named description. In a subsequent version this field was renamed summary. To solve this problem we could run a migration script across all MongoDB collections used to store Product instances for each tenant. However, that could be a difficult and very lengthy set of operations, rendering it an impractical approach. As an alternative, we’ll simply ask the BSONSerializer to map any BSON field on Product named description to the field named summary. Then, when the migrated Product is serialized back to a DBObject and saved in the MongoDB collection, the new serialization will contain a field named summary rather than description. Of course, it also means that any Product instances never read and saved back to the store will remain with the obsolete description field names. You’ll have to weigh the trade-offs of this lazy migration approach.

> 在上例中，我们假设 Product 在先前拥有一个名为 description 的字段，之后该字段被重命名为 summary。要解决这个问题，我们可以运行一个迁移脚本对 MongoDB 中所有的 Product 实例进行转化。但是，这种做法是比较困难的，并且非常耗时。另一种做法是，在反序列化时，利用 BSONSerializer 将 BSON 格式中所有名为 descirption 的字段映射为 summary。之后，在序列化时，由于我们使用的是新的 summary 字段，MongoDB 中保持的数据也将相应地更新为 summary 字段。当然，这也意味着，对于那些没有进行读取进而保存的 Product，它们将继续持有原来的 description 字段。因此，对于这种延迟迁移的做法，我们应该慎重权衡。

Next, we need a way for MongoDB to generate a unique identity for each Aggregate instance to use:

> 接下来，我们需要 MongoDB 生成对象的唯一标识：

```java
public class MongoProductRepository
        extends MongoRepository<Product>
        implements ProductRepository {
    ...
    public ProductId nextIdentity() {
        return new ProductId(new ObjectId().toString());
    }
    ...
}
```

We still use method nextIdentity(), but in this implementation we initialize the ProductId with the String value of a new ObjectId. The main reason for this is that we want MongoDB to use the same unique identity that we hold in the Aggregate instance itself. Thus, when we serialize a Product (or another type in a different Repository implementation), we can ask the BSONSerializer to map that identity to the special MongoDB \_id key:

> 此时，我们依然使用 nextIdentity（）方法，但是在实现中，我们传入一个新建的 ObjectId（转化为 String 类型）来实例化一个 ProductId。主要原因在于，我们希望 MongoDB 使用与聚合本身相同的唯一标识。因此，当我们在序列化一个 Product 时，可以将该唯一标识映射到特殊的 MongoDB_id 键上：

```java
public class BSONSerializer<T> {
    ...
    public DBObject serialize(T anObject) {
        DBObject serialization = this.toDBObject(anObject);
        return serialization;
    }

    public DBObject serialize(String aKey, T anObject) {
        DBObject serialization = this.serialize(anObject);
        serialization.put("_id", new ObjectId(aKey));
        return serialization;
    }
    ...
}
```

The first serialize() method supports no such \_id mapping, giving clients the option to retain the matching identities, or not. Next, look at how the save() method is implemented:

> 第一个 serialize（）方法不支持这样的\_id 映射，客户端可以在这两个方法中自行选取。接下来，让我们看看 save（）方法的实现：

```java
public class MongoProductRepository
        extends MongoRepository<Product>
        implements ProductRepository {
    ...
    @Override
    public void save(Product aProduct) {
        this.databaseCollection(
                this.collectionName(aProduct.tenantId()))
            .save(this.serialize(aProduct));
    }
    ...
}
```

Similar to the Coherence implementation of the same Repository interface, we get a tenant-specific collection in which to store the Product instances for a given TenantId. This yields a Mongo DBCollection from a DB. To get the DBCollection object we have the following in the MongoRepository abstract base class:

> 和 Coherence 相似，在保存 Product 时，我们为每个 Tenant 都创建了单独的 Product 集合，并通过 TenantId 进行获取。该集合以 MongoDB 的 DBCollection 类表示。 在 MongoRepository 抽象基类中，我们定义了 databaseCollection（）方法来获取该 DBCollection 对象：

```java
public abstract class MongoRepository<T> {
    ...
    protected DBCollection databaseCollection(
            String aDatabaseName,
            String aCollectionName) {
        return MongoDatabaseProvider
                .database(aDatabaseName)
                .getCollection(aCollectionName);
    }
    ...
}
```

We use a MongoDatabaseProvider to get a connection to the database instance, which answers with a DB object. From the returned DB object we ask for a DBCollection. As seen in the concrete Repository implementation, the collection is named by the combination of the text "product" and the full identity of the tenant. The Agile PM Context uses a dedicated database named agilepm, much like the way the Coherence implementation names its cache:

> 在上例中，我们通过 MongoDatabaseProvider 获取到一个数据库连接，该连接以一个 DB 类型的对象表示。然后，通过调用 DB 对象的 getCollection（）方法来获取一个 DBCollection。在 MongoProductRepository 的实现中，该 DBCollection 的名字由文本“product”和 Tenant 的唯一标识组成。在敏捷项目管理上下文中，我们为数据库命名为 agilepm，这和 Coherence 对缓存的命名相似：

```java
public class MongoProductRepository
        extends MongoRepository<Product>
        implements ProductRepository {
    ...
    protected String collectionName(TenantId aTenantId) {
        return "product" + aTenantId.id();
    }

    protected String databaseName() {
        return "agilepm";
    }
    ...
}
```

Similar to the SpringHibernateSessionProvider presented previously, the MongoDatabaseProvider is the means to retrieve an application-wide instance of DB.

> 与先前的 S pringHibernateSessionProvider 相似，这里的 MongoDatabaseProvider 用于获取一个数据库实例。

The same DBCollection is used for save() and for finding instances of Product:

> 除了用于 save（）方法外，DBCollection 还用于对 Product 的查找：

```java
public class MongoProductRepository
        extends MongoRepository<Product>
        implements ProductRepository {
    ...
    @Override
    public Collection<Product> allProductsOfTenant(
            TenantId aTenantId) {
        Collection<Product> products = new ArrayList<Product>();
        DBCursor cursor =
            this.databaseCollection(
                    this.databaseName(),
                    this.collectionName(aTenantId)).find();
        while (cursor.hasNext()) {
            DBObject dbObject = cursor.next();
            Product product = this.deserialize(dbObject);
            products.add(product);
        }
        return products;
    }

    @Override
    public Product productOfId(
            TenantId aTenantId, ProductId aProductId) {
        Product product = null;
        BasicDBObject query = new BasicDBObject();
        query.put("productId",
                new BasicDBObject("id", aProductId.id()));
        DBCursor cursor =
            this.databaseCollection(
                    this.databaseName(),
                    this.collectionName(aTenantId)).find(query);
        if (cursor.hasNext()) {
            product = this.deserialize(cursor.next());
        }
        return product;
    }
    ...
}
```

The implementation of allProductsOfTenant() is, again, very similar to that for Coherence. We simply ask the tenant-based DBCollection to find() all instances. As for productOfId(), this time we give the DBCollection method find() a DBObject describing the specific Product instance to retrieve. In both finder methods we use the returned DBCursor to get all, and get only the first instance, respectively.

> 同样，这里的 allProductsOfTenant（）也与 Coherence 中的实现相似。要获取一个 Tenant 下所有的 Product 实例，我们只需调用 DBCollection 中的 find（）方法。在 productOfId（）方法中，我们向 find（）方法传入了一个 DBObject 对象，该对象描述了需要查找的 Product 实例。在两个查找方法中，我们都使用了 DBCursor 对象。在 allProductsOfTenant（）中，DBCursor 用于返回所有的实例；而在 productOfId（）中，DBCursor 返回的是第一个实例，而此时的查找结果中也只包含了一个实例。

## 12.3 ADDITIONAL BEHAVIOR 额外的行为

Sometimes it is beneficial to provide additional behavior on a Repository interface, besides the typical kinds presented in the previous sections. One behavior that comes in handy is to answer the count of all instances in the collection of Aggregates. You might think of this behavior as having the name count. However, since a Repository should mimic a collection as closely as possible, you might consider instead using the following method:

> 对于资源库来说，除了前文讲到的那些典型的行为之外，我们还可以向资源库接口中添加一些额外的行为。其中之一便是计算聚合实例的总数。你可能会将该行为方法命名为 count（），但是由于一个资源库应该尽可能地模拟一个集合，因此我们可以考虑使用以下方法：

```java
public interface CalendarEntryRepository {
    ...
    public int size();
}
```

Method size() is exactly what a standard java.util.Collection supplies. When using Hibernate, the implementation would work like this:

> 这里的 size（）方法和 java.util.Collection 中的一模一样。在使用 Hibernate 时，该方法可以实现为：

```java
public class HibernateCalendarEntryRepository
        implements CalendarEntryRepository  {
    ...
    public int size() {
        Query query =
            this.session().createQuery(
                "select count(*) from CalendarEntry");
        int size = ((Integer) query.uniqueResult()).intValue();
        return size;
    }
}
```

There may be other calculations that must be performed in the data store (database or grid included) in order to meet some stringent nonfunctional requirement. This can be the case if moving the data from its store to where the business logic executes is too slow. Instead you may have to move the code to the data. This can be accomplished using database stored procedures or data grid entry processors, such as are available with Coherence. However, such implementations are often best placed under the control of Domain Services (7), since those are used to house stateless, domain-specific operations.

> 在数据存储（包括数据库或数据网格）中，我们可能还需要执行一些计算过程来满足某些非功能性需求。比如，我们需要将数据从数据存储中搬移到业务逻辑执行的地方，而有时这是一个非常漫长的过程。这时，我们可能需要将代码迁移到数据存储中，比如使用数据库的存储过程或者数据网格的条目处理器（entryprocessor），Coherence 便提供了这样的功能。然而，这些功能最好应该放在领域服务（7）中，因为领域服务正是用于处理那些无状态的、特定于领域的操作。

It may at times be advantageous to query Aggregate parts out of the Repository without directly accessing the Root itself. This might be so if an Aggregate holds a large collection of some Entity type, and you need to get access only to the instances that match a certain criterion. Of course, this might make sense only if the Aggregate allows for such access by navigation through the Root. You wouldn’t design a Repository to provide access to parts that the Aggregate Root would not otherwise allow access to by way of navigation. Doing so would violate the Aggregate contract. I suggest that you would also not design the Repository to provide this kind of access as a mere shortcut for client convenience. I think this should be used primarily to address performance concerns under conditions where navigation through the Root would cause an unacceptable bottleneck. The methods that address such optimal access would have the same basic characteristics as other finders (see earlier in this chapter) but would answer instances of the contained parts rather than Root Entities. Again, use with caution.

> 有时，如果我们要获取聚合根下的某些子聚合，我们不用先从资源库中获取到聚合根，然后再从聚合根中获取这些子聚合，而是可以直接从资源库中返回。在有些情况下，这种做法是有好处的。比如，某个聚合根拥有一个很大的实体类型集合，而你需要根据某种查询条件返回该集合中的一部分实体。当然，只有在聚合根中提供了对该实体集合的导航时，我们才能这么做，否则，我们便违背了聚合的设计原则。我建议不要因为客户端的方便而提供这种访问方式。更多的时候，采用这种方式是由于性能上的考虑，比如从聚合根中访问子聚合将带来性能瓶颈的时候。此时的查找方法和其他查找方法具有相同的基本特征，只是它直接返回聚合根下的子聚合，而不是聚合根本身。无论如何，请慎重使用这种方式。

Another reason might influence you to design in special finder methods. Certain use cases of your system may not follow the exact contours of a single Aggregate type when rendering views of domain data. They may instead cut across types, possibly composing just certain parts of one or more Aggregates. In situations like this you might choose not to, in a single transaction, find whole Aggregate instances of various types and then programmatically compose them into a single container, and supply that payload container to a client. You might instead use what is called a use case optimal query. This is where you specify a complex query against the persistence mechanism, dynamically placing the results into a Value Object (6) specifically designed to address the needs of the use case.

> 另外，我们还有可能在资源库中创建一些特殊的查找方法。比如，如果我们需要在用户界面中显示数据，而这些数据来自于多个聚合，此时我们不用先分别获取到每个聚合，再从中提取出所需数据，而是可以使用用例优化查询（Use CaseOptimal Query）的方法直接查询所需要的数据。此时，我们可以直接在持久化机制上执行查询，然后将查询结果放在一个值对象（6）中予以返回。

It should not seem strange for a Repository to in some cases answer a Value Object rather than an Aggregate instance. A Repository that provides a size() method answers a very simple Value in the form of an integer count of the total Aggregate instances it holds. A use case optimal query is just extending this notion a bit to provide a somewhat more complex Value, one that addresses more complex client demands.

> 从资源库中返回值对象而非聚合实例并不奇怪。比如，前面我们所使用的 size（）方法便是如此，该方法以简单值对象的形式返回聚合实例的数目。对于用例优化查询来说也是一样的，只是此时我们返回的是一个相对复杂的值对象而已。

If you find that you must create many finder methods supporting use case optimal queries on multiple Repositories, it’s probably a code smell. First of all, this situation could be an indication that you’ve misjudged Aggregate boundaries and overlooked the opportunity to design one or more Aggregates of different types. The code smell here might be called Repository masks Aggregate mis-design.

> 在使用用例优化查询时，如果你发现你必须创建多个查询方法，那么这很有可能是一种坏味道，这意味着你对聚合边界的划分是错误的。

However, what if you encounter this situation and your analysis indicates that your Aggregate boundaries are well designed? This could point to the need to consider using CQRS (4).

> 然而，如果的确发生了这样的情况，并且你确认对聚合边界的设计是正确的，那么此时你便应该考虑使用 CQRS（4）了。

## 12.4 MANAGING TRANSACTIONS 管理事务

The domain model and its encompassing Domain Layer is never the correct place to manage transactions.5 The operations associated with a model are usually too fine grained to themselves manage transactions and shouldn’t be aware that transactions play a part in their life cycle. If you are to avoid placing transactional concerns in the model, just where do they belong?

> 对事务的管理绝对不应该放在领域模型和领域层中[6]。通常来说，与领域模型相关的操作都非常细粒度的，以致于无法用于管理事务，另外，领域模型也不应该意识到事务的存在。那么，对事务的管理应该放在什么地方呢？

5. Note that for some persistence mechanisms transaction management is either nonexistent or works differently from ACID transactions common with relational databases. Both Coherence and many NoSQL stores differ in that way, and this material is generally not applicable to such data storage mechanisms.

A common architectural approach to facilitating transactions on behalf of persistence aspects of the domain model is to manage them in the Application Layer (14).6 Generally, we create one Facade [Gamma et al.] there for each major use case grouping addressed by the application/system. The Facade is designed with coarse-grained business methods, usually one for each use case flow (which may be limited to one for a given use case). Each such business method coordinates a task as required by the use case. When a Facade’s business method is invoked by the User Interface Layer (14), whether on behalf of a human or another system, the business method begins a transaction and then acts as a client to the domain model. After all necessary interaction with the domain model is successfully completed, the Facade’s business method commits the transaction it started. If an error/exception occurs that prevents completion of the use case task, the transaction is rolled back by the same managing business method.

> 通常来说，我们将事务放在应用层（14）中[7]。[Gamma et al.]。然后为每个主要的用例创建一个门面[Gamma et al.]，门面中的业务方法通常都是粗粒度的，常见的情况是每一个用例流对应一个业务方法。业务方法对用例所需操作进行协调。当用户界面层（14）调用门面中的一个业务方法时，该方法都将开始一个事务。同时，该业务方法将作为领域模型的客户端而存在。在所有的操作完成之后，门面中的业务方法将提交事务。在这个过程中，如果发生错误/异常，那么业务方法将对事务进行回滚。

6. There are other concerns managed by the Application Layer, such as security, but I don’t discuss those here.

The transaction may be managed declaratively or explicitly by developer code. Whether or not your transactions are declarative or user managed, what I have described here logically works as follows:

> 我们可以通过声明式的方法来管理事务，也可以自行编码。无论采用哪种方式，对事务的管理过程都与以下执行过程相似：

```java
public class SomeApplicationServiceFacade {
    ...
    public void doSomeUseCaseTask()  {
        Transaction transaction = null;
        try {
            transaction = this.session().beginTransaction();
            // use the domain model ...
            transaction.commit();
        } catch (Exception e) {
            if (transaction != null) {
                transaction.rollback();
            }
        }
    }
}
```

To enlist changes to the domain model in a transaction, ensure that Repository implementations have access to the same Session or Unit of Work for the transaction that the Application Layer started. That way the modifications made in the Domain Layer will be properly committed to the underlying database or rolled back.

> 要将对领域模型的修改添加到事务中，我们必须保证资源库实现与事务使用了相同的 Session 或 Unit of Work。这样，在领域层中发生的修改才能正确地提交到数据库中，或者回滚。

There is such a variety in how this can be accomplished that I cannot address all possibilities. What I will do is note that enterprise Java containers and inversion-of-control containers, such as Spring, provide the means to do what I have described, and it is generally well understood. The emphasis here is to use what is appropriate for your environment. As an example, here’s how you might do so using Spring:

> 有很多方法都可以完成对事务的管理，我并不会一一列举。这里我主要讨论在一些企业级 Java 容器和依赖反转容器中是如何管理事务的，比如 Spring。在 Spring 中，我们可以通过以下方式来管理事务：

```xml
<tx:annotation-driven transaction-manager="transactionManager"/>

<bean
    id="sessionFactory"
    class="org.springframework.orm.hibernate3.LocalSessionFactoryBean">
    <property name="configLocation">
        <value>classpath:hibernate.cfg.xml</value>
    </property>
</bean>

<bean
    id="sessionProvider"
    class="com.saasovation.identityaccess.infrastructure
           .persistence.SpringHibernateSessionProvider"
    autowire="byName">
</bean>

<bean
    id="transactionManager"
    class="org.springframework.orm.hibernate3
           .HibernateTransactionManager">
    <property name="sessionFactory">
        <ref bean="sessionFactory"/>
    </property>
</bean>

<bean
    id="abstractTransactionalServiceProxy"
    abstract="true"
    class="org.springframework.transaction.interceptor
           .TransactionProxyFactoryBean">
    <property name="transactionManager">
        <ref bean="transactionManager"/>
    </property>
    <property name="transactionAttributes">
        <props>
            <prop key="*">PROPAGATION_REQUIRED</prop>
        </props>
    </property>
</bean>
```

The configured sessionFactory bean provides the means to obtain a Hibernate Session. The bean named sessionProvider is used to associate a Session obtained from the sessionFactory with the current Thread of execution. The sessionProvider bean can be used by Hibernate-based Repositories when they need to get the Session instance for the Thread they are running under. The transactionManager uses the session-Factory to get and manage Hibernate transactions. The one remaining bean, abstractTransactionalServiceProxy, is used optionally as a proxy for declaring transactional beans using Spring configuration. The topmost declaration allows transactions to be declared via Java annotations, which may be more convenient than using configuration:

> 在上例中，sessionFactory 用于获取一个 Hibernate 提供的 Session，sessionProvider 将该 sessionFactory 与当前线程关联起来。当基于 Hibernate 的资源库需要为当前线程获取一个 Session 实例时，它将通过 sessionProvider 来完成。另外，transactionManager 通过 sessionFactory 来获取并管理 Hiberante 事务。余下的 abstractTransactionalServiceProxy 是可选的，它的作用是为需要事务管理的 bean 提供委派。最上面的 annotation-driven 使得我们通过 Java 注解的方式来声明事务，这种方式比显式的配置更加方便：

```xml
<tx:annotation-driven transaction-manager="transactionManager"/>
```

With this wired you can now declare a given Facade business method transactional using a simple annotation:

> 如此一来，在门面的业务方法中，我们便可以使用@Transactional 注解来声明事务：

```java
public class SomeApplicationServiceFacade {
    ...
    @Transactional
    public void doSomeUseCaseTask()  {
        // use the domain model ...
    }
}
```

Compared to the previous example of managing a transaction, this certainly cuts down on clutter in the business method and allows you to focus on the task coordination itself. By means of this annotation, when the business method is invoked, Spring automatically starts a transaction, and when the method completes, the transaction is either committed or rolled back as appropriate.

> 与先前的事务管理例子相比，此时的业务方法更加清晰，这也使得我们将关注点放在业务操作本身上。在这种方法中，当业务方法执行时，Spring 将自动地启动一个事务，当方法执行完成时，事务要么提交，要么回滚。

Here is a look at the source code of the sessionProvider bean as it is implemented for the Identity and Access Context:

> 在身份与访问上下文中，我们可以找到 sessionProvider 的源代码：

```java
package com.saasovation.identityaccess.infrastructure.persistence;

import org.hibernate.Session;
import org.hibernate.SessionFactory;

 public class SpringHibernateSessionProvider {
    private static final ThreadLocal<Session> sessionHolder =
            new ThreadLocal<Session>();
    private SessionFactory sessionFactory;

    public SpringHibernateSessionProvider() {
        super();
    }

    public Session session() {
        Session threadBoundsession = sessionHolder.get();
        if (threadBoundsession == null) {
            threadBoundsession = sessionFactory.openSession();
            sessionHolder.set(threadBoundsession);
        }
        return threadBoundsession;
    }

    public void setSessionFactory(SessionFactory aSessionFactory) {
        this.sessionFactory = aSessionFactory;
    }
}
```

Since the sessionProvider is a Spring bean that is declared with autowire="byName", when the bean is instantiated as a singleton its setSessionFactory() method is invoked to inject the sessionFactory bean instance. To save you looking back through the chapter in search of how a Hibernate-based Repository uses this, here’s a brief reminder:

> 在 Spring 配置中，由于该 sessionProvider 被声明为 autowire="byName"，在实例化时，它的 setSessionFactory（）方法将自动地找到名为“sessionFacotry”的 bean 实例，并将其作为参数传入。在本章的前面，我们给出了基于 Hibernate 的资源库示例代码，其中便有对 SpringHibernateSessionProvider 的使用：

```java
package com.saasovation.identityaccess.infrastructure.persistence;

public class HibernateUserRepository
        implements UserRepository  {
    @Override
    public void add(User aUser) {
        try {
            this.session().saveOrUpdate(aUser);
        } catch (ConstraintViolationException e) {
            throw new IllegalStateException("User is not unique.", e);
        }
    }
    ...
    private SpringHibernateSessionProvider sessionProvider;

    public void setSessionProvider(
            SpringHibernateSessionProvider aSessionProvider) {
        this.sessionProvider = aSessionProvider;
    }

    private org.hibernate.Session session() {
        return this.sessionProvider.session();
    }
}
```

This snippet is from the HibernateUserRepository of the Identity and Access Context. This class, too, is a Spring bean that is autowired by name, which means its method setSessionProvider() is automatically invoked upon creation so that it gets a reference to the sessionProvider bean, which is an instance of SpringHibernateSessionProvider. When the add() method (or any other method that provides persistence) is invoked, it asks for a Session through its session() method. In turn, session() uses the injected sessionProvider to obtain the thread-bound Session instance.

> 以上代码片段摘自身份与访问上下文中的 HibernateUserRepository。该类也是一个 Spring 所管理的 bean，并且使用了与 sessionProvider 相同的 autowire 机制。当 setSessionProvider（）方法调用时，它将找到名为“sessionProvider”的 bean，并将其作为参数传入。这里的 sessionProvider 即 SpringHibernateSessionProvider 类的实例。在执行 add（）方法（或者其他持久化方法）时，它通过调用 session（）方法获取一个 Session，session（）方法进而使用注入的 sessionProvider 来获得一个线程绑定的 Session 实例。

While I have demonstrated how transactions are managed only when using Hibernate, all of these principles carry over to TopLink, JPA, and other persistence mechanisms. With any such persistence mechanism you must find a way to provide access to the same Session, Unit of Work, and transaction that the Application Layer is managing. Dependency injection works well for this if it is available. If it isn’t available, there are other creative ways to facilitate the necessary wiring, even going as far as manually binding such objects to the current thread.

> 虽然我只讨论了 Hibernate 的事务管理，但这些原则同样适用于 TopLink、JAP 或者其他的持久化机制。对于其中任何一个持久化机制，我们都需要在整个业务操作中访问相同的 Session、Unit of Work 和由应用层所管理的事务。此时，依赖注入是一个很好的选择。但是，在没有依赖注入的情况下，我们依然可以找到很多方式来实施事务管理，甚至可以通过手动的方式将这些对象绑定到当前线程中。

### 12.4.1 A Warning 警告

I feel obligated to provide a parting warning about overuse of transactions in conjunction with the domain model. Aggregates must be designed carefully in order to ensure correct consistency boundaries. Be careful not to overuse the ability to commit modifications to multiple Aggregates in a single transaction just because it works in a unit test environment. If you aren’t careful, what works well in development and test can fail severely in production because of concurrency issues. If need be, revisit Aggregates (10) for vital reminders to precisely define consistency boundaries in order to ensure transactional success.

> 我认为有必要给读者一个警告：不要过度地在领域模型上使用事务。我们必须慎重地设计聚合以保证正确的一致性边界。有时，在测试环境下，在单个事务中修改多个聚合可能工作得很好，但是在产品环境下，却有可能出现由并发所导致的事务失败。在聚合（10）中，我们讨论了如何准确地定义一致性边界以保证事务的成功，读者可以自行参考。

## 12.5 TYPE HIERARCHIES 类型层级

When using an object-oriented language to develop a domain model, it can be tempting to leverage inheritance to create type hierarchies. We might think of this as an opportunity to place default state and behavior in a base class and then extend that using subclasses. And why not? It seems like a perfect way to avoid repeating yourself.

> 在使用面向对象语言来开发领域模型时，我们通常喜欢通过继承来创建类型层级。此时，我们将默认状态和行为放在基类中，然后创建子类对其进行扩展。为什么不呢？这似乎是避免重复的绝佳方式。

Creating Aggregates that have a common ancestry and yet stand apart from their relatives with a separate Repository is a different use of inheritance from creating Aggregates with the same ancestry that share a single Repository. So this section does not discuss the situation where all Aggregate types in a single domain model extend a Layer Supertype [Fowler, P of EAA] to provide domain-wide common state and/or behavior.7

> 对于共享基类的聚合类来说，我们可以为每一种实际的聚合类型创建一个资源库，也可以在单个资源库中创建不同的实际聚合类。对于对继承的使用来说，这两者是不同的。因此，本节不会讨论所有的聚合类型都扩展自同一个层超类型[Fowler，Pof EAA]的情况。

7. I discuss the benefits of using a Layer Supertype in the design of Entities (5) and Value Objects (6). See the respective chapters.

Rather, here I am referring to creating a relatively small number of Aggregate types that extend a common domain-specific superclass. These are designed in order to form a hierarchy of closely related types that have interchangeable, polymorphic characteristics. These kinds of hierarchies use a single Repository to store and retrieve instances of the separate types, because the client should use the instances interchangeably, and clients rarely if ever have to be aware of the specific subclass that they are dealing with at any given time, which reflects the Liskov Substitution Principle (LSP) [Liskov].

> 我这里想讨论的是一组数目相对较少的聚合类型，它们都扩展自一个特定于领域的超类。这些关联密切的聚合所组成的类型层级具有可互换性和多态性的特征。此时，我们使用单个资源库来保存和获取层级中的不同聚合类型，而客户端无须知道他们所使用的实际类型。这也体现了 Liskov 替换原则（Liskov SubstitutionPrinciple，LSP）[Liskov]。

Here’s what I mean. Say your business uses external businesses to provide various kinds of services, and you need to model the relationships. You decide to have a common abstract base class ServiceProvider, but for some good reason you need to divide various concrete types of these because the services each provides are both common and yet distinctly different. You might have a WarbleServiceProvider and a WonkleServiceProvider. You design these types such that you can schedule a service request in a generic way:

> 打个比方，你的系统需要使用外部系统提供的各种服务，而你需要处理它们之间的关系。你决定创建一个抽象基类 ServiceProvider。由于每种服务既存在共同之处，又存在不同之处，因此你需要创建多个不同的实际服务类，比如 WarbleServiceProvider 和 WonkleServiceProvider。你希望通过一种通用的方法来访问这些服务：

```java
// client of domain model
serviceProviderRepository.providerOf(id)
        .scheduleService(date, description);
```

With this context, it is clear that the creation of domain-specific Aggregate type hierarchies will probably have limited usefulness in many domains. Here’s why. As demonstrated previously, most times the common Repository will be designed with finder methods that retrieve instances of any of the subclasses. That means that the method will answer instances of the common superclass, in this case a ServiceProvider, not instances of the specific subclasses, WarbleServiceProvider and WonkleServiceProvider. Think of what would happen if finders were designed to return specific types. Clients would have to know which identities or other descriptive attributes of the Aggregates would lead to specific typed instances. Otherwise it could lead to an unmatched find or a ClassCastException when a matched instance of the wrong type is returned. Even if you could design in a good way to find instances of the correct types, clients would also have to know which subclasses could perform specifically different operations, given that the Aggregates could not be entirely designed for LSP.

> 这样看来，在很多情况下，创建特定于领域的聚合类型层级的作用似乎并不大。原因在于：通常来说，资源库所提供的查找方法可以返回任何一个聚合子类的实例。这意味着查找方法所返回的应该是这些聚合子类的共有超类，就像本例中的 ServiceProvider 一样；而不是某个特定的子类，比如 WarbleServiceProvider 或 WonkleServiceProvider。考虑一下，如果查找方法返回了某个特定的子类，情况会怎么样？此时，客户端需要知道什么样的唯一标识（或者其他描述属性）对应着什么样的特定实例。否则，这将导致类型不匹配，或者 ClassCastException 异常。即便你能正确地处理这种情况，由于此时的聚合很有可能并不完全地满足 Liskov 替换原则，你依然需要知道各个子类所提供的特殊操作。

To solve the first problem of segregating types by identity, you might conclude that you could safely detect instances by encoding Aggregate type information as a discriminator in the class of the unique identity. You could do so. But that also leads to two additional problems. The client must take on the responsibility of resolving and mapping identities to types. The other new problem is coupling clients to the distinct operations by type. It leads to this kind of client type dependencies:

> 要解决唯一标识和聚合类型之间的对应问题，你可能会想到通过唯一标识来判断应该返回什么类型的聚合。当然，你可以这么做，但是这同样会导致问题。客户端将负责唯一标识和聚合类型之间的映射。另外，在客户端与特定操作之间也产生了耦合。此时的客户端代码将与以下代码相似：

```java
// client of domain model
if (id.identifiesWarble()) {
    serviceProviderRepository.warbleOf(id)
            .scheduleWarbleService(date, warbleDescription);
} else if (id.identifiesWonkle()) {
    serviceProviderRepository.wonkleOf(id)
            .scheduleWonkleService(date, wonkleDescription);
} ...
```

If this kind of interaction becomes the norm rather than the exception, it indicates a code smell. Granted, if the benefits gained from creating a hierarchy are so great, a rare one-off usage like this may be a worthwhile trade-off. However, in this contrived example a more discerning design of the implied ServiceDescription type and the internal implementation of scheduleService() would probably suffice. Otherwise, I think we’d have to ask if we could gain some benefits from using inheritance while assigning each type a separate Repository. In the case where only two or a few such concrete subclasses are necessary, it may be best to create separate Repositories. When the number of concrete subclasses grows to several or many, most of which can be used completely interchangeably (LSP), it is worthwhile for them to share a common Repository.

> 有时，这种方式并不是有可能产生异常这么简单，它往往意味着一种代码坏味道。诚然，如果你从这样的类型层级中获得了极大的好处，那么这种一次性的使用场景也许是一个很好的折中。然而，对于目前这个并不自然的例子，使用 ServiceDescription 和 scheduleServie（）方法的内部实现似乎已经足够了。请思考：为不同的聚合类型提供单独的资源库究竟给我们带来了什么好处？在聚合子类较少的情况下，为它们使用单独的资源库可能是最好的方式。但是，随着聚合子类数目的增加，而同时它们又具有完全的可互换性时，使用一个共享的资源库便更合适了。

Most of the time, this kind of situation can be completely avoided by designing type descriptive information as a property of the Aggregate (not in the identity). See the discussion about Standard Types under Value Objects (6). This way a single Aggregate type could internally implement different behavior based on an explicitly determined Standard Type. Using an explicit Standard Type, we could have a single concrete ServiceProvider Aggregate and design its scheduleService() to dispatch based on its type. To shield clients from the decisions based on the type we ensure that such is not leaked out to them. Instead, scheduleService() and other ServiceProvider methods properly enclose such domain-specific decisions, as can be seen here:

> 多数情况下，这个问题都可以通过在聚合中维护一个描述属性来彻底解决。请参考值对象（6）中对标准类型的讨论。此时，我们只需要设计单个聚合类型，在其内部通过不同的标准类型来实现不同的行为。在使用显式标准类型的情况下，我们只需要创建一个实际的 ServiceProvider 聚合类，然后在 scheduleService（）方法中根据标准类型来分发服务。同时，我们需要确保这些逻辑不能泄露到客户端中。要达到这样的目的，我们可以在 scheduleService（）方法中包含该领域特定的选择逻辑，比如：

```java
public class ServiceProvider {
    private ServiceType type;
    ...
    public void scheduleService(
            Date aDate,
            ServiceDescription aDescription) {
        if (type.isWarble()) {
            this.scheduleWarbleService(aDate, aDescription);
        } else if (type.isWonkle()) {
            this.scheduleWonkleService(aDate, aDescription);
        } else {
            this.scheduleCommonService(aDate, aDescription);
        }
    }
    ...
}
```

If the internal dispatching becomes messy, we can always design another smaller hierarchy to deal with that. In fact, the Standard Type itself could be designed as a State [Gamma et al.], assuming you like that approach. In that case the various types would implement specialized behavior. This, of course, also means that we’d have a single ServiceProviderRepository, which addresses the desire to store different types in one Repository and use them with common behavior.

> 如果内部的分发逻辑变得凌乱，我们总能通过设计更小的层级予以处理。事实上，如果你喜欢，标准类型本身便可以通过状态模式[Gamma et al.]来实现。在这种情况下，不同的标准类型将实现各自的特有行为。当然，这同样也意味着我们可以设计单个 ServiceProviderRepository 来保存不同类型的标准类型。

The situation could also be sidestepped with the use of role-based interfaces. Here we might have decided to design a SchedulableService interface that multiple Aggregate types would implement. See the discussion about roles and responsibilities under Entities (5). Even if inheritance is used, Aggregate polymorphic behavior can most often be carefully designed such that no special cases are surfaced to clients.

> 另外，我们还可以通过基于角色的接口来解决这个问题。比如，我们可以设计一个 SchedulableService 接口，然后让多个聚合类型都实现该接口。有关角色和职责的讨论，请参考实体（5）。这里，虽然我们也使用了继承，但是由继承所致的多态行为并不会泄漏到客户端中。

## 12.6 REPOSITORY VERSUS DATA ACCESS OBJECT 资源库 vs 数据访问对象（DAO）

Sometimes the idea of a Repository is considered synonymous with Data Access Object, or DAO. Both provide an abstraction over a persistence mechanism. This is true. However, an object-relational mapping tool also provides an abstraction over a persistence mechanism, but it is neither a Repository nor a DAO. Thus, we wouldn’t call just any persistence abstraction a DAO. We must rather determine if the DAO pattern is being implemented.

> 有时，资源库和数据访问对象——即 DAO——被当作同义词看待。它们都提供了对持久化机制的抽象。然而，ORM 工具同样也提供了对持久化机制的抽象，但是它既不是资源库，也不是 DAO。因此，我们不能将所有的持久化抽象都称为 DAO，而是需要确定这种模式是否得到了真正的实现。

I think there are generally differences between Repositories and DAOs. Basically, a DAO is expressed in terms of database tables, providing CRUD interfaces to them. Martin Fowler in [Fowler, P of EAA] separates the uses of DAO-like facilities from those that are used with a domain model. He identifies Table Module, Table Data Gateway, and Active Record as patterns that would typically be used in a Transaction Script application. That’s because DAO and related patterns tend to serve as wrappers around database tables. On the other hand, Repository and Data Mapper, having object affinity, are typically the patterns that would be used with a domain model.

> 资源库和 DAO 是不同的。一个 DAO 主要从数据库表的角度来看待问题，并且提供 CRUD 操作。Martin Fowler 在[Fowler，P of EAA]中将 DAO 相关设施与领域模型分离开来对待。他指出，诸如表模块（Table Module）、表数据网关（TableData Gateway）和活动记录（Active Record）这样的模式应该用于事务脚本程序中。这是因为，这些与 DAO 相关的模式通常只是对数据库表的一层封装。而另一方面，资源库和数据映射器（Data Mapper）则更加偏向于对象，因此通常被用于领域模型中。

Since you can use DAO and related patterns to perform fine-grained CRUD operations on data that would otherwise be considered parts of an Aggregate, this would be a pattern to avoid with a domain model. Under normal conditions you want the Aggregate itself to manage its business logic and other internals and keep everyone else out.

> 在 DAO 模式中所执行的 CRUD 操作都是可以放在聚合中来实现的，因此，我们应该尽量避免在领域模型中使用这些 DAO 模式。在正常情况下，我们总是希望由聚合本身来管理业务逻辑。

I did indicate previously that at times a stored procedure or a data grid entry processor is essential to meet some demanding nonfunctional requirement. Depending on your domain, this may be more the rule than the exception. If a system nonfunctional requirement is not driving this, however, I suggest that you should avoid it. Housing and executing business logic in the data store many times runs orthogonal to DDD. I would conclude that the use of a Data Fabric Function/Entry Processor is not really disruptive to the goals of domain modeling. The Function/Entry Processor implementation would be written in Java, for example, and would adhere to the Ubiquitous Language (1) and goals of the domain. The only difference from the core model is where the Function/Entry Processor is executed, which is not disruptive. On the other hand, prolific use of stored procedures is potentially very disruptive to DDD because the programming language is generally not well understood by the modeling team and implementations are generally “safely” tucked away from their view. If so, that is exactly the opposite of what DDD is trying to accomplish.

> 在前文中，我的确也说过，在有些情况下可以使用存储过程或数据网格的条目处理器来完成一些非功能性的操作。根据你所工作的领域，这更像是一种规则，而不是例外。但是，如果不存在这样的的非功能性需求，那么我建议你不要使用它们。更多的时候，在数据存储中放置以及执行业务逻辑是与 DDD 背道而驰的。当然，我得说，使用数据网织函数/条目处理器并不会真正地分裂领域建模的目标。比如，它们也是可以通过 Java 来实现的，并且能够表达通用语言（1），同时满足领域建模的目标。它们与核心模型唯一的不同在于执行场所的不同，而这并不具有分裂性。而另一方面，大量地使用存储过程则是具有分裂性的了，因为此时，建模团队并不能很好地理解存储过程所使用的语言。此外，通常来说它们也看不到存储过程的实现，而这些正是有悖于 DDD 目标的。

You may choose to think of a Repository as a DAO in a general sense. The primary thing to keep in mind is that as much as possible you should try to design your Repositories with a collection orientation rather than a data access orientation. That will help keep you focused on the domain as a model rather than on data and any CRUD operations that may be used behind the scenes to manage its persistence.

> 通常来说，你可以将资源库当作 DAO 来看待。但是请注意一点，在设计资源库时，我们应该采用面向集合的方式，而不是面向数据访问的方式。这有助于你将自己的领域当作模型来看待，而不是 CRUD 操作。

## 12.7 TESTING REPOSITORIES 测试资源库

There are two ways to look at testing Repositories. You have to test the Repositories themselves in order to prove that they work correctly. You also must test code that uses Repositories to store the Aggregates that they create and to find preexisting ones. For the first kind of test you must use the full production-quality implementations. Otherwise you won’t know if your production code will work. For the second kind of test, either you can use your production implementations, or you can use in-memory implementations instead. I discuss the production implementation tests now and defer the in-memory tests to just a bit later.

> 我们可以从两个方面对资源库进行测试。首先，我们需要测试资源库本身是能正确工作的。其次，我们还要测试对资源库的使用，以保证能够正确地保存和获取聚合实例。对于前者，我们必须使用产品环境下的资源库实现。对于后者，我们既可以使用产品实现，也可以使用内存实现。接下来，我将首先讨论前一种测试，然后再讨论后一种。

Let’s take a look at the tests for the Coherence implementation of the Prod-uctRepository presented previously:

> 让我们看看以 Coherence 实现的 ProductRepository：

```java
public class CoherenceProductRepositoryTest extends DomainTest {
    private ProductRepository productRepository;
    private TenantId tenantId;

    public CoherenceProductRepositoryTest() {
        super();
    }
    ...
    @Override
    protected void setUp() throws Exception {
        this.setProductRepository(new CoherenceProductRepository());
        this.tenantId = new TenantId("01234567");
        super.setUp();
    }

    @Override
    protected void tearDown() throws Exception {
        Collection<Product> products =
            this.productRepository()
                    .allProductsOfTenant(tenantId);
        this.productRepository().removeAll(products);
    }

    protected ProductRepository productRepository() {
        return this.productRepository;
    }

    protected void setProductRepository(
            ProductRepository aProductRepository) {
        this.productRepository = aProductRepository;
    }
}
```

There are some general setup and tear-down operations to prepare for and clean up after each test. To set up we create an instance of class Coherence-ProductRepository and then create a fake instance of TenantId.

> 对于每一个测试，我们都需要事先做一些准备，测试完毕之后再做一些清理工作。在准备时，我们创建了一个 CoherenceProductRepository，然后创建一个假的 TenantId 实例。

To tear down we remove all Product instances that may have been added to the backing cache by each test. For Coherence this is an important cleanup step. If you don’t remove all cached instances, they will remain during subsequent tests, which may cause failure for certain assertions such as persisted instance counts.

> 在清理时，我们从缓存中移除掉所有的 Product 实例，这些实例是在测试过程中加入缓存的。对于 Coherence 来说，这是非常重要的一步。否则，这些 Product 实例将在余下的测试中继续存在，从而有可能导致余下测试的断言失败，比如计算实例数目。

Next, we test the Repository behavior:

> 然后，我们开始测试资源库的行为：

```java
public class CoherenceProductRepositoryTest extends DomainTest {
    ...
    public void testSaveAndFindOneProduct() throws Exception {
        Product product =
            new Product(
                    tenantId,
                    this.productRepository().nextIdentity(),
                    "My Product",
                    "This is the description of my product.");
        this.productRepository().save(product);
        Product readProduct =
            this.productRepository()
                .productOfId(tenantId, product.productId());
        assertNotNull(readProduct);
        assertEquals(readProduct.tenantId(), tenantId);
        assertEquals(readProduct.productId(), product.productId());
        assertEquals(readProduct.name(), product.name());
        assertEquals(readProduct.description(), product.description());
    }
    ...
}
```

As the test method name states, here we save a single Product and attempt to find it. The first task is to instantiate a Product and then save it to the Repository. If no exception is thrown by the infrastructure, we may think that the Product was correctly saved. However, there is only one way to know for certain. We have to find the instance and compare it to the original. To find the instance we pass its globally unique identity to method productOfId(). If the instance was found, we can successfully assert that it is not null, that its tenantId is the same, its productId is the same, its name is the same, and its description is the same as the one that was stored.

> 正如测试方法名所表示的，这里我们先保存一个 Product 实例，然后再对其进行查找。首先，我们需要实例化一个 Product 并将其保存到资源库中。在没有发生异常的情况下，我们便可以认为保存操作执行成功。但是，要确认这一点，我们只有通过一种方式，即从资源库中找到该实例，再将其与原来的 Product 实例进行比较。我们通过调用 productOfId（）方法来查找一个 Product 实例，该方法接受一个 Product 的唯一标识作为参数。之后，我们先检查所返回的 Product 实例是否为 null。如果不是，再将该 Product 实例的 tenantId、productId、name 和 descirption 属性分别与原有 Product 中相对应的属性进行比较。

Next, we test saving and finding multiple instances:

> 接下来，我们测试对多个聚合实例的保存和查找：

```java
public class CoherenceProductRepositoryTest extends DomainTest {
    ...
    public void testSaveAndFindMultipleProducts() throws Exception {
        Product product1 =
            new Product(
                    tenantId,
                    this.productRepository().nextIdentity(),
                    "My Product 1",
                    "This is the description of my first product.");
        Product product2 =
            new Product(
                    tenantId,
                    this.productRepository().nextIdentity(),
                    "My Product 2",
                    "This is the description of my second product.");
        Product product3 =
            new Product(
                    tenantId,
                    this.productRepository().nextIdentity(),
                    "My Product 3",
                    "This is the description of my third product.");
        this.productRepository()
            .saveAll(Arrays.asList(product1, product2, product3));
        assertNotNull(this.productRepository()
            .productOfId(tenant, product1.productId()));
        assertNotNull(this.productRepository()
            .productOfId(tenant, product2.productId()));
        assertNotNull(this.productRepository()
            .productOfId(tenant, product3.productId()));

        Collection<Product> allProducts =
            this.productRepository().allProductsOfTenant(tenant);
        assertEquals(allProducts.size(), 3);
    }
    ...
}
```

First we instantiate three Product instances and then save them at once using saveAll(). Next, we again use productOfId() to find individual instances. If all three instances are not null, we are convinced that all three instances were correctly persisted.

> 在上例中，我们首先实例化 3 个 Product 实例，然后调用 saveAll（）方法一次性地将它们保存到资源库中。之后，我们依然通过 productOfId（）方法来分别查找单个实例，如果资源库所返回的 3 个实例都不为 null，那么我们便可以认为对这 3 个 Product 实例的持久化都是正确的。

Cowboy Logic 牛仔的逻辑

AJ: “My sister told me her husband asked her to sell all the stuff in his storage unit when he dies. My sister asked him why. He said he didn’t want some jerk to have his stuff when she remarries. She told him not to worry since she wasn’t going to marry another jerk.”

> AJ：“我姐姐告诉我，她的丈夫给她说：‘在我死后，记得将我保存的所有东西都卖掉。’我姐问他为什么。他说：‘我不想在你再婚之后，这些东西落到一个懦夫的手中。’我姐告诉她说：‘不要担心，我不会再嫁给另一个懦夫的。’”

Image

There is one Repository method, allProductsOfTenant(), that has not yet been tested. Given that the Repository cache was completely empty when the test started, we should be able to successfully read three Product instances from it. So we attempt to find all of them. The returned Collection should never be null, even if you don’t find what you expected. So the last step in the test is to assert that the full number of expected Product instances, or three, was in fact found.

> 资源库中还有一个方法没有被测试到，即 allProductsOfTenant（）方法。在资源库的缓存已完全清空的情况下，在测试执行时，我们应该能够成功地读取这 3 个 Product 实例。因此，所返回的 Collection 便不应该为 null，即便其中的内容并不是你所期望的。这样一来，测试的最后一步便是判断所返回实例的数目，我们断言此时的数目应该为 3。

Now that we have a test that demonstrates how clients can use the Repository and proves its correctness, we can look at how you can more optimally test clients that use Repositories.

> 现在，我们已经有一个测试来展示客户端对资源库的使用，接下来我们将以更加优化的方式来测试客户端对资源库的使用。

### 12.7.1 Testing with In-Memory Implementations 以内存实现进行测试

If it is very difficult to set up the full persistent implementation of a Repository for test, or too slow to use it, you can leverage another approach. You may also face undesirable conditions early on during domain modeling, perhaps when your persistence mechanisms, including the database schema, are not yet available. When you face any of these situations, it works best to implement an in-memory edition of Repositories.

> 对于准备一个完整的资源库实现来说，如果存在困难，或者速度太慢，那么我们可以考虑使用另一种方式。另外，在领域建模早期，你也有可能面临一些麻烦，比如持久化机制并不可用，或者数据库的 Schema 还未准备好等。此时，我们便可以使用一个内存版本的资源库。

Creating in-memory editions can be quite simple, but it may also pose some challenges. The simple part is creating a HashMap to back your interface. It is straightforward to put() entries to and remove() them from the Map. We just use the globally unique identity of each Aggregate instance as the key. The Aggregate instance itself serves as the value. The add() or save() methods and the remove() methods are quite trivial. In fact, in the case of the Prod-uctRepository the entire implementation is fairly simple:

> 创建内存资源库可以是非常简单的，但同时也存在一些挑战。说它是简单的，是因为我们可以用一个 HashMap 来实现资源库。对于一个 Map 来说，调用 put（）和 remove（）方法都是非常直接的。我们只需要将全局的唯一标识作为每个聚合的键，而将聚合实例作为相应的值。事实上，在这种情况下，整个 ProductRepository 的实现都是简单的：

```java
package com.saasovation.agilepm.domain.model.product.impl;

public class InMemoryProductRepository implements ProductRepository {
    private Map<ProductId,Product> store;

    public InMemoryProductRepository() {
        super();
        this.store = new HashMap<ProductId,Product>();
    }

    @Override
    public Collection<Product> allProductsOfTenant(Tenant aTenant) {
        Set<Product> entries = new HashSet<Product>();
        for (Product product : this.store.values()) {
            if (product.tenant().equals(aTenant)) {
                entries.add(product);
            }
        }
        return entries;
    }

    @Override
    public ProductId nextIdentity() {
        return new ProductId(java.util.UUID.randomUUID()
                .toString().toUpperCase());
    }

    @Override
    public Product productOfId(Tenant aTenant, ProductId aProductId) {
        Product product = this.store.get(aProductId);
        if (product != null) {
            if (!product.tenant().equals(aTenant)) {
                product = null;
            }
        }
        return product;
    }

    @Override
    public void remove(Product aProduct) {
        this.store.remove(aProduct.productId());
    }

    @Override
    public void removeAll(Collection<Product> aProductCollection) {
        for (Product product : aProductCollection) {
            this.remove(product);
        }
    }

    @Override
    public void save(Product aProduct) {
        this.store.put(aProduct.productId(), aProduct);
    }

    @Override
    public void saveAll(Collection<Product> aProductCollection) {
        for (Product product : aProductCollection) {
            this.save(product);
        }
    }
}
```

There is actually only a single special case for productOfId(). To correctly implement this finder, after getting a matching Product by the given ProductId, we must also check that the TenantId of the Product matches the Tenant parameter. If it doesn’t, we set the Product instance to null.

> 对于 productOfId（）方法来说，我们需要稍微注意一下。要正确地实现该查找方法，在通过 ProductId 获取到 Product 实例时，我们必须检查该 Product 的 TenantId 与传入的 aTenant 参数是否相同，如果不同，我们将返回 null。

We can actually make a near-identical copy of CoherenceProductRepositoryTest named InMemoryProductRepositoryTest to test this in-memory implementation. The only change that needs to be made is in setUp():

> 我们几乎可以原封不动地将 CoherenceProductRepositoryTest 复制成 InMemoryProductRepositoryTest，唯一的区别只是在于 setUp（）方法：

```java
public class InMemoryProductRepositoryTest extends TestCase {
    ...
    @Override
    protected void setUp() throws Exception {
        this.setProductRepository(new InMemoryProductRepository());
        this.tenantId = new TenantId("01234567");
        super.setUp();
    }
    ...
}
```

Just instantiate InMemoryProductRepository rather than the Coherence implementation. Other than that the test methods themselves are identical.

> 这里，在 setUp（）方法中，我们实例化了一个 InMemoryProductRepository，而不是 CoherenceProductRepository。除此之外，其他的测试方法都是一样的。

The possible difficult challenges are generally related to implementing more advanced finders, where parameter criteria are complex to resolve. If the criteria and resolution logic becomes too complex, you may have to find a way to work around the situation. It might mean prepopulating the Repository with instances that will resolve the search while making the finder method itself return only the instance or instances that are prepopulated. You can prepopulate using the test’s setUp() method.

> 对于内存资源库来说，有可能存在的挑战在于实现更加复杂的查找方法，此时所传入的查询参数将更难处理。在这种情况下，你可能需要谋求另外的解决方法。比如，在 setUp（）方法中，我们可以预先向资源库中存放一些满足查询条件的聚合实例，然后让查找方法只返回这些实例。

Another advantage to implementing in-memory editions of your Repositories is when you need to test for proper uses of save() with a persistence-oriented interface. You can implement the save() methods to count invocations. After each test is run, you can assert that the invocation count matches the number required by the client of the specific Repository. Generally, you could use this approach when testing Application Services that must explicitly save() changes to an Aggregate.

> 内存资源库的另一个好处在于：当你需要测试面向持久化资源库接口的 save（）方法时，你可以在 save（）方法中计算对其本身的调用次数。在每次测试执行完后，你可以验证资源库中的 save（）方法调用次数和客户端所需要的调用次数是相等的。例如，对于一个必须显式调用 save（）方法的应用服务来说，我们便可以采用这种方法。

Image

## 12.8 WRAP-UP 本章小结

In this chapter we looked in depth at implementing Repositories.

> 在本章中，我们深入地学习了如何实现资源库。

- You learned about collection-oriented and persistence-oriented Repositories, and why to use one or the other.
- You saw how to implement Repositories for Hibernate, TopLink, Coherence, and MongoDB.
- You investigated why you might need additional behavior on a Repository’s interface.
- You considered how transactions play into the use of Repositories.
- You are now familiar with the challenges of designing Repositories for type hierarchies.
- You looked at some fundamental differences between Repositories and Data Access Objects.
- You saw how to test Repositories and different ways to test using Repositories.

---

> - 你学习了面向集合和面向持久化的资源库，以及对它们的选取。
> - 你学到了如何通过 Hibernate、TopLink、Coherence 和 MongoDB 来实现资源库。
> - 你学到了为什么需要为资源库接口添加额外的行为。
> - 你学到了在使用资源库时，如何管理事务。
> - 你学到了为类型层级设计资源库时所面临的挑战。
> - 你学到了资源库与 DAO 的基本区别。
> - 你学到了如何测试资源库本身，以及如何测试对资源库的使用。

Next, we’ll shift gears and take a careful look at integrating Bounded Contexts.

> 接下来，我们将学习集成限界上下文。
