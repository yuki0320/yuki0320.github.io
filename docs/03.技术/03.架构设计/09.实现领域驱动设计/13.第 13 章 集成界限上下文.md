---
title: 第 13 章 集成界限上下文
date: 2021-01-07 16:25:13
permalink: /pages/6818f8/
categories:
  - 技术
  - 技术文档
  - 实现领域驱动设计
tags:
  - 
---
# 第 13 章 集成界限上下文

Making mental connections is our most crucial learning tool, the essence of human intelligence; to forge links; to go beyond the given; to see patterns, relationships, context.

> 心智连接是我们最重要的学习工具，它是人类智力的本质所在，它帮助我们弥补先天不足，它启发我们看清模式、关系和上下文环境。

——Marilyn Ferguson

There are always multiple Bounded Contexts (2) in any project of significance, and two or more of those Bounded Contexts will need to integrate. Using Context Maps (3), we discussed the relationships that commonly exist between Bounded Contexts, and we examined some ways that those relationships can be managed correctly according to the principles of DDD. If you don’t have a fairly strong grasp of Domains (2), Subdomains (2), and Bounded Contexts, or of Context Maps, you should obtain that before continuing. The material presented here builds on those fundamental concepts.

> 一个项目中通常存在着多个限界上下文（2），并且我们需要在它们之间进行集成。在上下文映射图（3）中，我们讨论了限界上下文之间的常见关系，并且讨论到了如何通过 DDD 的原则来正确处理它们之间的关系。如果你对领域（2）、子域（2）和限界上下文还不甚了解，那么请重温本书相关章节，因为本章所讲的都是建立在那些基本概念之上的。

As previously discussed, Context Maps have two primary forms. One form is a simple drawing that is used to illustrate the kinds of relationships that exist between any two or more Bounded Contexts. The second and far more concrete form is the code that actually implements those relationships. That’s what we are considering now.

> 在本书前面我们已经讨论到，上下文映射图存在两种主要形式。一种是通过绘制一些简单的框图来展示它们之间的集成关系；另一种则是通过代码来实现这些集成关系。在本章中，我们主要讨论第二种形式。

Road Map to This Chapter 本章学习路线图

- Review some of the basics of integration, and develop the proper mindset necessary to succeed in integrating systems in a distributed computing environment.
- See how you can approach integration using RESTful resources, and consider some of its advantages and disadvantages.
- Learn how to integrate when using messaging.
- Understand the challenges you will face when you decide to duplicate information across Bounded Contexts.
- Study examples that provide increasing maturity in design approaches.

---

> - 温习有关集成限界上下文的基础知识。
> - 学习通过 REST 资源的方式来集成限界上下文，以及这种方式的优缺点。
> - 学习使用消息来集成限界上下文。
> - 学习在不同限界上下文中维护重复信息时所面临的挑战。
> - 通过示例进一步掌握集成限界上下文的设计方法。

## 13.1 INTEGRATION BASICS 集成基础知识

When two Bounded Contexts need to integrate, there are a few reasonably straightforward ways this can be done in code.

> 有多种直接的方式可以完成限界上下文之间的集成。

One such straightforward approach is for a Bounded Context to expose an application programming interface (API), and another Bounded Context to use that API via remote procedure calls (RPCs). The API could be made available using SOAP or simply support sending XML requests and responses over HTTP (not the same as REST). Actually, there are several ways to create a remotely accessible API. This is one of the more popular ways to integrate, and since it supports a procedure call style, it is easily understood by programmers used to calling procedures or methods. That’s pretty much all of us.

> 其中一种便是在一个限界上下文中暴露应用程序编程接口（API），然后在另一个限界上下文中通过远程过程调用（RPC）的方式访问该 API。此时的 API 可以通过 SOAP 协议暴露给其他限界上下文，也可以直接在 HTTP 中使用 XML（这种方式与 REST 不同）。事实上，我们有多种方式创建这样的远程 API，SOAP 只是其中最流行的方式之一，因为它支持过程调用的风格，这是我们程序员能够非常容易理解的。

A second straightforward way to integrate Bounded Contexts is through the use of a messaging mechanism. Each of the systems that need to interact do so through the use of a message queue or a Publish-Subscribe [Gamma et al.] mechanism. Of course, these messaging gateways can well be thought of as an API, but we may find broader acceptance if we simply refer to them as service interfaces instead. There are a large number of integration techniques that may be employed when using messaging, many of them discussed in [Hohpe & Woolf].

> 另一种直接的集成方式便是使用消息机制。在消息机制中，每一个需要交互的系统都使用消息队列或者发布-订阅[Gamma et al.]机制。当然，我们同样可以将消息看作是某种形式的 API，但是更好的方式是将消息机制看成是一种服务接口。有大量的技术都支持通过消息来集成限界上下文，详情请参考[Hohpe & Woolf]。

A third way to integrate Bounded Contexts is by using RESTful HTTP. Some think of this as a kind of RPC approach, but it really is not. It has some similar properties in that one system makes a request of another system, but these requests are not made using procedures that take parameters. As discussed in Architecture (4), REST is a means of exchanging and modifying resources that are uniquely identified using a distinct URI. Various operations can be performed on each resource. RESTful HTTP provides methods, primarily GET, PUT, POST, and DELETE. Even though these may seem to support only CRUD operations, using a little imagination allows us to actually categorize operations with explicit intent within one of the four method categories. For example, GET can be used to categorize various kinds of query operations, and PUT can be used to encapsulate a command operation that executes on an Aggregate (10).

> 第三种集成限界上下文的方式是使用 RESTful HTTP。有人认为 REST 也是某种形式的 RPC，其实并非如此。诚然，REST 和 RPC 的确存在相似之处，比如它们都是从一个系统向另一个系统发出请求的。但是，在 REST 的请求中并不包含过程调用中的参数。在架构（4）中我们已经讲到，REST 用于交换和更改资源，这些资源通过 URI 的方式进行定位，每种资源的 URI 都是唯一的。在每种资源上，我们可以执行不同种类的操作。RESTful HTTP 提供了一些方法，比如 GET、PUT 和 DELETE。虽然从表面上看，这些方法只支持 CRUD 操作，但是如果多思考一下你便知道，我们可以通过这 4 个方法的意图对不同的操作进行分类。比如，GET 方法可以包含不同类型的查询操作，而 PUT 方法则用于聚合（10）上的命令操作。

Of course, this in no way means that there are only three ways to integrate applications. You can, for example, use file-based integration and shared-database integration, but doing so could make you old before your time.

> 当然，以上并不意味着只存在三种集成限界上下文的方法。你还可以通过共享文件和数据库的方式进行集成，但是此时我只能说，你也太不与时俱进了。

Cowboy Logic 牛仔的逻辑

AJ: “You better take a low seat in your saddle. That horse is a tough one and it’ll make you feel old before your time.”

> AJ：“在马鞍上你最好坐得低一点，那匹马不好对付。要驯服它，你得与时俱进才行。”

Image

Although I’ve highlighted three common ways that are used to integrate Bounded Contexts, we’ll actually stick with just two of those in this chapter. We will mostly focus on integrating with messaging mechanisms but will see how to use RESTful HTTP as well. We’ll avoid examples using RPC because you can easily imagine creating procedural APIs that could be used to replace the other two approaches. Also, RPC has less resilience when our goal is to support autonomous services (aka autonomous applications). A failed system that would normally provide an RPC-based API will prevent dependent systems from succeeding in their own operations.

> 虽然上面我提到了三种主要的集成限界上下文的方式，但是在本章中，我只会讨论到其中的两种。我将重点讲解通过消息机制来集成限界上下文，另外就是使用 RESTful HTTP 的方式。对于 RPC 来说，通过简单地创建过程式的 API，我们也能达到前两种方式的集成效果。另外，当我们需要支持自治性服务（即自治性应用程序）时，RPC 便没有这么好的适应性了。此时，如果 RPC 的提供方失效，那么客户方的调用也将失败。

This brings up a topic of vital importance, which requires the attention of every integration developer.

> 这将引出一个极其重要的话题，对于每一个做集成的开发人员来说，这都是值得注意的。

### 13.1.1 Distributed Systems Are Fundamentally Different 分布式系统之间存在根本性区别

Problems always arise with integration when developers who are unfamiliar with the principles of distributed systems gloss over its inherent complexity. This can be especially true when using RPC, because those inexperienced with distribution commonly imagine that any one remote call is as good as an in-process call. Such assumptions can cause cascading failure across any number of systems when just one system or one of its components becomes unavailable, even temporarily so. Thus, all developers working within distributed systems will succeed or fail by the following Principles of Distributed Computing:

> 对于那些不熟悉分布式系统原则的开发者来说，他们经常容易忽略掉分布式系统的内在复杂性，此时，问题也就接踵而至了。特别是对于 RPC 来说，没有分布式开发经验的人总认为远程过程调用和进程内调用是一样的。在这样的假设下，他们经常会面临犹如多米诺骨牌似的系统失败，因为任何一个系统组件的失败都将导致级联反应，从而使其他系统也跟着失败。因此，任何一个分布式开发者都应该知道以下分布式计算原则：

- The network is not reliable.
- There is always some latency, and maybe a lot.
- Bandwidth is not infinite.
- Do not assume that the network is secure.
- Network topology changes.
- Knowledge and policies are spread across multiple administrators.
- Network transport has cost.
- The network is heterogeneous.

---

> - 网络是不可靠的。
> - 总会存在时间延迟，有时甚至非常严重。
> - 带宽是有限的。
> - 不要假设网络是安全的。
> - 网络拓扑结构将发生变化。
> - 知识和政策在多个管理员之间传播。
> - 网络传输是有成本的。
> - 网络是异构的。

These are purposely stated differently from the “Fallacies of Distributed Computing” [Deutsch]. I call them principles to emphasize the challenges that must be worked around and complexities that must be planned for, rather than the mistakes commonly made by the naive.

> 与“Fallacies of Distributed Computing”[Deutsch]相比，我故意更改了说法。我将它们称为原则，是为了强调分布式系统的复杂性及其所面临的挑战，而不是单单罗列一些常见的错误。

### 13.1.2 Exchanging Information across System Boundaries 跨系统边界交换信息

Most of the time when we need a foreign system to provide a service for our own system, we need to pass informational data to the service. The services we use sometimes need to provide responses. Thus, we need a reliable way to pass informational data between systems. This data needs to be exchanged between disparate systems in a structure that is easily consumed by all involved. Most of us would choose to use some standard way to do that.

> 多数时候，我们都需要一个外部系统为我们自己的系统提供服务，此时我们会向该服务传递一些信息数据，同时外部服务还有可能返回数据。因此，我们需要一种可靠的方式在两个系统之间传递这些信息数据。所传信息数据的结构应该能被所有的系统所消费。要达到这样的目的，大多数人都会选择一些标准的信息数据结构。

Informational data sent as parameters or messages constitutes just machine-readable structures that can be generated in one of many formats. We must also create some form of contract between the data-exchanging systems, and possibly even the mechanisms to parse or interpret those structures, so they can be consumed.

> 以参数或消息的形式传送的信息数据只是一些机器能读懂的数据结构，它可以生成多种数据格式。在交互的系统之间，我们需要创建某种形式的契约，甚至创建能够解析和翻译这些数据结构的机制，以使这些数据能够被正确地消费。

There are several ways to generate the structures used to exchange information between systems. One technical implementation simply relies on the programming language facilities to serialize objects into a binary format and deserialize them on the consumer’s side. This works well as long as all systems support the same language facilities, and if the serialization is actually compatible or interchangeable between disparate hardware architectures. It also requires you to deploy all the interfaces and classes of objects that are used across systems to each system that uses the specific object type.

> 有多种方式都可以生成信息数据的结构，比如 XML、JSON，或者像协议缓存这样的特殊格式。每一种方式都有各自的优缺点，其中的影响因素包括丰富性、紧凑性、类型转换的性能、对象转换的灵活性和易用性等。在考虑到分布式计算原则时，比如“网络传输是有成本的”，有些方式的成本可能是非常昂贵的。

Another approach to building exchangeable information structures is to use some standard intermediate format. Some options are to use XML, JSON, or a specialized format such as Protocol Buffers. Each of these approaches has advantages and disadvantages, some of which include richness and compactness factors, performance of type conversions, support for flexibility between object versions, and ease of use. Some of these can have costly impacts when considering the Principles of Distributed Computing listed earlier (for example, “Network transport has cost”).

Using this intermediate format approach, you may still desire to deploy all the interfaces and classes of objects that are used across systems, and use a tool to place the data of the intermediate format into your type-safe objects. This has the advantage that you can use objects the same way in the consuming system as you would in the source system.

> 在使用这些中间格式时，我们都希望将所有的接口和类部署到所有的系统中，然后使用工具将这些中间格式的数据转化成类型安全的对象。这种方式的优点在于，消费系统和源系统都是通过相同的方式来使用这些对象的。

Of course, deploying these interfaces and classes also has related complexity, and it typically means that the consuming system will need to be recompiled to maintain compatibility with the latest versions of interface and class definitions. There is also the danger of using the foreign objects freely in the consuming system as if they were our very own, which would tend to violate the very DDD strategic design principles we have been fighting so hard to follow. Some may think that by declaring this as a Shared Kernel (3), it indemnifies the approach. However, be aware that the convenience of objects that are shared between systems can lead you down a slippery slope. Yet, regardless of the complexity and potential danger of polluted models, many believe that any strong typing afforded by this tactic is a suitable trade-off for the required complexity.

> 当然，部署这些接口和类也是存在复杂性的；同时这种方式还意味着，如果出现了新版本的接口和类定义，那么消费方系统需要重新编译以保证与源系统的兼容性。此外，将外部对象直接当作本地对象来使用也是存在危险的，而这也违背了 DDD 的战略设计原则。有人认为，此时可以使用一个共享内核（3）。然而，当在系统间共享对象时，由于对这些对象的访问过于方便，你很有可能适得其反。无论如何，在不考虑复杂性和潜在危险性的情况下，在这种方式中使用任何强类型对象都是一种很好的折中。

Still, I encounter those who struggle with this for various reasons, and they often wish for an easier and safer approach, but one that doesn’t entirely discard type safety. Let’s consider such an approach.

> 此外，我还遇到过很多正挣扎于此的人，他们希望有一种更简单、更安全的方式，而同时又不完全地损失类型安全性。让我们看看这样一种方式。

What if we could define a contract between the systems that produce the exchangeable information structures and those that consume them in such a way that the consumers could confidently use the data without deserializing it into object instances of specific classes? We can define such a reliable contract using a standards-based approach, which actually forms a Published Language (3). One such standard approach is to define a custom media type, or the semantic equivalent. Whether or not you have good reason to register such a media type using the guidelines from RFC 4288, it is the actual specification that matters. The specification defines the binding contract between producers and consumers and offers a foolproof means to exchange such media without sharing the interface and class binaries.

> 我们可以设计一种契约，该契约用于在不同系统之间创建可交换的信息结构，而消费方在使用这些信息数据时，它并不用将这些数据反序列化成某种类型的对象实例。我们可以用一种标准的方式来定义这样的契约，此时的契约便是某种形式的发布语言（3）。其中一种标准方式便是自定义一种媒体类型。无论你是否会根据 RFC 4288 来注册这样的媒体类型，这里重要的是这种媒体类型所体现出的规范。该规范定义了生产方和消费方之间的绑定契约，在这种契约的框架下，双方系统不需要共享接口和类。

This does require some trade-offs, as always. You will not be able to navigate using property accessors as you would if you had the interfaces/classes for each object, and with associated type safety. You would also lack some IDE support, such as the ability to use code completion. This isn’t really a big disadvantage. Further, you would have no operational function/method support that having the Event class could provide. However, I do not see the lack of Event operational functions/methods as a disadvantage, but rather as a protection. The consuming Bounded Context should be interested only in the data properties and should never be tempted to use functionality that is part of a different model. The consumer’s Port Adapters (4) should shield its domain model from any such dependencies and must instead pass needed Event data as appropriate parameters with types as defined only in its own Bounded Context. Any necessary calculations or processing should be performed by the producing Bounded Context and provided as enriching Event data attributes.

> 当然，这种方式也不是尽善尽美的。你将无法像接口/类一样在对象上使用属性访问器，同时你也得不到 IDE 的支持，比如代码自动补全等功能。这些都并不是什么大的缺点。此外，你将无法获得在有事件类时的一些函数/方法操作。但是，我并不认为这是一个缺点，它反而可以作为一种保护措施。作为消费方的限界上下文需要关心的只应该是数据属性，而不是外部模型所提供的功能。消费方中的端口适配器（4）应该将自己的领域模型与外部模型隔离开来，同时所传入的事件数据必须遵循本地限界上下文中的类型定义。任何计算和处理过程都应该在生产方限界上下文中完成，然后向消费方提供足够的事件数据。

Consider an example. SaaSOvation needs to exchange media between its various Bounded Contexts. It will do so using RESTful resources and by sending messages containing Events (8) between services. In fact, one kind of RESTful resource is a notification, and Event-based messages are also sent to subscribers as Notification objects. In other words, in both cases the Notification holds an Event, and the two are formatted into a single structure. The custom media type specification for notifications and Events could indicate a contract that includes

> 举个例子，SaaSOvation 公司需要在不同的限界上下文中交换数据。他们可以使用 REST 资源的方式，也可以在不同的服务系统之间发送含有事件（8）的消息。REST 资源的其中一种表现形式称为通知（notification），而基于事件的消息也是通过 Notification 对象的形式发送给订阅方的。换句话讲，在两种情况下都由 Notification 持有事件，而这两者将被格式化成单一的结构。此时，为通知和事件创建的自定义的媒体类型规范将含有以下契约：

- Type: Notification format: JSON
- notificationId: long integer unique identity
- typeName: text String type of notification, an example type name being com.saasovation.agilepm.domain.model.product.↵backlogItem.BacklogItemCommitted
- version: integer version of the notification
- occurredOn: date/time when the notification’s contained Event happened
- event: JSON payload details; see specific Event types

---

> - 类型：Notification 格式：JSON
> - notificationId：长整型唯一标识
> - typeName：Notification 的类型名，比如 com.saasovation.agilepm.domain.model.product.backlogItem.BacklogItemCommitted
> - version：Notification 的版本，整型数
> - occurredOn：Notification 包含的事件所发生的日期/时间
> - event：JSON 格式的事件数据，请参考具体的事件类型

Using the fully qualified class name (package name included) for the typeName allows subscribers to precisely differentiate various Notification types. The notification specification would be followed by the various Event type specifications. For one example, consider a familiar Event named BacklogItemCommitted:

> 对 typeName 使用全类名（包含包名）使得订阅方能够精确地区分不同的 Notification 类型。紧跟着该 Notification 规范的应该是不同类型的事件类型规范。比如，对于 BacklogItemCommitted 事件，它的类型规范如下：

- Event type: com.saasovation.agilepm.domain.model.product.↵backlogItem.BacklogItemCommitted
- eventVersion: integer version of the Event, which is the same as the Notification version
- occurredOn: date/time when the Event occurred, which is the same as Notification occurredOn
- backlogItemId: BacklogItemId, which contains the id text string attribute
- committedToSprintId: SprintId, which contains the id text string attribute
- tenantId: TenantId, which contains the id text string attribute
- Event details: see specific Event types

---

> - 事件类型：com.saasovation.agilepm.domain.model.product.backlogItem.BacklogItemCommitted
> - eventVersion：事件的版本号，以整型数表示，与 Notification 的 version 相同
> - occurredOn：事件发生的日期/时间，与 Notification 的 occuredOn 相同
> - backlogItemId：BacklogItemId，以字符串表示
> - committedToSprintId：SpringId，以字符串表示
> - tenantId：TenantId，包含了字符串形式的 id 属性
> - 事件细节：请参考具体的事件类型

We would, of course, specify the Event details for every Event type. With the Notification and all Event types specified, we can safely use a NotificationReader as demonstrated by this test:

> 当然，我们还可以为每一种事件类型提供事件细节。有了 Notification 和所有的事件类型，我们便可以安全地使用一个 NotificationReader 来读取某个通知，如以下测试所示：

```java
DomainEvent domainEvent = new TestableDomainEvent(100, "testing");
Notification notification = new Notification(1, domainEvent);
NotificationSerializer serializer =
     NotificationSerializer.instance();
 String serializedNotification = serializer.serialize(notification);
NotificationReader reader =
     new NotificationReader(serializedNotification);

assertEquals(1L, reader.notificationId());
assertEquals("1", reader.notificationIdAsString());
assertEquals(domainEvent.occurredOn(), reader.occurredOn());
assertEquals(notification.typeName(), reader.typeName());
assertEquals(notification.version(), reader.version());
assertEquals(domainEvent.eventVersion(), reader.version());
```

The test shows how the NotificationReader can provide type-safe standard parts for every serialized Notification object.

> 在上例中，对于每个序列化的 Notification 对象，NotificationReader 都为其提供了类型安全的访问方式以读取不同的数据成分。

The next test shows how the special parts of each Event’s details can also be read out of a Notification payload. Event object navigation is provided using XPath-like syntax, or dot-separated properties, or you may use attribute names separated by commas (Java varargs). You can see that each attribute can be read as a String value or as its actual primitive type (int, long, boolean, double, and so on) if the type is other than String:

> 下一个测试展示了如何从 Notification 的事件细节中读取各个特殊的数据成分。我们可以通过类似于 XPath 的方式，或者以点（.）分开的方式来读取各个属性值，另外还可以使用以逗号分开的属性名的方式进行读取。每一个属性都可以用 String 类型表示，而对于那些原始类型，我们可以直接使用实际类型（比如 int、long、boolean 和 double 等）：

```java
TestableNavigableDomainEvent domainEvent =
    new TestableNavigableDomainEvent(100, "testing");

Notification notification = new Notification(1, domainEvent);

NotificationSerializer serializer = NotificationSerializer.instance();

String serializedNotification = serializer.serialize(notification);

NotificationReader reader =
     new NotificationReader(serializedNotification);

assertEquals("" + domainEvent.eventVersion(),
    reader.eventStringValue("eventVersion"));
assertEquals("" + domainEvent.eventVersion(),
    reader.eventStringValue("/eventVersion"));
assertEquals(domainEvent.eventVersion(),
    reader.eventIntegerValue("eventVersion").intValue());
assertEquals(domainEvent.eventVersion(),
    reader.eventIntegerValue("/eventVersion").intValue());
assertEquals("" + domainEvent.nestedEvent().eventVersion(),
    reader.eventStringValue("nestedEvent", "eventVersion"));
assertEquals("" + domainEvent.nestedEvent().eventVersion(),
    reader.eventStringValue("/nestedEvent/eventVersion"));
assertEquals(domainEvent.nestedEvent().eventVersion(),
    reader.eventIntegerValue("nestedEvent", "eventVersion").intValue());
assertEquals(domainEvent.nestedEvent().eventVersion(),
    reader.eventIntegerValue("/nestedEvent/eventVersion").intValue());
 assertEquals("" + domainEvent.nestedEvent().id(),
    reader.eventStringValue("nestedEvent", "id"));
assertEquals("" + domainEvent.nestedEvent().id(),
    reader.eventStringValue("/nestedEvent/id"));
assertEquals(domainEvent.nestedEvent().id(),
    reader.eventLongValue("nestedEvent", "id").longValue());
assertEquals(domainEvent.nestedEvent().id(),
    reader.eventLongValue("/nestedEvent/id").longValue());
assertEquals("" + domainEvent.nestedEvent().name(),
    reader.eventStringValue("nestedEvent", "name"));
assertEquals("" + domainEvent.nestedEvent().name(),
    reader.eventStringValue("/nestedEvent/name"));
assertEquals("" + domainEvent.nestedEvent().occurredOn().getTime(),
    reader.eventStringValue("nestedEvent", "occurredOn"));
assertEquals("" + domainEvent.nestedEvent().occurredOn().getTime(),
    reader.eventStringValue("/nestedEvent/occurredOn"));
assertEquals(domainEvent.nestedEvent().occurredOn(),
    reader.eventDateValue("nestedEvent", "occurredOn"));
assertEquals(domainEvent.nestedEvent().occurredOn(),
    reader.eventDateValue("/nestedEvent/occurredOn"));
assertEquals("" + domainEvent.occurredOn().getTime(),
    reader.eventStringValue("occurredOn"));
assertEquals("" + domainEvent.occurredOn().getTime(),
    reader.eventStringValue("/occurredOn"));
assertEquals(domainEvent.occurredOn(),
    reader.eventDateValue("occurredOn"));
assertEquals(domainEvent.occurredOn(),
    reader.eventDateValue("/occurredOn"));
```

The TestableNavigableDomainEvent holds a TestableDomain-Event, which allows us to test navigation to deeper attributes. The various attributes are read using XPath-like syntax with varargs attribute navigation. We also test reading each attribute value as various types.

> 在上例中，TestableNavigableDomainEvent 持有了一个 TestableDomainEvent，这使得我们可以测试对那些深度属性的导航访问。不同的属性都通过类似于 XPath 语法的方式进行读取，同时我们还测试了以不同的类型来读取每个属性值。

Since Notification and Event instances always have a version number, you can key off of the version to read specialized attributes in a specific version. Consumers that specialize in a given version can pick out the special parts that they need. However, it is also possible for consumers to receive any given Event-containing Notification as if it were version 1.

> 由于 Notification 和其所包含的事件实例总会携带一个版本号，此时我们便可以通过版本号来读取特定于某个版本的特殊属性。当然，此时，我们依然可以将 Notification 当作最老的版本（即版本 1）予以接收。

Thus, if we carefully consider how each Event type is designed, we can protect most consumers from incompatibility when all they need is version 1 of a given Event. Such consumers never have to change or be recompiled when an Event changes. Still, you really have to think in terms of the version compatibility and plan for smart modifications to new versions so you don’t break most consumers. Sometimes it’s impossible to achieve, but in many cases it is entirely possible.

> 因此，如果我们仔细地设计每一种事件类型，那么对于多数消费方来说便不会出现不兼容的问题。在事件发生变化时，他们并不需要做相应的修改，或者重新编译。当然，作为服务方来说，我们依然需要考虑到版本的兼容性，在做修改时应该顾及到消费方。虽然有时这是难于做到的，但是在大多数情况下，这是可能的。

This approach has the added advantage that Events can hold more than just primitive attributes and strings. Events may also safely hold instances of more sophisticated Value Objects (6), which is especially effective when their Value types tend to be stable. This is certainly the case with BacklogItemId, SprintId, and TenantId, as demonstrated by the following code, this time using dot-separated property navigation:

> 这种方式的另外一个好处在于，事件中可以不只是包含原始类型或者字符串，而是可以包含更复杂的值对象（6）。比如，对于上例中的 BacklogItemId、SprintId 和 TenantId 来说，我们可以通过以下方式进行访问：

```java
NotificationReader reader =
      new NotificationReader(backlogItemCommittedNotification);

String backlogItemId = reader.eventStringValue("backlogItemId.id"));

String sprintId = reader.eventStringValue("sprintId.id"));

String tenantId = reader.eventStringValue("tenantId.id"));
```

The fact that any held Value instances are frozen in the structure allows Events to be not only immutable, but also eternally fixed. New versions of Value Object types contained by Events do not impact your ability to read older versions of those Values from preexisting Notification instances. Certainly, Protocol Buffers can be far easier to use when Event versions change significantly and often, and dealing with those changes becomes unwieldy for consumers that use the NotificationReader.

> 这些值对象在数据结构中被冻结了，这意味着此时的事件不仅是不变的，并且从长远来看都是固定的。如果事件中包含了新版本的值对象，这并不会妨碍消费方访问那些既有 Notification 实例中的老版本的值对象。值得指出的是，对于版本经常改变的事件来说，使用协议缓存将更加简单，而 NotificationReader 将变得笨重且复杂。

Understand that this is simply an option for gracefully handling deserialization without deploying Event types and dependencies everywhere. Some will find this approach quite elegant and liberating, while others will find it risky, inept, or downright dangerous. The opposite approach of deploying interfaces and classes everywhere the serialized objects are consumed is well known. Here I provide some food for thought by pointing out a less traveled road.

> 以上，我只是提供了一种反序列化方式，这种方式不需要到处部署事件类型和其他依赖组件。对有些人来说，这是一种优雅的方式；而另外有些人却认为这是一种危险的、笨拙的方式。更多的时候，人们使用的是部署接口与类的方式。这里，我提供的是一条鲜有人走的道路。

Cowboy Logic 牛仔的逻辑

LB: “You know, J, when a cowboy’s too old to set a bad example, he hands out good advice.”

> LB：“你知道吗，J，牛仔在年轻的时候通常是一些坏榜样，但是年老之后，他们却能好好地教导别人。”

Image

It is possible that each approach—deploying classes to exchange serializations versus defining a media type contract—has an advantage at different stages of a project. For example, depending on the number of teams, Bounded Contexts, change ratio, and other factors, it might work out to share classes and interfaces when your project is starting, but it could be better to use a more decoupled, custom media type contract in the production stage. In practice this may or may not work for a particular team or set of teams. Sometimes what a team starts out with ends up being what they live with ongoing, and they never take the time to make a 180-degree change.

> 无论是哪种方式——部署接口/类，还是定义媒体类型契约——对于项目的某些阶段来说，它们有可能是适用的。比如，在项目开始时，我们可以使用部署接口和类的方式，但是在产品环境下，使用低耦合的自定义媒体类型契约则更好。当然，在实践中，这不见得对每个团队都适用。有些团队在一开始便认定了其中一种方式，之后就不改了。

To keep our running examples simple and understandable, in the remainder of the chapter I use the NotificationReader throughout. Whether or not to use a custom media type contract and NotificationReader in your Bounded Contexts is your choice to make.

> 出于简单性考虑，在本章余下的例子中，我们都将使用 NotificationReader。当然，至于是否要使用自定义的媒体类型契约和 NotificationReader，选择权在你自己。

## 13.2 INTEGRATION USING RESTFUL RESOURCES 通过 REST 资源集成限界上下文

When a Bounded Context provides a rich set of RESTful resources through URIs, it is a kind of Open Host Service (3):

> 当一个限界上下文以 URI 的方式提供了大量的 REST 资源时，我们便可称其为开放主机服务（3）：

Define a protocol that gives access to your subsystem as a set of services. Open the protocol so that all who need to integrate with you can use it. Enhance and expand the protocol to handle new integration requirements. [Evans]

> 为系统所提供的服务定义一套协议。开放该协议以使其他需要集成的系统能够使用。在有新的集成需求时，对协议进行改进和扩展。[Evans]

We can well think of the HTTP methods—GET, PUT, POST, and DELETE—combined with resources on which they operate, as a set of open services. HTTP and REST certainly form an open protocol allowing all who need to integrate with the subsystem to do so. The fact that a virtually unlimited number of resources—each with a unique identity through a URI—can be created allows the protocol to handle new integration requirements as needed. It is a very versatile way to allow clients to integrate with your Bounded Context.

> 我们完全可以把 HTTP 方法——GET、PUT、POST 和 DELETE——以及它们所操作的资源看作是开放的服务。此时，HTTP 和 REST 便组成了交互系统之间的开放协议；而几乎取之不竭的 URI 又使得这些协议能够处理新的集成需求。因此，这是一种功能强大的集成限界上下文的方式。

Even so, since the RESTful service provider must be directly interacted with whenever a resource is operated on, this style does not permit clients to be completely autonomous. If the REST-based Bounded Context becomes unavailable for some reason, dependent client Bounded Contexts will be unable to carry out necessary integration operations during any downtime.

> 虽然如此，由于在请求服务时，REST 服务的提供方都必须直接参与，因此使用这种方式的客户端并不是完全自治的。如果提供 REST 服务的限界上下文不可用，那么客户端限界上下文也无法完成集成操作。

Still, we can overcome this to some extent by making dependence on RESTful resources a lesser obstacle to consumer autonomy. Even when RESTful (or RPC for that matter) is your only means to integrate, you can create the illusion of temporal decoupling by using timers or messaging in your own system. That way your system will reach out to any remote systems only when a timer elapses or when a message is received. If the remote system is unavailable, the timer threshold can be backed off, or if using messaging the message can be negatively acknowledged to the broker and redelivered. This naturally places more of a burden on your team to make the systems loosely coupled, but that’s a price you may have to pay to achieve autonomy.

> 当然，也不是完全没有办法，我们至少可以通过某些手段来减少 REST 对自治性的阻碍。即便 REST 是你唯一的集成方式，你依然可以通过定时器或者消息机制来营造一种暂时的解耦。此时，你的系统可以在定时器触发时，或者事件抵达时，与远程系统交互。如果远程系统不可用，那么定时器所获得的服务数据便可以作为替补；或者在使用消息时，我们可以向消息提供方回复否定应答，以使其重新发布消息。诚然，这种方式将增加你团队的负担，但这是你所要付出的代价。

Image

When the SaaSOvation team developing the Identity and Access Context needed to create a way for integrators to use their Bounded Context, they determined that RESTful HTTP would be one of the best ways to open their system for integration without directly exposing the structural and behavioral details of their domain model. For them this meant designing a set of RESTful resources that would provide representations of identity and access concepts on a tenant-by-tenant basis.

> 当 SaaSOvation 公司的开发团队决定将身份与访问上下文的功能提供给客户方时，他们选择了 RESTful HTTP，他们认为这种方式的好处在于不用向客服方暴露自身领域模型的结构和行为细节。他们需要通过 REST 资源的方式向外提供 Tenant 的身份与访问相关的数据信息。

Much of their design would allow integrating Bounded Contexts to GET resources that convey user and group identity, and also indicate role-based security permissions for those identity types. For example, if an integration client needs to know if a user within a given tenant could play a specific access role, the client should GET a resource using this URI format:

> 在身份与访问上下文中，他们通过 HTTP 的 GET 方法向外提供用户和用户群的身份标识，以及与他们相关的角色信息。比如，如果客户方想知道某个租户下的某个用户是否扮演了某个角色，它可以通过以下 URI 向身份与访问上下文发送 GET 请求：

```
/tenants/{tenantId}/users/{username}/inRole/{role}
```

If the tenant’s user is in the role, the resource representation is included in the successful 200 response. Otherwise, the response is a 204 No Content status code if the user does not exist or does not play that named role. It’s a simple RESTful HTTP design.

> 如果该用户的确扮演了 role 这个角色，那么在返回中将包含 HTTP 的状态码 200，即表示成功，否则将返回表示无内容的状态码 204。这是一种简单的 RESTful HTTP 设计。

Let’s look at how the team exposed the access resources and how integration clients could consume them in terms of the Ubiquitous Language (1) of their own Bounded Context.

> 接下来，让我们看看这是如何实现的，以及客户方是如何以符合通用语言（1）的方式来消费这些资源的。

### 13.2.1 Implementing the RESTful Resource 实现 REST 资源

As SaaSOvation started applying REST principles to one of their Bounded Contexts, they learned some important lessons. Let’s look in on their journey.

> 当 SaaSOvation 公司将 REST 原则应用于身份与访问上下文中时，他们学到了很重要的一课。让我们来看看他们的这段旅程。

As the SaaSOvation team working in the Identity and Access Context considered how to provide an Open Host Service for integrators, they considered simply exposing their domain model as a set of RESTful linked resources. That would mean allowing HTTP clients to GET a unique tenant resource and navigate through its users, groups, and roles. Was that a good idea? It seemed natural at first. After all, that would afford clients with the greatest flexibility. Clients could know everything about the domain model and just make decisions in their own Bounded Context.

> 当身份与访问上下文的团队考虑着如何向集成方提供开放主机服务时，他们认为可以简单地以 REST 链接资源的方式将领域模型暴露出去。这意味着客户方可以通过 HTTP GET 的方式获得一个租户资源，然后访问其中的用户、用户群和角色等信息。这是一种好的方式吗？在一开始看来，这似乎是一种很自然的方式。毕竟，此时客户方被赋予了最大的灵活性，他们知道领域模型的各个方面。对于一个用户是否扮演某个角色的问题，他们可以在自己的限界上下文中做出判断。

Which DDD Context Mapping pattern best describes this design approach? In reality that is not an Open Host Service, but depending on the size of the shared model it would instead be a Shared Kernel or a Conformist (3). Publishing a Shared Kernel or accepting a Conformist relationship puts consumers into a tightly coupled integration with the consumed domain model. Those kinds of relationships should be avoided if at all possible since they tend to run counter to the most fundamental goals of DDD.

> 那么，对于这种设计方式，我们可以采用哪种 DDD 的上下文映射模式呢？事实上，这并不是一种开放主机服务，而更像是共享内核或者遵奉者（3），这使得消费方和身份与访问上下文中的领域模型紧密地耦合起来。我们应该尽量地避免这种情况，因为它违背了 DDD 的根本目标。

It was a good thing that along the way the team found some good advice to avoid exposing their model to clients in that way. They learned to think of the use cases (or user stories) that integrators needed. That was in harmony with this part of the Open Host Service definition: “Enhance and expand the protocol to handle new integration requirements.” That means that you provide only what integrators need at present, and you understand those needs only by considering a range of use case scenarios.

> 令人欣慰的是，团队成员们获得了一些好的建议，从而避免了将领域模型直接暴露给客户方。他们学到了如何从集成方所需用例（或者用户故事）的角度来看待问题。这是符合开放主机服务的部分定义的：“在有新的集成需求时，对协议进行改进和扩展。”这意味着他们只需要提供集成方当前之所需，而这种需求便是通过用例所驱动出来的。

When the team followed that advice, they realized that, for example, what integrators are really interested in is whether or not a given user can play a specific role. Shielding the integrators from the details of understanding the domain model would ultimately increase their productivity and make their dependent Bounded Contexts more maintainable. In terms of design it meant that their User RESTful resource could include the following design:

> SaaSOvation 公司的团队采取了这个建议，他们意识到，集成方真正关心的只是一个用户是否扮演某个角色。向集成方隐藏领域模型的细节也增加了团队的生产力，并且可以增加那些依赖方限界上下文的可维护性。此时，User 的 REST 资源应该包含：

```java
@Path("/tenants/{tenantId}/users")
public class UserResource {
    ...
    @GET
    @Path("{username}/inRole/{role}")
    @Produces({ OvationsMediaType.ID_OVATION_TYPE })
    public Response getUserInRole(
            @PathParam("tenantId") String aTenantId,
            @PathParam("username") String aUsername,
            @PathParam("role") String aRoleName) {
        Response response = null;
        User user = null;
        try {
            user = this.accessService().userInRole(
                        aTenantId, aUsername, aRoleName);
        } catch (Exception e) {
            // fall through
        }
        if (user != null) {
            response = this.userInRoleResponse(user, aRoleName);
        } else {
            response = Response.noContent().build();
        }
        return response;
    }
    ...
}
```

In the Hexagonal (4) or Ports and Adapters architecture, class User-Resource is an Adapter for the RESTful HTTP Port provided by the JAX-RS implementation. A consumer makes a request in the form

> 在六边形（4）或端口与适配器架构中，UserResource 类是 RESTful HTTP 端口的适配器，该端口通过 JAX-RS 实现。此时，消费方可以通过以下方式发出请求：

```
GET /tenants/{tenantId}/users/{username}/inRole/{role}
```

The Adapter delegates to the AccessService, an Application Service (14) that provides an API at the inner hexagon. Being a direct client of the domain model, the AccessService manages the use case task and transaction. The task includes finding whether or not the User exists at all, and if so, whether or not it plays the named role:

> 该适配器会把功能委派给 AccessService，这是一个应用服务（14），它位于六边形内部，并向外提供 API。作为领域模型的直接客户，AccessService 负责管理用例和事务。该用例包括查找一个 User 是否存在，如果存在，再判断该 User 是否扮演了某个指定的角色：

```java
package com.saasovation.identityaccess.application;
...
public class AccessService ... {
    ...
    @Transactional(readOnly=true)
    public User userInRole(
            String aTenantId,
            String aUsername,
            String aRoleName) {
        User userInRole = null;
        TenantId tenantId = new TenantId(new TenantId(aTenantId));
        User user =
            DomainRegistry
                .userRepository()
                .userWithUsername(tenantId, aUsername);
        if (user != null) {
            Role role =
                DomainRegistry
                    .roleRepository()
                    .roleNamed(tenantId, aRoleName);
            if (role != null) {
                GroupMemberService groupMemberService =
                        DomainRegistry.groupMemberService();
                if (role.isInRole(user, groupMemberService)) {
                    userInRole = user;
                }
            }
        }
        return userInRole;
    }
    ...
}
```

The Application Service finds both the User and the named Role Aggregate. When the Role query method isInRole() is called, a GroupMemberService is passed in. This is not an Application Service, but rather a Domain Service (7) that helps the Role perform certain domain-specific checks and queries that the Role itself should not be responsible for.

> 应用服务将分别找到 User 和 Role 聚合。当 Role 的查询方法 isInRole（）被调用时，我们传入了一个 GroupMemberService。GroupMemberService 并不是一个应用服务，而是一个领域服务（7），它帮助 Role 执行一些与领域相关的检查和查询，因为这些职责并不属于 Role 本身。

The Response from the UserResource is formed from the resolved User and the specific role name, using one of the custom media types:

> UserResource 中的 Response 包含了一个 User 及其所扮演的角色名，此时团队成员使用了一个自定义的媒体类型：

```java
package com.saasovation.common.media;

public class OvationsMediaType {
    public static final String COLLAB_OVATION_TYPE =
            "application/vnd.saasovation.collabovation+json";
    public static final String ID_OVATION_TYPE =
            "application/vnd.saasovation.idovation+json";
    public static final String PROJECT_OVATION_TYPE =
            "application/vnd.saasovation.projectovation+json";
    ...
}
```

When the user is in the named role, the UserResource Adapter produces an HTTP response with a JSON representation like the following:

> 如果一个 User 的确扮演了某个指定的角色，那么 UserResource 适配器将在 HTTP 应答中包含以下 JSON 数据：

```
HTTP/1.1 200 OK
Content-Type: application/vnd.saasovation.idovation+json
...
{
    "role":"Author","username":"zoe",
    "tenantId":"A94A8298-43B8-4DA0-9917-13FFF9E116ED",
    "firstName":"Zoe","lastName":"Doe",
    "emailAddress":"zoe@saasovation.com"
}
```

As you will see next, the integrating consumer of this RESTful resource can translate it into the specific kind of domain object needed by its Bounded Context.

> 当消费方在获取到该 REST 资源时，他们将把这些资源翻译成本地限界上下文中的领域对象。

### 13.2.2 Implementing the REST Client Using an Anticorruption Layer 使用防腐层实现 REST 客户端

Although the JSON representation produced by the Identity and Access Context is quite useful to the client integrators, when we are focused on the goals of DDD, the representation will not be consumed as is in the client Bounded Context. As discussed in previous chapters, if the consumer is the Collaboration Context, the team is not interested in primitive users and their roles. Instead, the team developing in the collaboration model is interested in the domain-specific roles. The fact that in some other model there is a set of User objects that can be assigned to one or more roles as modeled by a Role object is really not in the collaboration sweet spot.

> 对于客户方来说，虽然身份与访问上下文所提供的 JSON 展现数据非常有用，但是当我们考虑到 DDD 的目标时，客户方的限界上下文是不会原封不动地消费这些 JSON 数据的。在前面的章节中我们已经讲到，如果消费方是协作上下文，该上下文的开发团队对原生的用户和角色信息并不会感兴趣，他们关心的是更加特定于自身领域的角色。此时，单纯地使用 User 和 Role 领域对象对他们来说已经不再适用。

So, then, how do we make the user-in-role representation serve our specific collaboration purposes? Let’s take another look at a previously drawn Context Map, this time found in Figure 13.1. The important parts of the UserResource Adapter were shown in the previous subsection. This leaves the interfaces and classes to be developed specifically for the Collaboration Context. These are the CollaboratorService, the UserInRoleAdapter, and the CollaboratorTranslator. There is also the HttpClient, but that is provided by the JAX-RS implementation through the classes ClientRequest and ClientResponse.

> 那么，要使 User-Role 形式的数据能够服务于协作上下文，我们又应该怎么做呢？让我看看图 13.1 所示的上下文映射图，其中的 UserResource 适配器已经在前一节中讲到了。从图中可以看出，我们需要为协作上下文创建一些特定的接口和类，即 CollaboratorService、UserInRoleAdapter 和 CollaboratorTranslator。同时还有 HttpClient，这是通过 JAX-RS 实现中的 ClientRequest 和 ClientResponse 来提供的。

Image

Figure 13.1. The Open Host Service of the Identity and Access Context and the Anticorruption Layer of the Collaboration Context used for integration between the two

The trio of CollaboratorService, UserInRoleAdapter, and CollaboratorTranslator is used to form an Anticorruption Layer (3), the means by which the Collaboration Context will interact with the Identity and Access Context and translate the user-in-role representation into a Value Object for a specific kind of Collaborator.

> 这里的 CollaboratorService、UserInRoleAdaptor 和 CollaboratorTranslator 便组成了一个防腐层（3），该防腐层是协作上下文和身份与访问上下文交互的方式，同时它还负责将 User-Role 形式的数据翻译成 Collaborator 值对象。

Here’s interface CollaboratorService, which forms the simple operations of the Anticorruption Layer:

> 以下是 CollaboratorService，它组成了防腐层的基本操作：

```java
public interface CollaboratorService  {
    public Author authorFrom(Tenant aTenant, String anIdentity);
    public Creator creatorFrom(Tenant aTenant, String anIdentity);
    public Moderator moderatorFrom(Tenant aTenant, String anIdentity);
    public Owner ownerFrom(Tenant aTenant, String anIdentity);
    public Participant participantFrom(
            Tenant aTenant, String anIdentity);
}
```

From the viewpoint of the clients of CollaboratorService, the interface completely abstracts away the complexity of the remote system access and subsequent translations from the Published Language to objects that adhere to the local Ubiquitous Language. In this particular case we do use a Separated Interface [Fowler, P of EAA] and an implementation class because the implementation is technical and should not reside in the Domain Layer.

> 对于 CollaboratorService 的客户端来说，它根本看不到对远程系统的访问，以及是如何将远程系统的发布语言翻译成本地对象的。在本例中，我们的确使用到了独立接口[Fowler，P of EAA]，因为该接口的实现是技术性的，并且不应该位于领域层中。

All of these Factories (11) are very similar to each other. They all create a subclass of the abstract Collaborator Value type, but only if the user within aTenant and having anIdentity plays the security role within one of the five types: Author, Creator, Moderator, Owner, and Participant. Since they are so similar, let’s look at just one of the method implementations, authorFrom():

> CollaboratorSer vice 中的所有工厂（11）方法都是相似的。它们都用于创建抽象类 Collaborator 的某个子类。当然，前提是一个以 anIdentity 标定的 User 的确位于 aTenant 下，并且扮演了以下角色类型的其中一种：Author、Creator、Moderator、Owner 和 Participant。让我们看看 authorFrom（）工厂方法的实现：

```java
package com.saasovation.collaboration.infrastructure.services;

import com.saasovation.collaboration.domain.model.collaborator.Author;
...
public class TranslatingCollaboratorService
       implements CollaboratorService  {
    ...
    @Override
    public Author authorFrom(Tenant aTenant, String anIdentity) {
        Author author =
            this.userInRoleAdapter
                .toCollaborator(
                        aTenant,
                        anIdentity,
                        "Author",
                        Author.class);
        return author;
    }
    ...
}
```

First note that TranslatingCollaboratorService is in a Module (9) of the Infrastructure. We create the Separated Interface in the inner hexagon as part of the domain model. Yet, the implementation is technical and is housed at the outside of the Hexagonal architecture, where the Ports and Adapters reside.

> 请注意，这里的 TranslatingCollaboratorService 位于基础设施层的某个模块（9）中。虽然我们将独立接口 CollaboratorService 当作领域模型的一部分，并将它放置在了六边形的内部，但是它的实现却是技术性的，并且被放置在了六边形架构的外部，即端口和适配器所在的位置。

As part of the technical implementation, generally an Anticorruption Layer will have a specialized Adapter [Gamma et al.] and a translator. Looking again at Figure 13.1, you can see that our specific Adapter is UserInRoleAdapter, and the translator is the CollaboratorTranslator. The specialized UserInRoleAdapter of this Anticorruption Layer is responsible for reaching out to the remote system, requesting the necessary user-in-role resource:

> 作为技术实现的一部分，在防腐层中通常会有一个特定的适配器[Gamma et al.]和翻译器。再回头看看图 13.1，你将看到其中的适配器 UserInRoleAdapter 和翻译器 CollaboratorTranslator。这个特定的 UserInRoleAdapter 负责与远程系统的交互以请求所需的 User-Role 资源：

```java
package com.saasovation.collaboration.infrastructure.services;

import org.jboss.resteasy.client.ClientRequest;
import org.jboss.resteasy.client.ClientResponse;
...
public class UserInRoleAdapter {
    ...
    public <T extends Collaborator> T toCollaborator(
            Tenant aTenant,
            String anIdentity,
            String aRoleName,
            Class<T> aCollaboratorClass) {
        T collaborator = null;
        try {
            ClientRequest request =
                    this.buildRequest(aTenant, anIdentity, aRoleName);
            ClientResponse<String> response =
                    request.get(String.class);
            if (response.getStatus() == 200) {
                collaborator =
                    new CollaboratorTranslator()
                        .toCollaboratorFromRepresentation(
                            response.getEntity(),
                            aCollaboratorClass);
            } else if (response.getStatus() != 204) {
                throw new IllegalStateException(
                        "There was a problem requesting the user: "
                        + anIdentity
                        + " in role: "
                        + aRoleName
                        + " with resulting status: "
                        + response.getStatus());
            }
        } catch (Throwable t) {
            throw new IllegalStateException(
                    "Failed because: " + t.getMessage(), t);
        }
        return collaborator;
    }
    ...
}
```

If the response to the GET request is successful (status 200), it means that the UserInRoleAdapter has received a user-in-role resource, which can now be translated into our Collaborator subclass:

> 如果 GET 请求得到了成功（状态码 200）的应答，表明该 UserInRoleAdapter 获取到了相应的 User-Role 资源。之后，CollaboratorTranslator 负责将该资源翻译成 Collaborator 的子类对象：

```java
package com.saasovation.collaboration.infrastructure.services;

import java.lang.reflect.Constructor;
import com.saasovation.common.media.RepresentationReader;
...
public class CollaboratorTranslator {
    public CollaboratorTranslator() {
        super();
    }

    public <T extends Collaborator> T toCollaboratorFromRepresentation(
            String aUserInRoleRepresentation,
            Class<T> aCollaboratorClass)
    throws Exception {
        RepresentationReader reader =
                new RepresentationReader(aUserInRoleRepresentation);
        String username = reader.stringValue("username");
        String firstName = reader.stringValue("firstName");
        String lastName = reader.stringValue("lastName");
        String emailAddress = reader.stringValue("emailAddress");
        T collaborator =
            this.newCollaborator(
                    username,
                    firstName,
                    lastName,
                    emailAddress,
                    aCollaboratorClass);
        return collaborator;
    }

    private <T extends Collaborator> T newCollaborator(
            String aUsername,
            String aFirstName,
            String aLastName,
            String aEmailAddress,
            Class<T> aCollaboratorClass)
    throws Exception {
        Constructor<T> ctor =
            aCollaboratorClass.getConstructor(
                    String.class, String.class, String.class);
        T collaborator =
            ctor.newInstance(
                    aUsername,
                    (aFirstName + " " + aLastName).trim(),
                    aEmailAddress);
        return collaborator;
    }
}
```

This translator takes a user-in-role representation text String and the Class to be used to create the Collaborator subclass instance. First the RepresentationReader—quite similar to the NotificationReader introduced previously—is used to read four attributes out of the JSON representation. Again, we can confidently and reliably do this because the SaaSOvation custom media type forms a binding contract between producers and consumers. After the translator has the necessary String values, it uses them to instantiate the Collaborator Value Object and, in the case of this example, an Author:

> 该 CollaboratorTranslator 的 toCollaboratorFromRepresentation（）方法接受两个参数：User-Role 资源的文本展现（String 类型）和 Collaborator 的某个子类的 Class 类型。首先，RepresentationReader——和先前的 NotificationReader 相似——负责读取 JSON 数据展现中的 4 个属性。此时，我们可以非常自信地这么做，因为 SaaSOvation 公司自定义的媒体类型在生产方系统和消费方系统之间形成了一种绑定契约。在 CollaboratorTranslator 获取到了所需的 String 类型属性时，它将用这些属性来创建 Collaborator 值对象，在本例中即为 Author：

```java
package com.saasovation.collaboration.domain.model.collaborator;

public final class Author
       extends Collaborator  {
    public Author(
            String anIdentity,
            String aName,
            String anEmailAddress) {
        super(anIdentity, aName, anEmailAddress);
    }
    ...
}
```

There is no effort made to keep Collaborator Value instances synchronized with the Identity and Access Context. They are immutable and can only be fully replaced, not modified. Here’s how an Author is obtained by an Application Service and then given to a Forum to start a new Discussion:

> 如果要将 Collaborator 值对象实例和身份与访问上下文保持同步，我们并不需要做额外的工作。因为 Collaborator 是不变的，我们不能对其进行修改，而只能完全替代。下面的例子演示了应用服务如何获取到一个 Author，然后将其交给 Forum 来开始一个新的 Discussion：

```java
package com.saasovation.collaboration.application;
...
public class ForumService ... {
    ...
    @Transactional
    public Discussion startDiscussion(
            String aTenantId,
            String aForumId,
            String anAuthorId,
            String aSubject) {
        Tenant tenant = new Tenant(aTenantId);
        ForumId forumId = new ForumId(aForumId);
        Forum forum = this.forum(tenant, forumId);
        if (forum == null) {
            throw new IllegalStateException("Forum does not exist.");
        }
        Author author =
                this.collaboratorService.authorFrom(
                        tenant, anAuthorId);
        Discussion newDiscussion =
                forum.startDiscussion(
                        this.forumNavigationService(),
                        author,
                        aSubject);
        this.discussionRepository.add(newDiscussion);
        return newDiscussion;
    }
    ...
}
```

If a Collaborator name or e-mail address changes in the Identity and Access Context, such changes won’t be automatically updated in the Collaboration Context. Those kinds of changes rarely occur, so the team made the decision to keep this particular design simple and not attempt to synchronize changes in the remote Context with objects in their local Context. We will see, however, that the Agile Project Management Context has different design goals.

> 如果一个 Collaborator 的名字或者 E-mail 地址在身份与访问上下文中发生改变，该改变并不会自动地更新到协作上下文中。但是，这种情况很少发生，因此团队成员们决定维持既有的简单设计，而不用同步本地上下文和远程上下文。然而，在敏捷项目管理上下文中，我们将看到不同的设计目标。

There are other ways to implement an Anticorruption Layer, such as by means of a Repository (12). However, since Repositories are typically used to persist and reconstitute Aggregates, creating Value Objects by that means seems misplaced. If our goal is to produce an Aggregate from an Anticorruption Layer, a Repository may be a more natural source.

> 还有其他方式可以实现防腐层，比如资源库（12）。但是，由于资源库通常是用来持久化和重建聚合的，将其用于创建值对象似乎就不合适了。当然，如果我们的目的就是要通过防腐层创建聚合，那么资源库便是一种自然的选择。

## 13.3 INTEGRATION USING MESSAGING 通过消息集成限界上下文

A message-based approach to integration can allow any one system to achieve a higher degree of autonomy from systems it depends on. As long as the messaging infrastructure remains operational, messages can be sent and delivered even when any one system is unavailable.

> 在使用消息进行集成时，任何一个系统都可以获得更高层次的自治性。只要消息基础设施工作正常，即使其中一个交互系统不可用，消息依然可以得到发送和投递。

One of the ways that DDD can be leveraged to make systems autonomous is through the use of Domain Events. When something of significance happens in one system, it produces an Event about it. There will tend to be several or even many such Events that occur in each system, and you will create a unique kind of Event as a means to record each. As Events occur, they are published to interested parties by means of a messaging mechanism. That’s just a big-picture review. In case you bypassed the details of this topic in earlier chapters, you may be better off getting some background from Architecture (4), Domain Events (8), and Aggregates (10) before continuing here.

> 在 DDD 中，增强系统自治性的一种方式便是使用领域事件。当一个系统中发生一些显著性的事情时，它将为此发布领域事件。在每个系统中，都存在着多个甚至大量的事件，在创建这些事件时，我们需要考虑到事件的唯一性以便对每个事件进行记录。当事件发生时，系统将通过消息机制将这些事件发送到对事件感兴趣的相关方。当然，以上只是对于事件的高层总览。如果你错过了本书前面章节对事件细节的探讨，那么请参考架构（4）、领域事件（8）和聚合（10）等章节。

### 13.3.1 Staying Informed about Product Owners and Team Members 从 Scrum 的产品负责人和团队成员处得到持续通知

The Agile Project Management Context needs to manage a pool of Scrum product owners and team members for each tenant that subscribes to the service. At any time a product owner can create a new product and then assign team members to the team. How can the Scrum project management application know who plays each of these roles? The answer is that it won’t go it alone.

> 在敏捷项目管理上下文中，对于每个订阅的租户来说，系统都需要为其维护一组 Scrum 的产品负责人和团队成员。在任何时候，产品负责人都可以创建新的产品，然后添加团队成员。那么，这个 Scrum 项目管理系统如何知道什么样的人扮演着什么样的角色呢？答案是，它不会单干的。

Actually, the Agile Project Management Context is going to allow those roles to be managed by the Identity and Access Context, a natural and fitting choice. In that system each tenant that subscribes to the Scrum service will have two Role instances created: ScrumProductOwner and ScrumTeamMember. Each User who needs to play one of those roles will be assigned to it. Here’s the Application Service method in the Identity and Access Context that manages the task of assigning a User to a Role:

> 事实上，敏捷项目管理上下文将通过身份与访问上下文来管理不同的角色，这是一种自然的选择，也是合适的选择。在身份与访问上下文中，每一个订阅的租户都会创建 2 个 Role 实例：ScrumProductOwner 和 ScrumTeamMember。每一个需要扮演某种角色的 User 都会被指派给相应的 Role。在该限界上下文的应用服务中，我们通过以下方式来实现：

```java
package com.saasovation.identityaccess.application;
...
public class AccessService ... {
    ...
    @Transactional
    public void assignUserToRole(AssignUserToRoleCommand aCommand) {
        TenantId tenantId =
                new TenantId(aCommand.getTenantId());
        User user =
                this.userRepository
                    .userWithUsername(
                            tenantId,
                            aCommand.getUsername());
        if (user != null) {
            Role role =
                    this.roleRepository
                        .roleNamed(
                                tenantId,
                                aCommand.getRoleName());
            if (role != null) {
                role.assignUser(user);
            }
        }
    }
    ...
}
```

Great, but how does this help the Agile Project Management Context know who is in the role of a ScrumTeamMember or ScrumProductOwner? Here’s how. When method assignUser() of the Role completes, its last responsibility is to publish an Event:

> 非常好！但是，敏捷项目管理上下文又如何知道是谁扮演了 ScrumTeamMember 或者 ScrumProductOwner 呢？答案是：当 Role 中的 assignUser（）方法执行完毕时，它将发布一个事件：

```java
package com.saasovation.identityaccess.domain.model.access;
...
public class Role extends Entity {
    ...
    public void assignUser(User aUser) {
        if (aUser == null) {
            throw new NullPointerException("User must not be null.");
        }
        if (!this.tenantId().equals(aUser.tenantId())) {
            throw new IllegalArgumentException(
                    "Wrong tenant for this user.");
        }
        this.group().addUser(aUser);

        DomainEventPublisher
            .instance()
            .publish(new UserAssignedToRole(
                    this.tenantId(),
                    this.name(),
                    aUser.username(),
                    aUser.person().name().firstName(),
                    aUser.person().name().lastName(),
                    aUser.person().emailAddress()));
    }
    ...
}
```

Event UserAssignedToRole, enriched with User name and e-mail address properties, is eventually delivered to all interested parties. When the Agile Project Management Context receives the Event, it will use it to ensure that a new TeamMember or ProductOwner is established in its model. This is not a terribly difficult use case. Yet, there are more details to manage than may at first meet the eye. Let’s break these down.

> 这里的 UserAssignedToRole 事件包含有一个 User 的名字和 E-mail 地址，最终它将被投递到所有感兴趣的相关方。当敏捷项目管理上下文收到该事件时，它将相应地创建一个新的 TeamMember 或者 ProductOwner。这并不是一个多难的用例，但是它的实现细节却比我们想象中的要复杂。让我们深入其中去看看。

As it turns out, there are some highly reusable aspects to listening for notifications from RabbitMQ. We already have a simple object-oriented library that helps make the RabbitMQ Java client easier to use. Now we’re going to add one more simple class to make becoming an exchange queue consumer really simple:

> 对于 RabbitMQ 来说，有多种方式来监听其发出的通知。我们已经有一个简单的面向对象的类库来方便 RabbitMQ 的 Java 客户端。现在，我们再多加一个简单的类，该类将一个普通的消费方变为一个交换器队列的消费方：

```java
package com.saasovation.common.port.adapter.messaging.rabbitmq;
...
public abstract class ExchangeListener {
    private MessageConsumer messageConsumer;
    private Queue queue;

    public ExchangeListener() {
        super();
        this.attachToQueue();
        this.registerConsumer();
    }

    protected abstract String exchangeName();

    protected abstract void filteredDispatch(
            String aType, String aTextMessage);

    protected abstract String[] listensToEvents();

    protected String queueName() {
        return this.getClass().getSimpleName();
    }

    private void attachToQueue() {
        Exchange exchange =
                Exchange.fanOutInstance(
                        ConnectionSettings.instance(),
                        this.exchangeName(),
                        true);
        this.queue =
                Queue.individualExchangeSubscriberInstance(
                        exchange,
                        this.exchangeName() + "." + this.queueName());
    }

    private Queue queue() {
        return this.queue;
    }

    private void registerConsumer() {
        this.messageConsumer =
                MessageConsumer.instance(this.queue(), false);
        this.messageConsumer.receiveOnly(
                this.listensToEvents(),
                new MessageListener(MessageListener.Type.TEXT) {
            @Override
            public void handleMessage(
                    String aType,
                    String aMessageId,
                    Date aTimestamp,
                    String aTextMessage,
                    long aDeliveryTag,
                    boolean isRedelivery)
            throws Exception {
                filteredDispatch(aType, aTextMessage);
            }
        });
    }
}
```

The ExchangeListener is an abstract base class that concrete listener subclasses reuse. A concrete subclass need add only a little bit of code in addition to extending the abstract base class. First, it just ensures that the default base class constructor is invoked, which always happens anyway. Then all that’s left is to implement three abstract methods, two of which are very simple to implement: exchangeName(), filteredDispatch(), and listensToEvents().

> 这里的 ExchangeListener 是一个抽象基类。子类在扩展该抽象基类时只需要添加少许的代码即可。首先，子类需要保证正确地调用了抽象基类的构造函数。之后便是实现三个抽象方法了，即 exchangeName（）、filteredDispatch（）和 listensToEvents（），其中的两个实现起来都非常简单。

To implement exchangeName() all that is needed is to return the String name of the exchange for which the concrete listener consumes notifications. To implement the abstract method listensToEvents() you must answer a String[] of notification types that you want to receive. Many listeners will consume only one type of notification and so would answer an array with only one element. The one remaining method, filteredDispatch(), is the most complex of the three because it is responsible for the heavy lifting of handling received messages. To see how it works, let’s take a look at the listener of Event-carrying notifications for UserAssignedToRole:

> 要实现 exchangeName（）方法，我们只需要返回某个具体类在获取通知时所使用的交换器名称即可。要实现 listensToEvents（）方法，我们需要返回一个 String 类型的数组，其中包含了该具体类希望接收的通知类型。多数消息监听器都只处理一种类型的通知，因此 listensToEvents（）方法所返回的 String 数组中通常只包含一个元素。余下的 filteredDispatch（）方法是最复杂的，因为它负责处理所接收到的消息。让我们看看处理 UserAssignedToRole 事件的 TeamMemberEnablerListener：

```java
package com.saasovation.agilepm.infrastructure.messaging;
...
public class TeamMemberEnablerListener extends ExchangeListener {
    @Autowired
    private TeamService teamService;

    public TeamMemberEnablerListener() {
        super();
    }

    @Override
    protected String exchangeName() {
        return Exchanges.IDENTITY_ACCESS_EXCHANGE_NAME;
    }

    @Override
    protected void filteredDispatch(
                String aType,
                String aTextMessage) {
        NotificationReader reader =
                new NotificationReader(aTextMessage);
        String roleName = reader.eventStringValue("roleName");
        if (!roleName.equals("ScrumProductOwner") &&
            !roleName.equals("ScrumTeamMember")) {
            return;
        }
        String emailAddress = reader.eventStringValue("emailAddress");
        String firstName = reader.eventStringValue("firstName");
        String lastName = reader.eventStringValue("lastName");
        String tenantId = reader.eventStringValue("tenantId.id");
        String username = reader.eventStringValue("username");
        Date occurredOn = reader.occurredOn();

        if (roleName.equals("ScrumProductOwner")) {
            this.teamService.enableProductOwner(
                    new EnableProductOwnerCommand(
                        tenantId,
                        username,
                        firstName,
                        lastName,
                        emailAddress,
                        occurredOn));
        } else {
            this.teamService.enableTeamMember(
                    new EnableTeamMemberCommand(
                        tenantId,
                        username,
                        firstName,
                        lastName,
                        emailAddress,
                        occurredOn));
        }
    }

    @Override
    protected String[] listensToEvents() {
        return new String[] {
                "com.saasovation.identityaccess.domain.model.access.UserAssignedToRole"
                };
    }
}
```

The ExchangeListener default constructor is properly invoked, exchangeName() answers the name of the exchange published to by the Identity and Access Context, and method listensToEvents() answers a one-element array with the fully qualified class name of Event User-AssignedToRole. Note that publishers and subscribers should consider the use of fully qualified class names, which includes the Module name and the class name. This removes all possible collision or ambiguity that could exist with same or similarly named Events from different Bounded Contexts.

> 在上例中，ExchangeListener 的默认构造函数得到了正确的调用，exchangeName（）方法返回的是身份与访问上下文在发布事件时所使用的交换器的名字，而 listensToEvents（）所返回的数组中只包含了 UserAssignedToRole 事件的全类名。请注意，发布方和订阅方都应该使用事件的全类名，其中包含了事件所在的模块名和事件本身的类名。这样，如果不同的限界上下文使用了相同的事件类名，我们依然可以进行区分。

Again, it is filteredDispatch() that contains the bulk of the behavior. The method is named as it is because it can further filter the notification before it dispatches to the Application Service API. In this case it does filter before dispatching, by ignoring all notifications of type UserAssignedToRole that are not conveying Events about the roles named ScrumProductOwner and ScrumTeamMember. On the other hand, if the roles are the ones we are interested in receiving Events about, we get the UserAssignedToRole details out of the notification and dispatch to the Application Service named TeamService. Each of the Service methods enableProductOwner() and enableTeamMember() takes a command object, either EnableProductOwnerCommand or EnableTeamMemberCommand, respectively.

> 最后，真正包含大量行为的是 filteredDispatch（）方法。正如该方法的名字所暗示的，在调用应用层 API 之前，它将对通知进行过滤。在本例中，它将过滤掉那些不包含 ScrumProductOwner 和 ScrumTeamMember 角色的 UserAssignedToRole 事件。另一方面，如果 UserAssignedToRole 的确包含了以上两种角色，那么 filteredDispatch（）方法将从通知中提取出 UserAssignedToRole 事件的细节信息，并将操作进一步分发给应用层的 TeamService。TeamService 中的 enableProductOwner（）方法和 enableTeamMember（）方法都以一个命令对象为参数，分别是 EnableProductOwnerCommand 和 EnableTeamMemberCommand。

At first it might seem that a member would just be created as a result of one of these Events. However, since it is possible that each User could be assigned to one of these Roles, and then later unassigned, and then reassigned, it’s possible that the member represented by the User in the received notification already exists. Here’s how the TeamService deals with that situation:

> 乍看起来，每个 UserAssignedToRole 事件似乎都会导致新成员的创建。但是，每个 User 都可能被指派成任何一个 Role，之后还有可能解除指派，再重新指派。因此，可能发生的情况是：在所接收的通知中，一个 User 所表示的成员已经存在了。对此，以下是 TeamService 的解决方法：

```java
package com.saasovation.agilepm.application;
...
public class TeamService ... {
    @Autowired
    private ProductOwnerRepository productOwnerRepository;
    @Autowired
    private TeamMemberRepository teamMemberRepository;
    ...
    @Transactional
    public void enableProductOwner(
                EnableProductOwnerCommand aCommand) {
        TenantId tenantId = new TenantId(aCommand.getTenantId());
        ProductOwner productOwner =
                this.productOwnerRepository.productOwnerOfIdentity(
                        tenantId,
                        aCommand.getUsername());
        if (productOwner != null) {
            productOwner.enable(aCommand.getOccurredOn());
        } else {
            productOwner =
                    new ProductOwner(
                            tenantId,
                            aCommand.getUsername(),
                            aCommand.getFirstName(),
                            aCommand.getLastName(),
                            aCommand.getEmailAddress(),
                            aCommand.getOccurredOn());
            this.productOwnerRepository.add(productOwner);
        }
    }
}
```

For example, Service method enableProductOwner() deals with the possibility that the specific ProductOwner already exists. If it does exist, we assume that it may need to be enabled again, so we dispatch to the corresponding command operation. If the ProductOwner does not yet exist, we instantiate a new Aggregate and add it to its Repository. Actually, we deal with the TeamMember in the same way, so enableTeamMember() is implemented in the same way.

> 在上例中，enableProductOwner（）方法将检查一个特定的 ProductOwner 是否已经存在。如果已经存在，那么我们假设该 ProductOwner 需要重新激活，因此我们执行了相关的命令操作。如果不存在，那么我们创建一个新的聚合实例，然后将其添加到资源库中。对于 TeamMember 来说，我们也是这么处理的，因此 enableTeamMember（）方法和 enableProductOwner（）方法的实现方式相同。

### 13.3.2 Can You Handle the Responsibility? 你能处理这样的职责吗？

This all seems fine and good. It appears simple enough. We have Product-Owner and TeamMember Aggregate types, and we’ve designed them so that each holds some information about the backing User from the foreign Bounded Context. But did you realize how much responsibility we’ve just assumed by designing these Aggregates that way?

> 以上方法看来不错，并且也足够简单。我们有了 ProductOwner 和 TeamMember 聚合类型，它们都包含有外部限界上下文中 User 类的一些信息。但是，你有没有意识到，此时的聚合承担了多少职责？

Recall that in the Collaboration Context the team decided to just create immutable Value Objects that hold similar information (see “Implementing the REST Client Using an Anticorruption Layer”). Because the Values are immutable, the team will never have to worry about keeping the shared information up-to-date. Of course, the downside to that advantage is that if some of the shared information is updated, the Collaboration Context will never update the related objects that it created in the past. So the Agile Project Management team went for the opposite trade-off.

> 回想一下，在协作上下文中，要包含来自 User 的信息，开发团队使用的是一些不变的值对象（请参考“使用防腐层实现 REST 客户端”）。正因为这些值对象是不变的，开发团队根本不用担心对共享信息的更新。当然，这也是一个问题，即在共享信息更新之后，协作上下文中的相应对象将得不到更新。因此，敏捷项目管理开发团队选择了另一条路。

Now, however, there are a few challenges to keeping the Aggregates up-to-date. Why? Can’t we just listen for additional Event-carrying notifications that reflect changes to the User instances that correspond to our ProductOwner and TeamMember instances? Yes, indeed, we can and must do so. But the fact that we are using a messaging infrastructure makes this just a bit more challenging than might be obvious.

> 然而，要保持对聚合的实时更新是存在诸多挑战的。为什么？难道不是监听对 User 实例的修改，然后相应地修改 ProductOwner 和 TeamMember 吗？当然是，并且我们也必须这么做。但是，我们所使用的消息基础设施将给我们带来一些挑战。

For example, what would happen if in the Identity and Access Context a manager mistakenly unassigns Joe Johnson from the ScrumTeamMember role? Well, we receive an Event-carrying notification that indicates that fact, so we use the TeamService to disable the TeamMember corresponding to Joe Johnson. Wait. Seconds later the manager realizes that she has unassigned the wrong user from the ScrumTeamMember role, and that she should have unassigned Joe Jones instead. So she quickly assigns Joe Johnson back to the role and unassigns Joe Jones. Next, the Agile Project Management Context receives the corresponding notifications, and everyone is happy (except maybe Joe Jones). Or, is everything actually OK?

> 比如，在身份与访问上下文中，如果一个管理者错误地将 Joe Johnson 所扮演的 ScrumTeamMember 角色解除了，情况会怎么样？当然，我们会收到一个事件通知，然后调用 TeamService 将 Joe Johnson 所对应的 TeamMember 转为失活状态。等一等，几秒钟之后，该管理者意识到了错误，她真正应该被操作的 User 是 Joe Jones，而不是 Joe Johnson。因此，她立即将 ScrumTeamMember 角色再次指派给 Joe Johnson，然后解除 Joe Jones 所扮演的 ScrumTeamMember 角色。之后，敏捷项目管理上下文将接收到相应的通知，万事大吉。也或者，万事真的就大吉了吗？

We could be making a bad assumption about this use case. We are assuming that we receive the notifications in the order in which they actually occurred in the Identity and Access Context. Yet, things might not always work out so well. What would happen if, for whatever reason, the notifications about Joe Johnson were received in this order, UserAssignedToRole and then User-UnassignedFromRole? What will happen is that the TeamMember corresponding to Joe Johnson will be stuck in a disabled state, and at best someone will have to patch the data in the Agile PM database, or the manager will have to play some tricks to get the right Joe reenabled. This can happen, and ironically, it seems to always happen when we overlook the fact that it could happen. So, how do we prevent this?

> 对于这个用例来说，我们做出了错误的假设，即假设通知的接收顺序和它们在身份与访问上下文中的产生顺序相同。但是，事实却不总是如此。对于 Joe Johnson 来说，如果我们先接收到了 UserAssignedToRole 事件，再接收到 UserUnassignedToRole 事件，情况又会如何呢？在所有事件处理完后，JoeJohnson 所对应的 TeamMember 将依然处于失活状态。此时，有人可能需要向敏捷项目管理上下文的数据库中打些补丁，或者管理者需要玩弄一些小技巧将 JoeJohnson 重新激活。这种情况是有可能发生的，并且比我们所想象的发生频率更高。那么，我们应该如何避免这种情况呢？

Let’s take a closer look at the command objects that we pass as parameters to the TeamService APIs. For example, consider the commands EnableTeamMemberCommand and DisableTeamMemberCommand. Each of these requires a Date object, namely, occurredOn, to be provided. In fact, all of our command objects are designed this way. We will use the occurredOn values to ensure that our ProductOwner and TeamMember Aggregates deal with the command operations in a time-aware way. Thinking back to the use case that could have caused us trouble before, let’s see what would happen if we dealt with the possibility of the UserUnassignedFromRole arriving after UserAssignedToRole, even though they occurred in the opposite order:

> 让我们仔细看看传给 TeamServiceAPI 的命令对象，比如 EnableTeamMemberCommand 和 DisableTeamMemberCommand。这两个命令对象都需要提供一个 Data 对象，即 occurredOn 属性。事实上，所有的命令对象都是如此设计的。我们将使用该 occurredOn 属性来确保 ProductOwner 和 TeamMember 是以正确的时间顺序来处理命令操作的。对于前面的 UserAssignedToRole 先于 UserUnassignedToRole 被接收的情况，我们看看如何处理：

```java
package com.saasovation.agilepm.application;
...
public class TeamService ... {
    ...
    @Transactional
    public void disableTeamMember(DisableTeamMemberCommand aCommand) {
        TenantId tenantId = new TenantId(aCommand.getTenantId());
        TeamMember teamMember =
                this.teamMemberRepository.teamMemberOfIdentity(
                        tenantId,
                        aCommand.getUsername());
        if (teamMember != null) {
            teamMember.disable(aCommand.getOccurredOn());
        }
    }
}
```

Note that when we dispatch to the TeamMember disable() command method, we are required to pass an occurredOn value from the command object. The TeamMember will use this internally to make certain that disabling takes place only if it should:

> 请注意，当我们调用 TeamMember 的 disable（）命令方法时，我们需要传入命令对象中的 occurredOn 属性。TeamMember 将使用该属性来确保命令的正确执行：

```java
package com.saasovation.agilepm.domain.model.team;
...
public abstract class Member extends Entity  {
    ...
    private MemberChangeTracker changeTracker;
    ...
    public void disable(Date asOfDate) {
        if (this.changeTracker().canToggleEnabling(asOfDate)) {
            this.setEnabled(false);
            this.setChangeTracker(
                    this.changeTracker().enablingOn(asOfDate));
        }
    }

    public void enable(Date asOfDate) {
        if (this.changeTracker().canToggleEnabling(asOfDate)) {
            this.setEnabled(true);
            this.setChangeTracker(
                    this.changeTracker().enablingOn(asOfDate));
        }
    }
    ...
}
```

Note that this Aggregate behavior is provided by a common abstract base class, Member. Both the disable() and the enable() methods are designed to query a changeTracker to determine whether the requested operation can be carried out according to the asOfDate parameter (the command’s occurredOn value). The MemberChangeTracker Value Object maintains the occurrence of the most recent related operation and uses that to answer the query:

> 以上聚合行为是由一个抽象基类提供的，即 Member。其中的 disable（）和 enable（）方法都通过一个 changeTracker 来决定是否应该执行命令操作，此时的 asOfDate 参数即为所传入的 occurredOn 属性值。值对象 MemberChangeTracker 维护了最近一次操作的相关信息：

```java
package com.saasovation.agilepm.domain.model.team;
...
public final class MemberChangeTracker implements Serializable  {
    private Date emailAddressChangedOn;
    private Date enablingOn;
    private Date nameChangedOn;
    ...
    public boolean canToggleEnabling(Date asOfDate) {
        return this.enablingOn().before(asOfDate);
    }
    ...
    public MemberChangeTracker enablingOn(Date asOfDate) {
        return new MemberChangeTracker(
                asOfDate,
                this.nameChangedOn(),
                this.emailAddressChangedOn());
    }
    ...
}
```

If the operation is permitted and carried out, a replacement MemberChange-Tracker instance is obtained by using the corresponding enablingOn() method. Since we can expect PersonNameChanged and PersonContactInformationChanged changes to possibly arrive out of order, the same kinds of facilities are available with emailAddressChangedOn and nameChangedOn. In fact, there is one additional check for the case of e-mail address changes. It’s possible that PersonContactInformationChanged Events are indicating a change of telephone number or postal address rather than a less common e-mail address change:

> 如果 MemberChangeTracker 的 canToggleEnabling（）方法返回 true，即允许下一步操作，那么原有的 MemberChangeTracker 实例将被 enablingOn（）方法返回的新实例所替代。对于 PersonNameChanged 和 PersonContactInformationChanged 事件来说，它们也是有可能无序抵达的，因此它们也将分别拥有相应的 nameChangedOn 和 emailAddressChangedOn 属性。对于 PersonContactInformationChanged 事件来说，更多的时候可能是关于更改电话号码或邮寄地址的，而不是 E-mail 地址：

```java
package com.saasovation.agilepm.domain.model.team;
...
public abstract class Member extends Entity  {
    ...
    public void changeEmailAddress(
        String anEmailAddress,
        Date asOfDate) {
        if (this.changeTracker().canChangeEmailAddress(asOfDate) &&
            !this.emailAddress().equals(anEmailAddress)) {
            this.setEmailAddress(anEmailAddress);
            this.setChangeTracker(
                this.changeTracker().emailAddressChangedOn(asOfDate));
        }
    }
    ...
}
```

Here we check to see if in fact the e-mail address has changed. If it has not, we don’t want to track it as changed. If we did so, an out-of-order Event of the same type that did in fact carry a changed e-mail address would be ignored.

> 这里，我们检查 E-mail 地址是否发生了改变。如果没有，那么我们将不予跟踪。而如果的确跟踪了，那么真正包含有 E-mail 修改信息的事件将被忽略掉。

The MemberChangeTracker also serves to make Member subclass command operations idempotent, such that when the same notification is delivered multiple times by the messaging infrastructure, redundant deliveries are ignored.

> MemberChangeTracker 还使得 Member 的子类的命令操作是幂等的，即如果同一份通知被消息基础设施投递了多次，那么多余的通知将被忽略掉。

We might argue that introducing the MemberChangeTracker in the Aggregate design is a mistake. We might conclude that this has nothing to do with the Ubiquitous Language of Scrum-based teams. That is true. However, we never expose the MemberChangeTracker outside the Aggregate boundary. It is an implementation detail, and clients will never know it exists. The only detail that clients are aware of is that they must supply the occurredOn value for when the corresponding fact of a modification took place. What is more, this is exactly the kind of implementation detail that Pat Helland calls for as he describes how partner relationships are managed in his treatment of scalable, distributed systems that are eventually consistent. In that paper [Helland], specifically see section 5, “Activities: Coping with Messy Messages.”

> 当然，我们也可以认为引入 MemberChangeTracker 是聚合设计的一个错误，因为它与 Scrum 所使用的通用语言毫无关系。这是事实，但是，我们并没有把 MemberChangeTracker 暴露到聚合边界之外。这只是一个实现上的细节而已，客户端根本意识不到这个 MemberChangeTracker 的存在，它唯一需要提供的只是 occurredOn 属性值。另外，这也正是 Pat Helland 在描述如何处理分布式系统之间的合作者关系时所采用的实现细节。特别地，请参考[Helland]的第 5 节，“Activities：Coping with Messy Messages.”

Now, back to dealing with our new responsibilities . . .

> 现在，让我们回到对新职责的处理……

Although this is a very basic example of maintaining changes to duplicate information originating in a foreign Bounded Context, it is not a trivial responsibility to take on, at least not if you are using a messaging mechanism that could deliver messages out of order and more than once.1 Further, when we realize all of the possible operations in the Identity and Access Context that could have some kind of impact on just the few attributes that we maintain in Member, it can be a wake-up call:

> 对于在不同限界上下文间维护复制性信息来说，虽然以上只是一个非常基本的例子，但是其中的职责分离却并非琐碎之事，至少在使用消息机制时是这样的。因为此时我们需要考虑到消息无序抵达的情况和多次投递的情况[1]。另外，在身份与访问上下文中的所有操作都只会对 Member 的部分属性产生影响。意识到这一点，我们便可以总结出以下事件：

1. This could be a case where using the RESTful approach to notification consumption could be a distinct advantage since the notifications are guaranteed to be delivered in the same order in which they were appended to the Event Store (4, Appendix A). The notifications, from first to last, can be consumed over and over again for different reasons with the same order guarantees each time.

- PersonContactInformationChanged
- PersonNameChanged
- UserAssignedToRole
- UserUnassignedFromRole

---

And then we realize that there are a few other Events that could be just as important to react to:

> 还有另外的一些事件也是重要的：

- UserEnablementChanged
- TenantActivated
- TenantDeactivated

These facts emphasize that, if at all possible, it is best to minimize or even completely eliminate information duplication across Bounded Contexts. It may not be possible to entirely avoid the duplication of information. SLAs may make it impractical to retrieve remote data every time it is needed. That’s one of the motivations the team had to hold the personal name of the User and the user’s e-mail address locally. However, having the goal to reduce the amount of foreign information we take responsibility for will make our jobs much easier. It’s integrating with a minimalist’s mindset.

> 以上事实所强调的是：在有可能的情况下，我们应该最小化不同限界上下文之间的信息复制，甚至彻底消除。当然，要完全避免信息复制是不可能的。服务层协议（SLA）并不能保证每次对远程数据的获取都能成功。这也是为什么 SaaSOvation 的团队需要在本地上下文中维护 User 的名字和 E-mail 等信息。然而，对于那些位于我们自己职责之下的外部信息来说，信息量越少，我们的工作也越简单。这也是集成限界上下文的“最小化信息”原则。

Of course, there is no way to avoid duplication of tenant and user identity, and identity duplication across Bounded Contexts is necessary in general. That is one of the primary ways that Bounded Contexts can integrate at all. Besides, identity is safe to share because it is immutable. We can even use Aggregate disabling and soft deletions to ensure that referenced objects never disappear, as we do, for example, with Tenant, User, ProductOwner, and TeamMember.

> 当然，对于 Tenant 和 User 的唯一标识，我们是无法避免重复的，因为它们是必要的。这也是集成限界上下文的首要方法之一。另外，共享唯一标识是安全的，因为它们不会改变。我们甚至可以通过禁用聚合和软删除的方式来保证那些被引用的对象从不消失，比如 Tenant、User、ProudctOwner 和 TeamMember 便使用了这样的方法。

This call to attention doesn’t mean that Domain Events should not be enriched with information-conveying properties. Certainly, Events must provide enough information to inform consumers of the kinds of steps that they must take in response to past facts. Still, it is possible for Event data to be used to perform calculations and derive state in consuming foreign Bounded Contexts while not actually holding on to and assuming the responsibility for keeping it synchronized with its official state located in the system of record.

> 以上提醒并不表示领域事件就不应该包含信息属性。需要肯定的是，领域事件必须包含足够的信息以通知消费方完成相应的操作。此外，消费方的限界上下文可以使用事件数据来执行计算操作或者得出其他状态，即此时消费方并不用维护事件数据本身，也不用保持与远端系统的同步。

### 13.3.3 Long-Running Processes, and Avoiding Responsibility 长时处理过程，以及避免职责

If we likened what we described in the previous section to being a responsible adult, we might compare this section to an attempt to return to our teenage years. You know, adults have to assume all kinds of responsibility. Parents have to buy cars, insure them, pay to put gasoline in the tank, and spend their money to repair them. As teens we just want to use our parents’ car, but not pay for any of its expenses. There’s no way teenagers are going to make a car payment for their parents, fill the tank with gasoline, pay for a mechanic, or cover the cost of insurance. They just allow their parents to take care of that horrible R-word stuff so they can have all the fun.

> 如果我们将前一节所描述的看成是一个负责任的成年人，那么本节将带你回归到青年时代。你知道，成年人需要承担各种各样的职责。父母需要购买汽车，然后为汽车购买保险，再掏钱给汽车加油，最后还得花钱维修。作为年轻人来说，我们只是使用父母的汽车就行了，而不用担心花销。你想让一个青少年掏钱给父母买车、加油、维修然后购买保险，几乎是不可能的。他们只是让父母承担所有的责任，自己却逍遥自在去了。

What we are doing in this section is having fun with Long-Running Processes (4), but making sure we refuse to accept any of the painful responsibilities required when we duplicate information from other Bounded Contexts. We will just let the system of record deal with its own information after we’ve had all the fun making that foreign Bounded Context create and maintain data for us.

> 在本节中，我们将讲到长时处理过程（4），对于在不同限界上下文之间复制信息时所要求的职责来说，我们将予以拒绝。我们将使那些记录数据的系统自行处理自己的信息。

In Context Maps (3) we were presented with the Create a Product use case:

> 在上下文映射图（3）中，我们展示了一个“创建产品”的用例：

Precondition: The collaboration feature is enabled (option was purchased).

> 前提条件：协作功能可用（附加功能需要购买）。

1. The user provides Product descriptive information.
2. The user indicates a desire for a team discussion.
3. The user requests that the defined Product be created.
4. The system creates the Product with a Forum and Discussion.

---

> 1. 用户提供 Product 的描述信息。
> 2. 用户希望为该 Product 创建一个 Discussion。
> 3. 用户发出创建 Product 的请求。
> 4. 系统创建一个 Product，连同 Forum 和 Discussion。

Here’s where the fun begins, and where we kick responsibility across the network.

In Context Maps (3) the team proposed using a RESTful approach to integration between these two Bounded Contexts. However, the team finally settled on a message-based solution instead.

Also, one of the first things that you may notice is that the proposed concept originally added to the Ubiquitous Language as Discussion (in Chapter 3) has been refined. The Agile Project Management team saw the need to differentiate between the types of discussions, so there are now two different types: ProductDiscussion and BacklogItemDiscussion. (In this section we are concerned only with ProductDiscussion.) Both Value Objects have the same basic state and behavior, but the distinction adds type safety to help developers avoid attaching the wrong discussions to Product and Backlog-Item. For all practical purposes, they are the same. Each of these two discussion types just holds its availability and, if a discussion was established, the identity of the actual Discussion Aggregate instance in the Collaboration Context.

> 你可能会注意到，先前关于 Discussion（第 3 章）的通用语言在这里被进一步改善了。敏捷项目管理团队认为应该区分开两种类型的 Discussion，于是有了 ProductDiscussion 和 BacklogItemDiscussion（在本节中，我们只关注于 ProductDiscussion）。这两个值对象都具有相同的状态和行为，但是这样的区分有助于类型的安全性，从而避免了开发者将错误的 Discussion 添加到 Product 和 BacklogItem 中。而在实际应用中，它们却是一样的。这两个值对象都维护了自身的可见性信息，同时还包含协作上下文中 Discussion 聚合的唯一标识。

It is worth stating that the original proposal in the Agile Project Management Context to name one Value Object the same as the Aggregate in the Collaboration Context was not an error in judgment. Thus, to be completely clear, the Value Object’s name was not changed from Discussion to ProductDiscussion in order to distinguish it from the Aggregate in the Collaboration Context. From the standpoint of Context Mapping it would have been perfectly fine to leave the Value Object’s name as it was, because the Context is what distinguished the two objects. The decision to create two distinct Value types in the Agile Project Management Context was made only from the requirements of the isolated local model.

> 需要指出的是，虽然敏捷项目管理上下文中的值对象 Discussion 和协作上下文中的聚合 Discussion 拥有相同的名字，但是这并不是一个错误。因此，我们并没有将值对象 Discussion 重新命名为 ProductDiscussion 以示区分。从上下文映射的角度来看，维持 Discussion 值对象原有的名字是完全可以的，因为限界上下文已经对这两个对象进行了区分。在敏捷项目管理上下文中创建两个类型不同的值对象完全是出于本地模型的考虑。

To dive in, let’s first take a look at the Application Service (API) that is used to create a Product:

> 让我们首先来看看创建 Product 的应用服务：

```java
package com.saasovation.agilepm.application;
...
public class ProductService ... {
    @Autowired
    private ProductRepository productRepository;
    @Autowired
    private ProductOwnerRepository productOwnerRepository;
    ...
    @Transactional
    public String newProductWithDiscussion(
                NewProductCommand aCommand) {
        return this.newProductWith(
                aCommand.getTenantId(),
                aCommand.getProductOwnerId(),
                aCommand.getName(),
                aCommand.getDescription(),
                this.requestDiscussionIfAvailable());
    }
    ...
}
```

There are actually two ways to create a new Product. The first method, not shown here, creates a Product without a Discussion, while the one seen here does attempt to cause a ProductDiscussion to eventually be created and attached to the Product. The two internal methods, newProduct-With() and requestDiscussionIfAvailable(), are not shown here. The latter method is used to check whether or not the CollabOvation add-on is enabled. If it is, the availability state REQUESTED is returned; otherwise, the state return value is ADD_ON_NOT_ENABLED. Method newProductWith() invokes the Product constructor, so let’s look at the constructor next:

> 事实上，有两种方式都可以创建一个新的 Product。第一种方式不需要创建 Discussion，这里未予显示。上例所示的是第二种方式，它需要在创建 Product 时，连同创建一个 ProductDiscussion。两个内部方法，newProductWith（）和 requestDiscussionIfAvailable（），在这里也未予以显示。后者用于检查 CollabOvation 的附加功能是否可用。如果可用，那么它将返回 REQUESTED；否则返回 ADD_ON_NOT_ENABLED。方法 newProductWith（）将调用 Product 的构造函数，该构造函数如下所示：

```java
package com.saasovation.agilepm.domain.model.product;
...
public class Product extends ConcurrencySafeEntity  {
    ...
    public Product(
            TenantId aTenantId,
            ProductId aProductId,
            ProductOwnerId aProductOwnerId,
            String aName,
            String aDescription,
            DiscussionAvailability aDiscussionAvailability) {
        this();
        this.setTenantId(aTenantId);
        this.setProductId(aProductId);
        this.setProductOwnerId(aProductOwnerId);
        this.setName(aName);
        this.setDescription(aDescription);
        this.setDiscussion(
                ProductDiscussion.fromAvailability(
                        aDiscussionAvailability));
        DomainEventPublisher
            .instance()
            .publish(new ProductCreated(
                this.tenantId(),
                this.productId(),
                this.productOwnerId(),
                this.name(),
                this.description(),
                this.discussion().availability().isRequested()));
    }
    ...
}
```

The client is required to pass a DiscussionAvailability, which may convey one of the following states: ADD_ON_NOT_ENABLED, NOT_REQUESTED, or REQUESTED. The READY state is reserved as a completion state. Either of the first two states results in the creation of a Product-Discussion with that exact state, which means there won’t be an associated discussion, at least not as a result of construction. Given a request with the third state, REQUESTED, the ProductDiscussion will be created with a PENDING_SETUP state. Here’s the ProductDiscussion Factory Method used by the Product constructor:

> 客户端需要传入一个 DiscussionAvailability 参数，该参数拥有以下状态值：ADD_ON_NOT_ENABLED、NOT_REQUESTED 和 REQUESTED。另外，状态值 READY 表示完成状态。对于在前两种状态下所创建的 ProductDiscussion 对象，它将维护一份原有状态的属性，也即此时所创建的产品并没有与之关联的讨论。对于第三种状态 REQUESTED，所创建的 ProductDiscussion 对象将拥有 PENDING_SETUP 状态。以下是 ProductDiscussion 的工厂方法，该方法被 Product 的构造函数所使用：

```java
package com.saasovation.agilepm.domain.model.product;
...
public final class ProductDiscussion implements Serializable {
    ...
    public static ProductDiscussion fromAvailability(
            DiscussionAvailability anAvailability) {
        if (anAvailability.isReady()) {
            throw new IllegalArgumentException(
                    "Cannot be created ready.");
        }
        DiscussionDescriptor descriptor =
                new DiscussionDescriptor(
                        DiscussionDescriptor.UNDEFINED_ID);
        return new ProductDiscussion(descriptor, anAvailability);
    }
    ...
}
```

As long as the request is not for the READY state, which would be a problem, we get a ProductDiscussion with one of the three other states and an undefined descriptor. If the state is REQUESTED, a Long-Running Process will manage the creation of the collaborative discussion and its subsequent initiation with the Product. How? Recall that the last thing the Product constructor does is publish the ProductCreated Event:

> 只要此时的请求不是为了达到 READY 状态，那么这便是有问题的，此时我们将得到一个未定义的 DiscussionDescriptor。如果状态为 REQUESTED，那么长时处理过程将负责对 Discussion 的创建以及后续的初始化。问题是，它将如何做到这一步？回忆一下，Procuct 构造函数所做的最后一件事情便是发布 ProductCreated 事件：

```java
package com.saasovation.agilepm.domain.model.product;
    ...
    public Product(...) {
        ...
        DomainEventPublisher
            .instance()
            .publish(new ProductCreated(
                this.tenantId(),
                this.productId(),
                this.productOwnerId(),
                this.name(),
                this.description(),
                this.discussion().availability().isRequested()));
    }
    ...
}
```

If the state of the discussion availability is REQUESTED, the last parameter to the Event constructor will be true, which is exactly what is needed to start the Long-Running Process.

> 如果此时 Discussion 的状态为 REQUEST，那么传给 ProductCreated 构造函数的最后一个参数将为 true，这正是启动长时处理过程所需要的。

Think back to Domain Events (8); every single Event instance, including those of type ProductCreated, is appended to an Event Store for the specific Bounded Context in which the Event occurred. All newly appended Events are then forwarded from the Event Store to interested parties by means of a messaging mechanism. In the case of SaaSOvation, the teams have decided to use RabbitMQ for that purpose. We need to create a simple Long-Running Process to manage the creation of the discussion and then attach it to the Product.

> 在领域事件（8）中我们讲到，每一个事件实例，包括 ProductCreated，都会被添加到事件存储中，该事件存储是专门为产生该事件的限界上下文创建的。所有新加事件都会由事件存储通过消息机制转发到兴趣相关方。对于 SaaSOvation 公司来说，开发团队决定采用 RabbitMQ。我们需要创建一个简单的长时处理过程来创建 Discussion，并且将该 Discussion 赋给一个 Product。

Before moving on to the details of the Long-Running Process, let’s consider one more possible way that a discussion is requested. What if when a given Product instance is first created, either a discussion is not requested, or the collaboration add-on is only enabled? Later on the product owner decides to add a discussion, and the add-on is now available. The product owner can now use this command method on the Product:

> 在讨论长时处理过程的细节之前，让我们再来看看另一种请求创建 Discussion 的方式。有可能发生的情况是：在 Product 实例创建之初，客户端并没有发出创建 Discussion 的请求，或者此时的协作附加功能刚刚被启用。之后，产品负责人决定为该 Product 添加一个 Discussion，届时协作附加功能也可用了。此时，产品负责人便可以使用以下 Product 的命令方法：

```java
package com.saasovation.agilepm.domain.model.product;
...
public class Product extends ConcurrencySafeEntity  {
    ...
    public void requestDiscussion(
            DiscussionAvailability aDiscussionAvailability) {
        if (!this.discussion().availability().isReady()) {
            this.setDiscussion(
                    ProductDiscussion.fromAvailability(
                            aDiscussionAvailability));
            DomainEventPublisher
                .instance()
                .publish(new ProductDiscussionRequested(
                    this.tenantId(),
                    this.productId(),
                    this.productOwnerId(),
                    this.name(),
                    this.description(),
                    this.discussion().availability().isRequested()));
        }
    }
    ...
}
```

Method requestDiscussion() takes the familiar Discussion-Availability parameter, because the client must prove to the Product that the collaboration add-on is enabled. Of course, the client could cheat here and always pass REQUESTED, but that would just end up in a dead-end bug if the add-on is actually not available. Here, too, if the state of the discussion availability is REQUESTED, the last parameter to the Event constructor will be true, which is exactly what is needed to start the Long-Running Process:

> 这里的 requestDiscussion（）方法也使用了 DiscussionAvailability 参数，因为客户端需要向 Product 证实此时协作附加功能已经被启用了。当然，客户端可以总是传入 REQUESTED 状态以作欺骗，但是如果此时的协作附加功能并不可用，那么这将导致一个非常严重的 bug。和前面的 ProductCreated 一样，如果所传入的是 REQUESTED，那么 ProductDiscussionRequested 构造函数的最后一个参数将为 true，这正是启动长时处理过程所需要的：

```java
package com.saasovation.agilepm.domain.model.product;
...
public class ProductDiscussionRequested implements DomainEvent {
    ...
    public ProductDiscussionRequested(
            TenantId aTenantId,
            ProductId aProductId,
            ProductOwnerId aProductOwnerId,
            String aName,
            String aDescription,
            boolean isRequestingDiscussion) {
        ...
    }
    ...
}
```

This Event has exactly the same properties as ProductCreated, which will allow both Event types to be handled by the same listener.

> 这里的 ProductDiscussionRequested 事件和 ProductCreated 事件拥有相同的属性，因此它们可以通过同一个消息监听器进行处理。

We might ask whether publishing this Event makes any sense if the availability state is not REQUESTED. It does make sense, because whether or not the request can be fulfilled, the request was still made, unless it is currently in READY state. It is the responsibility of listeners to determine whether or not to actually do something in response to the Event. Perhaps receiving this Event with isRequestingDiscussion set to false indicates a problem, or setup of the add-on is in progress but still not done. Therefore, some intervention may be necessary. The process may need to send an e-mail to the administrator group, for example.

> 你可能会问，如果此时的可用性状态不为 REQUESTED，那么发布该事件又有什么意义呢？这的确是有意义的，因为无论请求是否会得到处理，请求依然会发出，除非此时的状态为 READY。要决定是否对事件进行响应，这是属于消息监听器的职责。也许 isRequestingDiscussion=false 的情况表示系统出了问题，或者协作附加功能还未就绪。因此，一些干预是有必要的。比如，此时的长时处理过程可能会向管理员发送一封 E-mail。

The classes used to manage the Long-Running Process on the Agile Project Management Context side are similar to those used to manage the creation and maintenance of the ProductOwner and TeamMember Aggregates (see the previous section). Each of the listeners presented here is wired using Spring such that it is instantiated as the Spring application context is created for this Bounded Context. The first listener registers itself to receive two kinds of notifications on the AGILEPM_EXCHANGE_NAME, ProductCreated, and ProductDiscussionRequested:

> 在敏捷项目管理上下文中，长时处理过程所需的类与先前（请参考上一节）创建和维护 ProductOwner 和 TeamMember 的类相似。每个监听器都由 Spring 容器所管理，在该上下文的 Spring 程序启动时，这些监听器也随之初始化。第一个监听器用于从 AGILEPM_EXCHANGE_NAME 交换器中接收两种类型的通知，即 ProductCreated 和 ProductDiscussionRequested：

```java
package com.saasovation.agilepm.infrastructure.messaging;
...
public class ProductDiscussionRequestedListener
       extends ExchangeListener {
    ...
    @Override
    protected String exchangeName() {
        return Exchanges.AGILEPM_EXCHANGE_NAME;
    }
    ...
    @Override
    protected String[] listensToEvents() {
        return new String[] {
                "com.saasovation.agilepm.domain.model.product.ProductCreated",
                "com.saasovation.agilepm.domain.model.product.ProductDiscussionRequested"
                };
    }
    ...
}
```

The COLLABORATION_EXCHANGE_NAME is the interest of the second listener, and specifically for notification DiscussionStarted:

> 第二个监听器将从 COLLABORATION_EXCHANGE_NAME 交换器中接收 DiscussionStarted 事件：

```java
package com.saasovation.agilepm.infrastructure.messaging;
...
public class DiscussionStartedListener extends ExchangeListener {
    ...
    @Override
    protected String exchangeName() {
        return Exchanges.COLLABORATION_EXCHANGE_NAME;
    }
    ...
    @Override
    protected String[] listensToEvents() {
        return new String[] {
                "com.saasovation.collaboration.domain.model.forum.DiscussionStarted"
                };
    }
    ...
}
```

You can probably see where this is going. If either ProductCreated or ProductDiscussionRequested is received by the first listener, it will dispatch a command to the Collaboration Context to have a new Forum and Discussion created on behalf of the Product. When that request is fulfilled by the components in the Collaboration Context, the DiscussionStarted notification is published and, once received, the corresponding discussion identity will be initiated on the Product. That’s the long and short of this Long-Running Process. Here is how the filteredDispatch() works in the first listener:

> 你可能已经看出一些眉目了。当第一个监听器接收到 ProductCreated 或者 ProductDiscussionRequested 事件时，它将向协作上下文发起一个命令，以此为 Product 创建一个新的 Forum 和 Discussion。当协作上下文处理完对该命令请求时，它将发布 DiscussionStarted 事件，该事件将进一步被第二个监听器所接收，然后在 Product 中创建该 Discussion 的唯一标识。这就是整个长时处理过程。以下是第一个监听器的 filteredDispatch（）方法：

```java
package com.saasovation.agilepm.infrastructure.messaging;
...
public class ProductDiscussionRequestedListener
        extends ExchangeListener {
    private static final String COMMAND =
           "com.saasovation.collaboration.discussion.CreateExclusiveDiscussion";
    ...
    @Override
    protected void filteredDispatch(
                String aType,
                String aTextMessage) {
        NotificationReader reader =
                new NotificationReader(aTextMessage);
        if (!reader.eventBooleanValue("requestingDiscussion")) {
            return;
        }
        Properties parameters = this.parametersFrom(reader);
        PropertiesSerializer serializer =
                PropertiesSerializer.instance();
        String serialization = serializer.serialize(parameters);
        String commandId = this.commandIdFrom(parameters);
        this.messageProducer()
            .send(
                serialization,
                MessageParameters
                    .durableTextParameters(
                            COMMAND,
                            commandId,
                            new Date()))
            .close();
    }
    ...
}
```

In the case of either Event type, ProductCreated or Product-DiscussionRequested, if the requestingDiscussion attribute is false, we ignore the Event. Otherwise, we build up a CreateExclusive-Discussion command from the Event’s state and send the command to the message exchange of the Collaboration Context.

> 对于 ProductCreated 和 ProductDiscussion Re que st e d 事件，如果 requestingDiscussion 属性值为 false，那么 filteredDispatch（）方法将忽略该事件。否则，我们将通过事件状态创建一个 CreateExclusiveDiscussion 命令对象，然后将该命令对象发送到协作上下文的消息交换器中。

This is a good time to pause and reflect on how this process is designed. Should the Agile Project Management Context really set up a listener to an Event published by a local Aggregate? Would it be better to create a listener for the ProductCreated Event in the Collaboration Context instead? If we did so, we could simply have the listener in the Collaboration Context manage the creation of the exclusive Forum and Discussion, and it would eliminate a bit of code from the Agile Project Management Context. To determine which is the better approach requires the consideration of a few factors.

> 现在，让我们暂停一下，看看该长时处理过程是如何设计的。在敏捷项目管理上下文中，我们应该为本地聚合所发出的事件创建一个监听器吗？在协作上下文中为 ProductCreated 创建监听器是不是更好呢？这样，我们只需要使用协作上下文中的监听器来管理对专属的 Forum 和 Discussion 的创建；另外，还可以去除敏捷项目管理上下文中的部分代码。要决定哪种方式更好，我们需要考虑诸多因素。

Does it make sense that an upstream Bounded Context listens for Events published from a downstream Context? Or, in an Event-Driven Architecture (4), are systems really upstream and downstream to each other? Need they be cast in that mold? Possibly the more important factor to consider is whether it would be correct for a ProductCreated Event to be interpreted in the Collaboration Context as indicating that an exclusive Forum and Discussion should be created. In fact, does ProductCreated actually have any meaning at all to the Collaboration Context? How many other Contexts may eventually desire similar automatic support for this very feature given their own unique Event types? Is it best to place such a burden to support any number of foreign Events as creation commands on the Collaboration Context? Yet, there is another factor to consider, which requires us to more carefully manage the success of Long-Running Processes. This topic, discussed just a bit later, may help to settle why we’ve approached it in this particular way.

> 在上游限界上下文中监听下游上下文中发布的事件，这样合理吗？或者，在事件驱动架构（4）中，各个系统之间的确存在着上下游关系吗？它们需要迎合这种关系吗？可能更重要的因素在于：如果由协作上下文来处理 ProductCreated 事件，并且由此创建专属的 Forum 和 Discussion，这种方式是否正确？还有多少其他的限界上下文也希望得到类似的支持？将这些职责放在协作上下文中是否是最好的方式？此外，还存在另外一个因素，它要求我们更仔细地管理长时处理过程。对此，我们将在稍后进行讨论。

Now, back to the example . . . Once received in the Collaboration Context, the command is adapted to pass to the ForumService, which is an Application Service. Note that this API has not yet been designed to use command parameters but rather takes individual attribute parameters:

> 回到前面的例子……当协作上下文接收到命令对象之后，它将调用应用服务 ForumService。请注意，ForumService 的 API 还未被设计成接收命令对象，而是单独的属性参数：

```java
package com.saasovation.collaboration.infrastructure.messaging;
...
public class ExclusiveDiscussionCreationListener
        extends ExchangeListener {
    @Autowired
    private ForumService forumService;
    ...
    @Override
    protected void filteredDispatch(
                String aType,
                String aTextMessage) {
        NotificationReader reader =
                new NotificationReader(aTextMessage);
        String tenantId = reader.eventStringValue("tenantId");
        String exclusiveOwnerId =
                reader.eventStringValue("exclusiveOwnerId");
        String forumSubject = reader.eventStringValue("forumTitle");
        String forumDescription =
                reader.eventStringValue("forumDescription");
        String discussionSubject =
                reader.eventStringValue("discussionSubject");
        String creatorId = reader.eventStringValue("creatorId");
        String moderatorId = reader.eventStringValue("moderatorId");

        forumService.startExclusiveForumWithDiscussion(
            tenantId,
            creatorId,
            moderatorId,
            forumSubject,
            forumDescription,
            discussionSubject,
            exclusiveOwnerId);
    }
    ...
}
```

That makes sense, but shouldn’t this ExclusiveDiscussionCreationListener send a response message back to the Agile Project Management Context? Well, not exactly. Both the Forum and Discussion Aggregates publish an Event in response to their respective creation: ForumStarted and DiscussionStarted. This Bounded Context publishes all its Domain Events though its exchange, defined by COLLABORATION_EXCHANGE_NAME. That’s why the DiscussionStartedListener in the Agile Project Management Context receives the DiscussionStarted Event. And here’s what that listener does when it receives the Event:

> 这是合乎情理的，但是，这里的 ExclusiveDiscussionCreationListener 是否应该向敏捷项目管理上下文发送一个应答呢？不见得。在 Forum 和 Discussion 聚合创建时，它们都会发布一个事件，分别为 ForumStarted 和 DiscussioinStarted。对于所有领域事件，协作上下文都将通过 COLLABORATION_EXCHANGE_NAME 交换器予以发布。因此，敏捷项目管理上下文将收到一个 DiscussionStarted 事件，此时，它将完成以下操作：

```java
package com.saasovation.agilepm.infrastructure.messaging;
...
public class DiscussionStartedListener extends ExchangeListener {
    @Autowired
    private ProductService productService;
    ...
    @Override
    protected void filteredDispatch(
                String aType,
                String aTextMessage) {
        NotificationReader reader =
                new NotificationReader(aTextMessage);
        String tenantId = reader.eventStringValue("tenant.id");
        String productId = reader.eventStringValue("exclusiveOwner");
        String discussionId =
                reader.eventStringValue("discussionId.id");

        productService.initiateDiscussion(
                new InitiateDiscussionCommand(
                    tenantId,
                    productId,
                    discussionId));
    }
    ...
}
```

This listener adapts the received notification’s Event properties to pass as a command to the ProductService Application Service. This initiateDiscussion() service method works like this:

> 该监听器使用 DiscussionStarted 事件中的属性来创建一个命令对象，然后将该对象传递给应用服务 ProductService。ProductService 中 initiateDiscussion（）方法的实现如下：

```java
package com.saasovation.agilepm.application;
...
public class ProductService ... {
    @Autowired
    private ProductRepository productRepository;
    ...
    @Transactional
    public void initiateDiscussion(
                InitiateDiscussionCommand aCommand) {
        Product product =
                productRepository
                    .productOfId(
                            new TenantId(aCommand.getTenantId()),
                            new ProductId(aCommand.getProductId()));
        if (product == null) {
            throw new IllegalStateException(
                    "Unknown product of tenant id: "
                    + aCommand.getTenantId()
                    + " and product id: "
                    + aCommand.getProductId());
        }
        product.initiateDiscussion(
                new DiscussionDescriptor(
                        aCommand.getDiscussionId()));
    }
    ...
}
```

Ultimately the Product Aggregate’s initiateDiscussion() behavior is executed:

> 最后执行的是 Product 聚合的 initiateDiscussion（）行为方法：

```java
package com.saasovation.agilepm.domain.model.product;
...
public class Product extends ConcurrencySafeEntity  {
    ...
    public void initiateDiscussion(DiscussionDescriptor aDescriptor) {
        if (aDescriptor == null) {
            throw new IllegalArgumentException(
                    "The descriptor must not be null.");
        }
        if (this.discussion().availability().isRequested()) {
            this.setDiscussion(this.discussion()
                           .nowReady(aDescriptor));
            DomainEventPublisher
                .instance()
                .publish(new ProductDiscussionInitiated(
                        this.tenantId(),
                        this.productId(),
                        this.discussion()));
        }
    }
    ...
}
```

If the Product discussion property is still in the REQUESTED state, it is transitioned to the READY state with the DiscussionDescriptor, which holds an identity reference to the exclusive Discussion in the Collaboration Context. The request for a Forum and Discussion to be created for and associated with the Product has just become consistent, although it happened eventually.

> 如果此时 Product 的 discussion 属性依然为 REQUESTED 状态，那么它将转成 READY 状态，并且将拥有一个 DiscussionDescriptor 属性，该 DiscussionDescriptor 携带了协作上下文中 Discussion 的唯一标识。此时，Forum、Discussion 和 Product 便达到了一致性，虽然这是通过事件的方式完成的。

However, if discussion is in the READY state at the time of this command invocation, it is not further transitioned. Is this a bug? No. It is one way to ensure that initiateDiscussion() is an idempotent operation. The assumption must be made that if the state is currently READY, the Long-Running Process has already completed. Perhaps any subsequent command invocation is due to a notification redelivery, since the team chose to use a messaging mechanism that delivers messages at least once. Whatever the case, we need not be concerned because the idempotent operation allows for any number of infrastructure and architectural influences to be harmlessly ignored when they should be. Further, in this specific case we didn’t need to design with a ProductChangeTracker as we did for the Member subclasses and their MemberChangeTracker. The simple fact that the discussion is READY tells us all we need to know.

> 然而，如果此时 discussion 的状态已经为 READY，那么它的状态将不会再改变了。这是一个 bug 吗？不是，这样可以保证 initiateDiscussion（）方法是一个幂等操作。因此，我们可以做出这样的假设：如果当前 discussion 的状态已经为 READY，那么该长时处理过程便已经完成了。也许，之后的命令调用都是由于消息的重新投递造成的，因为开发团队使用的消息机制可能会多次发送同一条消息。不管是什么原因，我们都不用担心，因为对于任何基础设施和架构所带来的影响，幂等操作都将予以忽略，并且是无害的。此外，在本例中，我们不用像先前的 MemberChangeTracker 一样设计一个 ProductChangeTracker，因为 discussion 的 READY 状态已经足够告诉我们所有了。

There could be a problem with this overall approach, however. What happens if the Long-Running Process experiences some sort of problem due to the messaging mechanism? How would we ensure that the process is run completely to its finish? Well, it’s probably time for the teenager to grow up a little.

> 但是，总的来说，这种方式还存在一个问题。如果该长时处理过程由于消息机制的原因出现了一些问题，这时我们应该怎么办呢？我们如何确保该长时处理过程能够运行直到完毕？好吧，是我们的青少年们成长的时候啦！

### 13.3.4 Process State Machines and Time-out Trackers 长时处理过程的状态机和超时跟踪器

We can make this process more mature by adding a concept similar to that described under Long-Running Processes (4). The SaaSOvation developers created a reusable concept that they named TimeConstrainedProcess-Tracker. A tracker watches for processes whose allotted time for completion has expired, and those that can be retried any number of times prior to expiring. The tracker design allows for retries at fixed intervals if desired and can eventually completely time-out after no retries at all, or after a determined number of retries.

> 在长时处理过程（4）中，我们讲到了“跟踪器”的概念，现在，通过采用相似的做法，我们可以使以上处理过程更加成熟。SaaSOvation 的开发者们创建了一个可重用的跟踪器概念：TimeConstrainedProcessTracker。该 TimeConstrainedProcessTracker 将监视那些指定完成时间已经过期了的处理过程；另外，对于那些在过期之前可以任意重试的处理过程，它也将进行监视。这种设计使得我们可以定期地对长时处理过程进行重试，或者在不进行重试（或在达到重试上限之后）的情况下彻底地超时。

To clarify, the tracker is not part of the Core Domain. It is rather part of a technical Subdomain that any SaaSOvation project can reuse. This means that in some cases we aren’t overly concerned with the rules of Aggregates when persisting trackers and later causing their modification. Trackers are relatively isolated and won’t tend to face concurrency conflicts since there is a one-to-one relationship with the associated process. However, if there are conflicts, we can count on messaging retries to help our cause. Any exception in the context of a notification delivery will cause the listener to NAK the message, which in turn causes RabbitMQ to redeliver. Still, we don’t anticipate the necessity of a great number of retries.

> 需要指出的是，跟踪器并不是核心域的一部分，而是属于技术子域的，该技术子域可以被 SaaSOvation 公司的所有项目所重用。这意味着，在有些情况下，在对跟踪器进行持久化或者修改的时候，我们不用严格地遵循聚合原则。另外，跟踪器也是相对独立的，并且与长时处理过程存在着一对一的关系，因此，并发冲突的可能性并不大。如果的确发生了并发冲突，那么我们依然可以依赖于消息重发来解决问题。在消息投递过程中产生的任何异常都会导致监听器做出否定应答，进而使得 RabbitMQ 重发消息。另外，我们并不期待对处理过程进行大量的重试。

It is the Product that holds the current state of the process, and in that context a tracker will publish the following Event when a retry interval is reached, or when the observed process completely times out:

> Product 维护了长时处理过程的当前状态，当重试间隔抵达，或者处理过程彻底超时时，跟踪器将发布以下事件：

```java
package com.saasovation.agilepm.domain.model.product;

import com.saasovation.common.domain.model.process.ProcessId;
import com.saasovation.common.domain.model.process.ProcessTimedOut;

public class ProductDiscussionRequestTimedOut extends ProcessTimedOut {
    public ProductDiscussionRequestTimedOut(
            String aTenantId,
            ProcessId aProcessId,
            int aTotalRetriesPermitted,
            int aRetryCount) {
        super(aTenantId, aProcessId,
              aTotalRetriesPermitted, aRetryCount);
    }
}
```

Events that subclass ProcessTimedOut are used by the tracker when retry intervals or full time-outs have been reached. Event listeners can use Event method hasFullyTimedOut() to determine whether the Event signifies a full time-out or is just a retry. If retries are permitted, assuming listeners have use of the ProcessTimedOut class, they can ask the Event for indicators and values such as allowsRetries(), retryCount(), totalRetriesPermitted(), and totalRetriesReached().

> 每一个监听器都可以通过调用 ProcessTimedOut 的 hasFullyTimedOut（）方法来确定该事件是否属于完全超时还是重试。如果是重试，那么监听器可以调用 ProcessTimedOut 的 allowsRetries（）、retryCount（）、totalRetriesPermitted（）和 totalRetriesReached（）等方法来获取更多的事件重试信息。

Armed with the ability to receive notifications about retries and time-outs, we can make the Product participate in a better process. First, we need to start the process, and we can do that from our existing ProductDiscussionRequestedListener:

> 在可以接收重试和超时通知的情况下，我们可以把 Product 放在一个更好的长时处理过程中。首先，我们需要启动该处理过程，此时我们可以使用既有的 Product-DiscussionRequestedListener：

```java
package com.saasovation.agilepm.infrastructure.messaging;
...
public class ProductDiscussionRequestedListener
        extends ExchangeListener {
    @Override
    protected void filteredDispatch(
                String aType,
                String aTextMessage) {
        NotificationReader reader =
                new NotificationReader(aTextMessage);

        if (!reader.eventBooleanValue("requestingDiscussion")) {
            return;
        }
        String tenantId = reader.eventStringValue("tenantId.id");
        String productId = reader.eventStringValue("product.id");
        productService.startDiscussionInitiation(
                new StartDiscussionInitiationCommand(
                        tenantId,
                        productId));

        // send command to Collaboration Context
        ...
    }
    ...
}
```

The ProductService creates the tracker and persists it, and it associates the process with the given Product:

> 这里的 ProductService 将创建了一个跟踪器，并对其持久化。然后，ProductService 将处理过程与 Product 关联起来：

```java
package com.saasovation.agilepm.application;
...
public class ProductService ... {
    ...
    @Transactional
    public void startDiscussionInitiation(
            StartDiscussionInitiationCommand aCommand) {
        Product product =
                productRepository
                    .productOfId(
                            new TenantId(aCommand.getTenantId()),
                            new ProductId(aCommand.getProductId()));
        if (product == null) {
            throw new IllegalStateException(
                    "Unknown product of tenant id: "
                    + aCommand.getTenantId()
                    + " and product id: "
                    + aCommand.getProductId());
        }
        String timedOutEventName =
                ProductDiscussionRequestTimedOut.class.getName();
        TimeConstrainedProcessTracker tracker =
                new TimeConstrainedProcessTracker(
                        product.tenantId().id(),
                        ProcessId.newProcessId(),
                        "Create discussion for product: "
                            + product.name(),
                        new Date(),
                        5L * 60L * 1000L, // retries every 5 minutes
                        3, // 3 total retries
                        timedOutEventName);
        processTrackerRepository.add(tracker);
        product.setDiscussionInitiationId(
                tracker.processId().id());
    }
    ...
}
```

The TimeConstrainedProcessTracker is instantiated to retry three times every five minutes, if necessary. True, we may not normally hard-code these values, but doing so allows us to see clearly how the tracker is created.

> 在必要的情况下，TimeConstrainedProcessTracker 将每隔 5 分钟便进行 3 次重试。诚然，通常来说我们都不会将这些数据硬编码到程序中，但是这使得我们清楚地看到一个跟踪器是如何创建的。

Did You Detect a Possible Problem Here? 你发现什么问题了吗？

The retry specification we are using could contribute to problems if we aren’t careful, but we’ll leave the design as is for now and act as if we think it’s all right.

> 如果不注意，我们这里所使用的重试规范可能会导致问题。但是，我们将维持原有设计，并且可以假设它是工作正常的。

It is this approach of creating a tracker on behalf of the Product that may best address the reason we have handled the ProductCreated Event locally, rather than having it interpreted in the Collaboration Context. This gives our own system the opportunity to set up process management and decouple the ProductCreated Event from the command in the Collaboration Context, namely, CreateExclusiveDiscussion.

> 正是由于有了这个代表 Product 的跟踪器，我们才有充足的理由将对 ProductCreated 事件的处理放在敏捷项目管理上下文本地，而不是交给协作上下文。这样，在我们自己的系统中，我们便可以对长时处理过程进行管理，并且在 ProductCreated 事件和协作上下文中的 CreateExclusiveDiscussion 命令对象之间进行解耦。

A background timer will fire regularly to check on process elapsed times. The timer will delegate to method checkForTimedOutProcesses() in the ProcessService:

> 一个后台定时器将定期地检查处理过程所消耗的时间。该定时器将检查功能委派给 ProcessService 的 checkForTimedOutProcesses（）方法：

```java
package com.saasovation.agilepm.application;
...
public class ProcessService ... {
    ...
    @Transactional
    public void checkForTimedOutProcesses() {
        Collection<TimeConstrainedProcessTracker> trackers =
            processTrackerRepository.allTimedOut();
        for (TimeConstrainedProcessTracker tracker : trackers) {
            tracker.informProcessTimedOut();
        }
    }
    ...
}
```

It’s the tracker’s method informProcessTimedOut() that confirms the need to retry or time-out a process and, if confirmed, publishes the ProcessTimedOut Event subclass.

> 跟踪器的 informProcessTimedOut（）方法将对重试或者超时进行确认。在确认之后，它将发布一个 ProcessTimedOut 的子类事件。

Next, we need to add a new listener to handle retries and time-outs. Up to three retries may occur every five minutes as needed. It’s the ProductDiscussionRetryListener:

> 接下来，我们需要添加一个新的监听器来处理重试或者超时。在需要的情况下，每隔 5 分钟便会发生 3 次重试。以下是 ProductDiscussionRetryListener：

```java
package com.saasovation.agilepm.infrastructure.messaging;
...
public class ProductDiscussionRetryListener extends ExchangeListener {
    @Autowired
    private ProcessService processService;
    ...
    @Override
    protected String exchangeName() {
        return Exchanges.AGILEPM_EXCHANGE_NAME;
    }

    @Override
    protected void filteredDispatch(
                String aType,
                String aTextMessage) {
        Notification notification =
            NotificationSerializer
                .instance()
                .deserialize(aTextMessage, Notification.class);
        ProductDiscussionRequestTimedOut event =
                notification.event();

        if (event.hasFullyTimedOut()) {
            productService.timeOutProductDiscussionRequest(
                    new TimeOutProductDiscussionRequestCommand(
                            event.tenantId(),
                            event.processId().id(),
                            event.occurredOn()));
        } else {
            productService.retryProductDiscussionRequest(
                    new RetryProductDiscussionRequestCommand(
                            event.tenantId(),
                            event.processId().id()));
        }
    }

    @Override
    protected String[] listensToEvents() {
        return new String[] {
                "com.saasovation.agilepm.process.ProductDiscussionRequestTimedOut"
                };
    }
}
```

This listener is interested only in ProductDiscussionRequestTimedOut Events and is designed to work with any number of retry and time-out permutations. It’s the process and tracker that determine how many times it could possibly be notified. Events will be sent under one of two possible conditions. The process may have completely timed out, or it may be a notification to retry the operation. In both cases the listener dispatches to the new Product-Service. If a complete time-out has occurred, the Application Service handles the situation:

> 该监听器只处理 ProductDiscussionRequestTimedOut 事件，并且可以处理重试和超时的任意组合。处理过程和跟踪器将决定所接收消息通知的次数。有两种情况将导致 ProductDiscussionRequestTimedOut 事件的发布，即处理过程彻底超时和重试。在这两种情况下，监听器都会将处理逻辑分发给新的 ProductService。在发生彻底超时的情况时，应用服务将予以处理：

```java
package com.saasovation.agilepm.application;
...
public class ProductService ... {
    ...
    @Transactional
    public void timeOutProductDiscussionRequest(
            TimeOutProductDiscussionRequestCommand aCommand) {
        ProcessId processId =
                ProcessId.existingProcessId(
                        aCommand.getProcessId());
        TenantId tenantId = new TenantId(aCommand.getTenantId());
        Product product =
                productRepository
                    .productOfDiscussionInitiationId(
                            tenantId,
                            processId.id());
        this.sendEmailForTimedOutProcess(product);
        product.failDiscussionInitiation();
    }
    ...
}
```

First an e-mail is sent to the product owner indicating that the discussion setup has failed, and then the Product is marked as failing discussion initiation. As seen from the new Product method failDiscussionInitiation(), we needed to declare an additional FAILED state as a DiscussionAvailability. Method failDiscussionInitiation() deals with the simple compensation necessary to keep the Product in a sound state:

> 首先，ProductService 将发送一封 E-mail 给产品负责人以告知创建讨论失败，然后 Product 将被标记为“初始化讨论失败”。对于 Product 中新的 failDiscussionInitiation（）方法来说，我们需要为 DiscussionAvailability 定义一个新的状态：FAILED。以下是 failDiscussionInitiation（）方法的实现：

```java
package com.saasovation.agilepm.domain.model.product;
...
public class Product extends ConcurrencySafeEntity  {
    ...
    public void failDiscussionInitiation() {
        if (!this.discussion().availability().isReady()) {
            this.setDiscussionInitiationId(null);
            this.setDiscussion(
                    ProductDiscussion
                        .fromAvailability(
                                DiscussionAvailability.FAILED));
        }
    }
    ...
}
```

What may be missing here is a new DiscussionRequestFailed Event being published by failDiscussionInitiation(). The team will have to consider the possible advantages of doing that. In fact, it could be that the e-mails sent to product owners and other administrative resources would be best handled as a result of just that Event. After all, what would happen if the ProductService method timeOutProductDiscussionRequest() encountered problems sending the e-mail? Things could get tedious. (Aha!) The team has made note of this and will return to address it later.

> 在 failDiscussionInitiation（）方法中，我们可能还缺少了一项操作：发布一个新的 DiscussionRequestFailed 事件。开发团队应该考虑这样做的好处。事实上，将前面的发送 E-mail 操作放在对 DiscussionRequestFailed 事件的处理中可能会更好。毕竟，如果 ProductService 的 timeOutProductDiscussionRequest（）方法在发送 E-mail 时出现了问题，我们应该怎么办呢？对此，开发团队做下了记录，并且决定之后回来解决这个问题。

On the other hand, if the Event indicates that a retry should be attempted, the listener delegates to the following operation in the ProductService:

另一方面，如果 ProductDiscussionRequestTimedOut 事件表明应该进行重试，那么监听器将调用 ProductService 的以下操作：

```java
package com.saasovation.agilepm.application;
...
public class ProductService ... {
    ...
    @Transactional
    public void retryProductDiscussionRequest(
            RetryProductDiscussionRequestCommand aCommand) {
        ProcessId processId =
                ProcessId.existingProcessId(
                        aCommand.getProcessId());
        TenantId tenantId = new TenantId(aCommand.getTenantId());
        Product product =
                productRepository
                    .productOfDiscussionInitiationId(
                            tenantId,
                            processId.id());
        if (product == null) {
            throw new IllegalStateException(
                    "Unknown product of tenant id: "
                    + aCommand.getTenantId()
                    + " and discussion initiation id: "
                    + processId.id());
        }
        this.requestProductDiscussion(
                new RequestProductDiscussionCommand(
                        aCommand.getTenantId(),
                        product.productId().id()));
    }
    ...
}
```

The Product is retrieved from its Repository by means of the associated ProcessId, which is set on the Product attribute discussionInitiationId. After the Product is obtained, it is used by the ProductService (self-delegation) to request the discussion again.

> 此时，我们通过资源库获取到 Product 实例。在查询时，所传入的 ProcessId 将用作 Product 的 discussionInitiationId。在获取到 Product 之后，它将被 ProductService 用于重新请求一个讨论。

Ultimately we get the desired outcome. When the discussion is started successfully, the Collaboration Context publishes the DiscussionStarted Event. Shortly following this our DiscussionStartedListener in the Agile Project Management Context receives the notification and dispatches to the ProductService as it did previously. This time, however, there’s new behavior:

> 最后，我们得到了想要的结果。在讨论成功开启之后，协作上下文将发布 DiscussionStarted 事件。之后，敏捷项目管理上下文的 DiscussionStartedListener 将监听到该事件，然后和先前一样，它会把处理逻辑分发给 ProductService。然而，这一次，出现了一些新的行为：

```java
package com.saasovation.agilepm.application;
...
public class ProductService ... {
    ...
    @Transactional
    public void initiateDiscussion(
               InitiateDiscussionCommand aCommand) {
        Product product =
                productRepository
                    .productOfId(
                            new TenantId(aCommand.getTenantId()),
                            new ProductId(aCommand.getProductId()));
        if (product == null) {
            throw new IllegalStateException(
                    "Unknown product of tenant id: "
                    + aCommand.getTenantId()
                    + " and product id: "
                    + aCommand.getProductId());
        }
        product.initiateDiscussion(
                new DiscussionDescriptor(
                        aCommand.getDiscussionId()));
        TimeConstrainedProcessTracker tracker =
                this.processTrackerRepository.trackerOfProcessId(
                        ProcessId.existingProcessId(
                                product.discussionInitiationId()));
        tracker.completed();
    }
    ...
}
```

The ProductService now provides the finishing behavior for the process, informing the tracker that it is completed(). From this point forward the tracker will no longer be selected as a retry or time-out notifier. The process is done.

> 此时的 ProductService 将执行长时处理过程的收尾工作，调用 completed（）方法以通知跟踪器处理过程执行完毕。在此之后，跟踪器将不再对重试或超时进行监视。整个长时处理过程到此成功完成。

Although we’re probably feeling good about the results, there could be a bit of a problem with this design. The way things stand, retrying requests to create a Product discussion could lead to some issues if we were to leave the design of the Collaboration Context as it is. The basic problem is that the operations in the Collaboration Context are currently not idempotent. Here is a breakdown of the minor design flaw and what should be done about it:

> 虽然我们可能会对这样的结果表示满意，但是对于协作上下文当前的设计来说，依然存在一些小问题。一个基本的问题是：此时协作上下文中的操作并不是幂等的。以下是这种设计的一些瑕疵以及我们应该如何应对：

- Since guaranteed, at least once, delivery of messages is in use, as soon as a message is sent to the exchange, it is sure to reach its listener(s) in a matter of time. If there is some delay in creating the new collaboration objects and it causes even one retry, the retry will in turn cause multiple sends of the same CreateExclusiveDiscussion command. All such commands will eventually be delivered. Thus, any retries will make the Collaboration Context attempt to create the same Forum and Discussion multiple times. We won’t actually end up with duplicates since uniqueness constraints are already imposed on Forum and Discussion properties. Thus, the multiple creation attempt errors will end up being benign. Yet, from the perspective of error logs the failed attempts will appear to be caused by bugs. The question is, While we still want to stipulate a complete process time-out, should the periodic retries be disabled?
- While it might seem that the solution is to disable retries in the Agile Project Management Context, the bottom line is that we need to make the Collaboration Context operations idempotent. Remember that RabbitMQ guarantees delivery at least once and thus may deliver the same command message multiple times, even if it is sent only once. Making the collaboration operations idempotent will prevent any attempt to create the same Forum and Discussion multiple times and will stifle logging of benign failures.
- It is possible for the Agile Project Management Context to fail when attempting to send the CreateExclusiveDiscussion command. If there is a problem with the message send, care must be taken to ensure that a resend is attempted until it succeeds. Otherwise, a request for creation of the Forum and Discussion will never be made. We can ensure command resend attempts in a few ways. If the message send fails, we can throw an exception from filteredDispatch(), which will cause a message NAK. As a result, RabbitMQ will consider it necessary to redeliver the ProductCreated or ProductDiscussionRequested Event notification, and our ProductDiscussionRequestedListener will receive it again. The other way to handle this is to simply retry the send until it succeeds, perhaps using a Capped Exponential Back-off. In the case of an offline RabbitMQ, retries could fail for quite a while. Thus, using a combination of message NAKs and retries could be the best approach. Still, if our process retries three times every five minutes, it could be all we need. After all, a complete process time-out results in an e-mail requesting human intervention.

---

> - 由于我们采用了可靠的消息机制，并且它有可能重复投递同一条消息，一旦消息被发送到交换器中，该消息必然会被监听器所监听到。如果在创建协作对象时发生了延迟，进而导致了消息的重发，那么这将导致多次发送同一个 CreateExclusiveDiscussion 命令对象的情况。这样的结果是：协作上下文将多次创建相同的 Forum 和 Discussion。当然，这并不会导致对象实例的重复存在，因为 Forum 和 Discussion 的属性已经具有唯一性约束了。因此，这种多次创建对象的错误将是良性的。但是，从错误日志来看，这却有可能使人认为这样的错误是系统中的 bug 所致。问题在于，在已经有超时处理的情况下，我们是否应该禁用周期性重试？
> - 虽然禁用敏捷项目管理上下文中的消息重试是一个不错的解决方案，但是这里的底线是：将协作上下文中的操作变成幂等操作。我们知道，RabbitMQ 有可能多次发送同一条命令消息，因此，如果我们将协作上下文中的操作变成幂等的，那么我们就可以避免多次创建 Forum 和 Discussion 的情况。
> - 敏捷项目管理上下文在发送 CreateExclusiveDiscussion 命令时，是有可能失败的。如果发生失败的情况，那么我们需要保证对命令的重发直到成功为止。否则，协作上下文将不能成功地创建 Forum 和 Discussion 对象。我们可以通过多种方式来保证对命令的重发。如果消息发送失败，我们可从 filteredDispatch（）方法中抛出一个异常，这将引发一个否定应答。之后，RabbitMQ 将重新发送 ProductCreated 或者 ProductDiscussionRequested 事件通知，而 ProductDiscussionRequestedListener 将再次监听到该事件。另一种方式则是简单地重复发送过程直到成功为止，比如可以使用盖帽指数后退算法。如果 RabbitMQ 不可用，那么我们有可能在很长一段时间里都无法成功地对消息进行重发。因此，将否定应答和消息重发结合起来使用可能是最好的方式。毕竟，如果发生彻底超时的情况，系统将发送一封 E-mail 以请求人为干预。

In the end, if the Collaboration Context’s ExclusiveDiscussionCreationListener could delegate to an idempotent Application Service operation, it would solve many of our problems:

> 总的来说，如果协作上下文中的 ExclusiveDiscussionCreationListener 能够将处理逻辑委派给一个幂等的应用服务，那么这将为我们解决很多问题：

```java
package com.saasovation.collaboration.application;
...
public class ForumService ... {
    ...
    @Transactional
    public Discussion startExclusiveForumWithDiscussion(
            String aTenantId,
            String aCreatorId,
            String aModeratorId,
            String aForumSubject,
            String aForumDescription,
            String aDiscussionSubject,
            String anExclusiveOwner) {
        Tenant tenant = new Tenant(aTenantId);
        Forum forum =
                forumRepository
                    .exclusiveForumOfOwner(
                            tenant,
                            anExclusiveOwner);
        if (forum == null) {
            forum = this.startForum(
                    tenant,
                    aCreatorId,
                    aModeratorId,
                    aForumSubject,
                    aForumDescription,
                    anExclusiveOwner);
        }
        Discussion discussion =
                discussionRepository
                    .exclusiveDiscussionOfOwner(
                            tenant,
                            anExclusiveOwner);
        if (discussion == null) {
            Author author =
                    collaboratorService
                        .authorFrom(
                                tenant,
                                aModeratorId);
            discussion =
                    forum.startDiscussion(
                            forumNavigationService,
                            author,
                            aDiscussionSubject);
            discussionRepository.add(discussion);
        }
        return discussion;
    }
    ...
}
```

By trying to find the Forum and Discussion from their unique exclusive owner attribute, we prevent attempting to create two Aggregate instances that may already exist. Wow, just a few lines of code make our Event-Driven processing so much better!

> 在上例中，我们通过 exclusiveForumOfOwner（）和 exclusiveDiscussionOfOwner（）方法分别判断对应的 Forum 和 Discussion 是否已经存在，这样可以避免对既有聚合实例的重复创建。不错吧，几行代码的工夫，我们便在很大程度上改进了该事件驱动处理过程。

### 13.3.5 Designing a More Sophisticated Process 设计一个更复杂的长时处理过程

Still, we may desire to design a more sophisticated process. In cases where multiple completion steps are necessary, it works best to have a more elaborate state machine. To address such needs, here’s the definition of a Process interface:

> 我们可能还希望创建一个更复杂的长时处理过程。在需要多步完成的情况下，我们最好是采用一个状态机。要满足这样的需求，我们可以创建一个 Process。以下是 Process 接口的定义：

```java
package com.saasovation.common.domain.model.process;

import java.util.Date;

public interface Process {
    public enum ProcessCompletionType {
        NotCompleted,
        CompletedNormally,
        TimedOut
    }
    public long allowableDuration();
    public boolean canTimeout();
    public long currentDuration();
    public String description();
    public boolean didProcessingComplete();
    public void informTimeout(Date aTimedOutDate);
    public boolean isCompleted();
    public boolean isTimedOut();
    public boolean notCompleted();
    public ProcessCompletionType processCompletionType();
    public ProcessId processId();
    public Date startTime();
    public TimeConstrainedProcessTracker
               timeConstrainedProcessTracker();
    public Date timedOutDate();
    public long totalAllowableDuration();
    public int totalRetriesPermitted();
}
```

The following are some of the more significant operations available with a Process:

> 以下是 Process 接口提供的主要操作：

- allowableDuration(): If the Process can time-out, answers either the total duration or the duration between retries.
- canTimeout(): If the Process can time-out, this method answers true.
- timeConstrainedProcessTracker(): If the Process can time-out, answers a new unique TimeConstrainedProcessTracker.
- totalAllowableDuration(): Answers the total allowable duration of the Process. If retries are not permitted, the answer is allowable-Duration(). If retries are permitted, the answer is allowableDuration() multiplied by totalRetriesPermitted().
- totalRetriesPermitted(): If the Process permits time-outs and retries, this method answers the total number of retries that may be attempted.

---

> - allowableDuration（）：在 Process 可以超时的情况下，该方法返回总的持续时间或者重试之间的持续时间。
> - canTimeout（）：如果 Process 可以超时，那么该方法将返回 true。
> - timeConstrainedProcessTracker（）：如果 Process 可以超时，该方法将返回一个新建的并且唯一的 TimeConstrainedProcessTracker。
> - totalAllowableDuration（）：返回 Process 所允许的总持续时间。在不允许重试的情况下，该方法的返回结果和 allowableDuration（）方法一样。否则，该方法返回的是 allowableDuration（）与 totalRetriesPermitted（）的乘积。
> - totalRetriesPermitted（）：在 Process 允许超时和重试的情况下，该方法将返回重试的总数目。

Implementers of Process may be observed for time-out and retries under the control of the now familiar TimeConstrainedProcessTracker. Once we create our Process, we can ask it for a unique tracker. This test shows how the two objects work together, which is much the same way that Product worked with its tracker:

> Process 的实现类可以通过 TimeConstrainedProcessTracker 来监控超时或者重试。在我们创建了一个 Process 之后，我们便可以从中获取到一个唯一的跟踪器。在以下测试中，我们展示了这两个类是如何协同工作的，这和 Product 及其跟踪器的工作方式相似：

```java
Process process =
     new TestableTimeConstrainedProcess(
            TENANT_ID,
            ProcessId.newProcessId(),
            "Testable Time Constrained Process",
            5000L);
TimeConstrainedProcessTracker tracker =
    process.timeConstrainedProcessTracker();
process.confirm1();

assertFalse(process.isCompleted());
assertFalse(process.didProcessingComplete());
assertEquals(process.processCompletionType(),
        ProcessCompletionType.NotCompleted);

process.confirm2();

assertTrue(process.isCompleted());
assertTrue(process.didProcessingComplete());
assertEquals(process.processCompletionType(),
        ProcessCompletionType.CompletedNormally);
assertNull(process.timedOutDate());

tracker.informProcessTimedOut();

assertFalse(process.isTimedOut());
```

The Process created by this test must complete (without retries) within five seconds (5000L milliseconds), which it always will do. The Process will be marked as completed, with fully completed processing, only after both confirm1() and confirm2() have been invoked. Internally the Process knows that both states must be confirmed:

> 以上测试中所创建的 Process 必须在 5 秒（5000L 毫秒）中之内完成。只有在 confirm1（）和 confirm2（）方法都被调用之后，该 Process 才能被标记为完成。在 Process 内部，它知道这两个状态都必须得到确认：

```java
public class TestableTimeConstrainedProcess extends AbstractProcess {
    ...
    public void confirm1() {
        this.confirm1 = true;
        this.completeProcess(ProcessCompletionType.CompletedNormally);
    }

    public void confirm2() {
        this.confirm2 = true;
        this.completeProcess(ProcessCompletionType.CompletedNormally);
    }
    ...
    protected boolean completenessVerified() {
        return this.confirm1 && this.confirm2;
    }

    protected void completeProcess(
            ProcessCompletionType aProcessCompletionType) {
        if (!this.isCompleted() && this.completenessVerified()) {
            this.setProcessCompletionType(aProcessCompletionType);
        }
    }
    ...
}
```

Even when this Process self-invokes completeProcess(), the Process cannot be marked as completed until completenessVerified() answers true. That method will answer true only when both confirm1 and confirm2 have been set to true. In other words, both the confirm1() and confirm2() operations must have been executed. Thus, method completenessVerified() allows for multiple processing steps to be confirmed as completed before the entire Process is considered completed, and every specialized kind of Process can have its own definition of completenessVerified().

> 即便该 Process 将自行调用 completeProcess（）方法，只有在 completenessVerified（）方法返回为 true 时，它的状态才能被标记为完成。而对于 completenessVerified（）方法来说，又只有当 confirm1 和 confirm2 都为 true 时，它才会返回 true。换句话说，confirm1（）和 confirm2（）方法都必须得到执行。因此，completenessVerified（）方法允许对多个处理步骤进行确认，只有在这些步骤都完成时，整个 Process 才算完成。每个 Process 的实现类都可以定义自己的 completenessVerified（）方法。

Yet, what will happen when the final step of this test is run?

> 但是，在本测试的最后一步执行之后，会发生什么情况呢？

```java
...
tracker.informProcessTimedOut();
assertFalse(process.isTimedOut());
```

From its internal state the tracker knows that the Process has actually not timed out. Thus, the assertion in the next line of code will always be false. (Of course, it is assumed that the entire test will complete in less than five seconds, and it is strongly believed that it always will under normal test conditions.)

> 跟踪器可以从自身的内部状态中获知该 Process 并未超时。因此，最后一行中断言 isTimeOut（）方法将总是返回 fales（当然，这里我们假设整个测试将在 5 秒钟之内完成，并且总是处于通常的测试环境中）。

An AbstractProcess base class implements Process, serving as an Adapter, and provides a really easy way to develop a more sophisticated Long-Running Process. Since AbstractProcess extends the Entity base class, it’s easy to design an Aggregate as a Process. For example, we could make Product subclass AbstractProcess, although it doesn’t need that level of sophistication. Still, we can imagine leveraging this approach to accommodate a more complex process and require method completenessVerified() to determine whether or not all required steps have completed.

> 在上例中，我们使用了一个抽象基类 AbstractProcess，该基类被作为一个适配器来使用。对于开发更加复杂的长时处理过程来说，这个基类向我们提供了一种非常简单的方式。由于该 AbstractProcess 扩展自 Entity 基类，我们可以很简单地将一个聚合设计成 Process。比如，我们可以使 Product 继承自 AbstractProcess，虽然它并不需要这样的复杂度。同样，我们可以将这种方式用于更加复杂的处理过程，并且使用 completenessVerified（）方法来决定所有的处理步骤是否全部完成。

### 13.3.6 When Messaging or Your System Is Unavailable 当消息机制或你的系统不可用时

No single approach to developing complex software systems is a panacea. There are always issues and drawbacks with any approach, some of which we have already discussed. One problem with a messaging system is that it can become unavailable for a period of time. This may be an infrequent situation, but when it does happen, there are a few things to keep in mind.

> 在开发复杂软件系统时，没有哪种单一的方式可以成为万能良方。每一种方式都有不足之处，其中的一些我们已经讨论过了。对于消息系统来说，其中一个问题是：在一段时间之内，它有可能是不可用的。这可能并不是一种多发的情况，但是如果发生，那么有几点是我们需要注意的。

When a messaging mechanism is offline for some time, notification publishers will be unable to send messages through it. Since this situation may be detected by the publishing client, it would likely work best to back off attempts to send notifications until the messaging system is available once again. This will be evident when any one send succeeds. But until that time, make sure that attempts to send occur less frequently than when everything is working well. It could make sense to back off as much as 30 seconds or a minute between retries. Remember, if your system has an Event Store, your Events will continue to be queued in your live system and can be sent as soon as messaging is available again.

> 在消息机制不可用时，通知的发布方将不能通过该消息机制发布事件。这种情况将被发布客户端所检测到，此时的客户端可以退一步，减少消息的发送量，等到消息系统可用时再进行正常发送。在这个过程中，如果其中一次发送成功，那么我们便可以认为消息系统已经再次可用了。但是直到那个时候，请确保消息的发送频率小于正常情况。我们可以每隔 30 秒或者 1 分钟重试一次。请注意，如果你的系统使用了事件存储，那么你的事件在成功发送之前都将一直位于消息队列中，当消息系统重新可用时，我们可以立即对这些消息进行发送。

Certainly listeners will not receive new Event-carrying notifications if the messaging infrastructure goes away for a period of time. When the messaging mechanism becomes available again, will your client listeners be automatically reactivated, or will it be necessary to subscribe to your consumer-side client mechanism again? If automatic recovery of consumers is not supported, you will need to be certain that your consumers are reregistered. Otherwise, you will eventually make the unwanted discovery that your Bounded Context isn’t receiving the notifications that are necessary to keep it interacting with the Bounded Contexts it depends on. That’s one kind of eventual consistency that you want to avoid.

> 对于消息监听器来说，在消息机制不可用时，它将接收不到新的事件通知。当消息系统重新可用时，你的监听器会被自动地重新激活吗，也或许你需要重新进行订阅？如果此时的消息消费方不能自动恢复，那么你需要确保重新注册该消费方。否则，你将发现你的限界上下文不再接收所依赖限界上下文发出的通知，这是你需要避免的。

It’s not always the messaging mechanism that is the source of message-based problems. Consider this situation. Your Bounded Context becomes unavailable for some lengthy period of time. When it becomes available again, the durable message exchanges/queues that it subscribes to have collected a lot of undelivered messages. Once your Bounded Context starts up again and registers its consumers, it could require a considerable amount of time to receive and process all the available notifications. There may not be much that you can do about this situation other than doggedly pursue limited downtime goals, develop a “live” deployment scheme, and design with redundant nodes (a cluster) so that losing one node doesn’t make your system unavailable. Still, there may be times when you can’t avoid some downtime. For example, if changes to your application’s code require changes to the database and you can’t patch in changes without causing problems, you will need some system downtime. In such cases your message consumption processing may simply have to play catch-up. Clearly it’s a situation that we need to be aware of and plan to avoid or deal with if it could be a problem.

> 当然，问题并不总是出自消息机制。考虑以下场景：在一段时间之内，你的限界上下文变得不可用。当它再次可用时，此时的消息系统中已经收集到了大量的未投递的消息。然后，你的限界上下文重新注册消息的消费方，那么要接收并处理完所有未被处理的消息将消耗大量的时间。对于这种情况来说，你将没有什么好做的。当然，你可以增加更多的节点（集群），此时即便其中一个节点不可用，整个系统依然是可用的。此外，有些时候你根本无法避免停机的情况。比如，当你对系统代码的修改需要更新数据库，而你并不能直接向数据库中打补丁时，你便需要一些系统停机时间了。在这种情况下，你的消息处理机制便只能使劲追赶了。

Image

## 13.4 WRAP-UP 本章小结

In this chapter we’ve examined various ways to successfully integrate multiple Bounded Contexts.

> 在本章中，我们学习了集成限界上下文的多种方式。

- We reviewed the basic mindset necessary to succeed with integration in a distributed computing environment.
- We considered how we can integrate multiple Contexts by means of RESTful resources.
- You got to see several examples of integration with messaging, including how to develop and manage Long-Running Processes, from simple to complex.
- You learned the challenges faced when you decide to duplicate information across Bounded Contexts, and how to manage it and also how to avoid it.
- You benefited from considering simple examples, and then progressed to the more complex ones that employed increasing design maturity.

---

> - 你学到了在分布式计算环境中完成系统集成所需要考虑的基本问题。
> - 你学习了如何通过 REST 资源的方式来集成限界上下文。
> - 你学到了通过消息集成限界上下文的多个例子，其中包括开发和管理长时处理过程。
> - 你学到了在不同限界上下文之间复制信息所面临的挑战，以及如何管理并且避免这些信息。
> - 你从简单的例子中学到了很多，然后学习了一些更加复杂的例子，这些例子体现了更高的设计成熟度。

Now that we’ve seen how to integrate multiple Bounded Contexts, let’s focus back on the single Bounded Context and how to design the parts of the application that surround the domain model.

> 接下来，让我们将目光转向单个限界上下文，看看如何设计环绕着领域模型的应用程序。
