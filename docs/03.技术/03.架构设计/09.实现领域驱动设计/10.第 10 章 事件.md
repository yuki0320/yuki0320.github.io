---
title: 第 10 章 事件
date: 2021-01-07 16:25:13
permalink: /pages/3206de/
categories:
  - 技术
  - 技术文档
  - 实现领域驱动设计
tags:
  - 
---
# 第 10 章 事件

The universe is built up into an aggregate of permanent objects connected by causal relations that are independent of the subject and are placed in objective space and time.

> 宇宙由一些永恒的物体聚合而成，这些物体通过某种因果关系联系在一起，这种关系独立于物体本身，并且存在于客观的空间和时间中。

——Jean Piaget

Clustering Entities (5) and Value Objects (6) into an Aggregate with a carefully crafted consistency boundary may at first seem like quick work, but among all DDD tactical guidance, this pattern is one of the least well understood.

> 将实体（5）和值对象（6）在一致性边界之内组成聚合（Aggregate）乍看起来是一件轻松的任务，但在 DDD 众多的战术性指导中，该模式却是最不容易理解的。

Road Map to This Chapter 本章学习路线图

- Along with SaaSOvation, experience the negative consequences of improperly modeling Aggregates.
- Learn to design by the Aggregate Rules of Thumb as a set of best-practice guidelines.
- Grasp how to model true invariants in consistency boundaries according to real business rules.
- Consider the advantages of designing small Aggregates.
- See why you should design Aggregates to reference other Aggregates by identity.
- Discover the importance of using eventual consistency outside the Aggregate boundary.
- Learn Aggregate implementation techniques, including Tell, Don’t Ask and Law of Demeter.

---

> - 以 SaaSOvation 为例，学习对聚合的不当建模所带来的负面影响。
> - 学习设计聚合的经验原则，并形成一套最佳实践。
> - 根据真实的业务规则，掌握如何在一致性边界中对真正的不变条件进行建模。
> - 学习一个聚合为什么应该通过标识（identity）去引用另一个聚合。
> - 了解在聚合边界之外使用最终一致性的重要性。
> - 学习聚合的实现技术，包括“告诉而非询问”（Tell Don't ask）原则和迪米特法则（Law of Demeter）。

To start off, it might help to consider some common questions. Is an Aggregate just a way to cluster a graph of closely related objects under a common parent? If so, is there some practical limit to the number of objects that should be allowed to reside in the graph? Since one Aggregate instance can reference other Aggregate instances, can the associations be navigated deeply, modifying various objects along the way? And what is this concept of invariants and a consistency boundary all about? It is the answer to this last question that greatly influences the answers to the others.

> 让我们首先来看看一些常见的问题。聚合只是将一些共享父类、密切关联的对象聚集成一个对象树吗？如果是这样，对于存在于这个树中的对象有没有一个实用的数目限制？既然一个聚合可以引用另一个聚合，我们是否可以深度地递归遍历下去，并且在此过程中修改对象呢？聚合的不变条件和一致性边界究竟是什么意思？最后一个问题的答案将在很大程度上影响我们对前面所有问题的解答。

There are various ways to model Aggregates incorrectly. We could fall into the trap of designing for compositional convenience and make them too large. At the other end of the spectrum we could strip all Aggregates bare and as a result fail to protect true invariants. As we’ll see, it’s imperative that we avoid both extremes and instead pay attention to the business rules.

> 有很多途径都将导致我们建立不正确的聚合模型。一方面，我们可能为了对象组合上的方便而将聚合设计得很大。另一方面，我们设计的聚合又可能因为过于贫瘠而丧失了保护真正不变条件的目的。我们应该同时避免这两个极端，转而将注意力集中在业务规则上。

## 10.1 USING AGGREGATES IN THE SCRUM CORE DOMAIN 在 Scrum 核心领域中使用聚合

We’ll take a close look at how Aggregates are used by SaaSOvation, and specifically within the Agile Project Management Context the application named ProjectOvation. It follows the traditional Scrum project management model, complete with product, product owner, team, backlog items, planned releases, and sprints. If you think of Scrum at its richest, that’s where ProjectOvation is headed; this is a familiar domain to most of us. The Scrum terminology forms the starting point of the Ubiquitous Language (1). Since it is a subscription-based application hosted using the software as a service (SaaS) model, each subscribing organization is registered as a tenant, another term of our Ubiquitous Language.

> 在本章中，你将看到 SaaSOvation 团队是如何使用聚合的，特别是在 ProjectOvation 项目的敏捷项目管理上下文中。ProjectOvation 遵从传统的 Scrum 项目管理模型，其中包括产品、产品负责人、团队、待定项、计划发布和冲刺等，这些术语组成了最初的通用语言（1）。这是一个部署在 SaaS 平台上的基于订阅的应用程序，每一个订阅方都是一个租户。租户是通用语言中的另一个术语。

Image

The company has assembled a group of talented Scrum experts and developers. However, since their experience with DDD is somewhat limited, the team will make some mistakes with DDD as they climb a difficult learning curve. They will grow by learning from their experiences with Aggregates, and so can we. Their struggles may help us recognize and change similar unfavorable situations we’ve created in our own software.

> 该公司召集了一群 Scrum 专家和开发者。然而，由于他们缺乏 DDD 经验，难免会犯一些错误。通过艰难的学习，他们学会了如何设计聚合。他们的经验也是值得我们学习的。

The concepts of this domain, along with its performance and scalability requirements, are more complex than any that the team has previously faced in the initial Core Domain (2), the Collaboration Context. To address these issues, one of the DDD tactical tools that they will employ is Aggregates.

> 该领域中的概念要比先前协作上下文的核心域（2）中的概念复杂得多；同时，对性能和可伸缩性的要求也更高。为了解决这样的问题，聚合便是一种很好的 DDD 战术工具。

How should the team choose the best object clusters? The Aggregate pattern discusses composition and alludes to information hiding, which they understand how to achieve. It also discusses consistency boundaries and transactions, but they haven’t been overly concerned with that. Their chosen persistence mechanism will help manage atomic commits of their data. However, that was a crucial misunderstanding of the pattern’s guidance that caused them to regress. Here’s what happened. The team considered the following statements in the Ubiquitous Language:

> 他们应该如何选择最佳的对象树呢？聚合模式讨论的是对象组合和信息隐藏，这是团队成员们已经知道的。此外，聚合模式还包含了一致性边界和事务，这是团队成员们所忽略了的地方。虽然他们采用的持久化机制可以帮助他们完成对数据的原子提交，但这却将是一个使他们打退堂鼓的致命错误。事情是这样发生的，他们根据通用语言达成了以下一致：

- Products have backlog items, releases, and sprints.
- New product backlog items are planned.
- New product releases are scheduled.
- New product sprints are scheduled.
- A planned backlog item may be scheduled for release.
- A scheduled backlog item may be committed to a sprint.

---

> - 产品拥有待定项，发布和冲刺。
> - 为新的待定项制定计划。
> - 为产品发布制定进度表。
> - 为产品冲刺制定进度表。
> - 一个计划好的待定项可以被安排在发布中。
> - 位于发布中的待定项可以提交到冲刺中。

From these they envisioned a model and made their first attempt at a design. Let’s see how it went.

> 基于以上条款，团队成员们建立起了一个模型，并开始了他们的第一次设计尝试。

### 10.1.1 First Attempt: Large-Cluster Aggregate 第一次尝试：臃肿的聚合

The team put a lot of weight on the words Products have in the first statement, which influenced their initial attempt to design Aggregates for this domain.

> 团队特别强调“一个产品拥有什么”，这在很大程度上影响了他们对聚合的设计。

It sounded to some like composition, that objects needed to be interconnected like an object graph. Maintaining these object life cycles together was considered very important. As a result the developers added the following consistency rules to the specification:

> 对于那些喜欢对象组合的团队成员来说，他们强调应该将相关联的对象组成对象树，并且将这些对象的生命周期放在一起来维护。因此，他们设计出了以下一致性原则：

- If a backlog item is committed to a sprint, we must not allow it to be removed from the system.
- If a sprint has committed backlog items, we must not allow it to be removed from the system.
- If a release has scheduled backlog items, we must not allow it to be removed from the system.
- If a backlog item is scheduled for release, we must not allow it to be removed from the system.

---

> - 如果一个待定项提交到了冲刺中，那么我们不能将该待定项其从系统中移除。
> - 如果一个冲刺中含有待定项，那么我们不能将该冲刺从系统中移除。
> - 如果一个发布中含有待定项，那么我们不能将该发布从系统中移除。
> - 如果一个待定项位于发布中，那么我们不能将该待定项从系统中移除。

As a result, Product was first modeled as a very large Aggregate. The Root object, Product, held all BacklogItem, all Release, and all Sprint instances associated with it. The interface design protected all parts from inadvertent client removal.

> 如此，Product 首先被建模成了一个非常大的聚合。此时的 Product 作为一个根（root）对象而存在，它包含了所有的 BacklogItem、Release 和 Sprint，而 Product 的接口设计避免了客户端对其所包含数据的意外删除。

This design is shown in the following code, and as a UML diagram in Figure 10.1:

> 此时 Product 的实现代码如下，对应的 UML 图请参考图 10.1：

```java
public class Product extends ConcurrencySafeEntity  {
    private Set<BacklogItem> backlogItems;
    private String description;
    private String name;
    private ProductId productId;
    private Set<Release> releases;
    private Set<Sprint> sprints;
    private TenantId tenantId;
    ...
}
```

Image

Figure 10.1. Product modeled as a very large Aggregate

The big Aggregate looked attractive, but it wasn’t truly practical. Once the application was running in its intended multi-user environment, it began to regularly experience transactional failures. Let’s look more closely at a few client usage patterns and how they interact with our technical solution model. Our Aggregate instances employ optimistic concurrency to protect persistent objects from simultaneous overlapping modifications by different clients, thus avoiding the use of database locks. As discussed in Entities (5), objects carry a version number that is incremented when changes are made and checked before they are saved to the database. If the version on the persisted object is greater than the version on the client’s copy, the client’s is considered stale and updates are rejected.

> 这个巨大的聚合看似诱人，但是却不实用。当系统运行于多租户环境中时，时常会出现事务失败的情况。让我们再进一步看看客户端是如何与这个技术性模型交互的。在持久化时，我们使用了乐观并发（optimistic concurrency）的方式以避免多个客户端同时修改一个 Product 实例。在实体（5）中我们讲到，持久化对象携带有一个递增的版本号，该版本号随着每次对该对象的修改而增加。如果对象在数据库中的版本号大于在客户端中的版本号，服务器将拒绝客户端的请求。

Consider a common simultaneous, multiclient usage scenario:

> 考虑以下一种常见的同时操作对象的情形：

- Two users, Bill and Joe, view the same Product marked as version 1 and begin to work on it.
- Bill plans a new BacklogItem and commits. The Product version is incremented to 2.
- Joe schedules a new Release and tries to save, but his commit fails because it was based on Product version 1.

---

> - 两个用户，Bill 和 Joe，都获取到了版本号为 1 的同一个 Product，然后各自开始工作。
> - Bill 创建并提交了一个新的 BacklogItem，此时 Product 的版本号更新为 2。
> - Joe 创建了一个新的 Release，当他试图保存 Product 时，提交失败，因为此时 Joe 手中 Product 的版本号依然是 1。

Persistence mechanisms are used in this general way to deal with concurrency.1 If you argue that the default concurrency configurations can be changed, reserve your verdict for a while longer. This approach is actually important to protecting Aggregate invariants from concurrent changes.

> 通常来说，持久化机制都是通过这种方式来处理并发的[1]。你可能会说，可以通过修改默认并发配置的方式来解决这个问题，此时，你得重新思考了。事实上，当我们并发地修改一个聚合时，这种方式对于保护聚合不变条件来说是非常重要的。

1. For example, Hibernate provides optimistic concurrency in this way. The same could be true of a key-value store because the entire Aggregate is often serialized as one value, unless designed to save composed parts separately.

These consistency problems came up with just two users. Add more users, and you have a really big problem. With Scrum, multiple users often make these kinds of overlapping modifications during the sprint planning meeting and in sprint execution. Failing all but one of their requests on an ongoing basis is completely unacceptable.

> 从以上的例子可以看出，即便在只有两个用户的情况下，系统都是有可能出现一致性问题的。随着用户的增多，这个问题也将越来越明显。在 Scrum 中，多个用户同时修改一个聚合的情况是很常见的，比如在召开冲刺计划会议的时候，或者在一个冲刺执行的过程中。这种在一个时刻只能成功处理一个用户请求的情况是完全不能接受的。

Nothing about planning a new backlog item should logically interfere with scheduling a new release! Why did Joe’s commit fail? At the heart of the issue, the large-cluster Aggregate was designed with false invariants in mind, not real business rules. These false invariants are artificial constraints imposed by developers. There are other ways for the team to prevent inappropriate removal without being arbitrarily restrictive. Besides causing transactional issues, the design also has performance and scalability drawbacks.

> 对新 BacklogItem 的创建绝不能影响对新 Release 的创建。Joe 的提交为什么会失败？究其根源，是因为在设计这个庞大的 Product 聚合时，我们的思维被一些错误的不变条件所占据，而不是真正的业务规则。这些错误的不变条件只是开发者人工引入的约束而已。此外，除了事务问题，这种设计还会影响到系统的性能和可伸缩性。

### 10.1.2 Second Attempt: Multiple Aggregates 第二次尝试：多个聚合

Now consider an alternative model as shown in Figure 10.2, in which there are four distinct Aggregates. Each of the dependencies is associated by inference using a common ProductId, which is the identity of Product considered the parent of the other three.

> 现在，让我们来看看另一种方法，如图 10.2 所示，该方法使用了 4 个分离的聚合类。它们之间通过 ProductId 关联起来，ProductId 是 Product 的唯一标识。此时，Product 作为其他 3 个聚合类的父聚合而存在。

Image

Figure 10.2. Product and related concepts are modeled as separate Aggregate types.

Breaking the single large Aggregate into four will change some method contracts on Product. With the large-cluster Aggregate design the method signatures looked like this:

> 在将一个大的 Product 聚合拆分成 4 个相对较小的聚合时，Product 类的方法签名也将发生改变。对于先前那个庞大的 Product，它的方法签名如下：

```java
public class Product ... {
    ...
    public void planBacklogItem(
        String aSummary, String aCategory,
        BacklogItemType aType, StoryPoints aStoryPoints) {
            ...
    }
    ...
    public void scheduleRelease(
        String aName, String aDescription,
        Date aBegins, Date anEnds) {
        ...
    }

    public void scheduleSprint(
        String aName, String aGoals,
        Date aBegins, Date anEnds) {
        ...
    }
    ...
}
```

All of these methods are CQS commands [Fowler, CQS]; that is, they modify the state of the Product by adding the new element to a collection, so they have a void return type. But with the multiple-Aggregate design, we have

> 以上所有的方法都是 CQS 命令方法[Fowler，CQS]；即它们将修改 Product 的状态，比如向集合中添加新元素，因此这些方法的返回类型为 void 类型。在采用多个聚合时，Product 的实现如下：

```java
public class Product ... {
    ...
    public BacklogItem planBacklogItem(
        String aSummary, String aCategory,
        BacklogItemType aType, StoryPoints aStoryPoints) {
        ...
    }

    public Release scheduleRelease(
        String aName, String aDescription,
        Date aBegins, Date anEnds) {
        ...
    }

    public Sprint scheduleSprint(
        String aName, String aGoals,
        Date aBegins, Date anEnds) {
        ...
    }
    ...
}
```

These redesigned methods have a CQS query contract and act as Factories (11); that is, each creates a new Aggregate instance and returns a reference to it. Now when a client wants to plan a backlog item, the transactional Application Service (14) must do the following:

> 此时，这些方法变成了 CQS 查询方法；并且扮演了工厂（11）的角色，即每个方法都创建一个新的聚合实例然后予以返回。现在，当客户端计划一个待定项时，应用层（14）将变成：

```java
public class ProductBacklogItemService ... {
    ...
    @Transactional
    public void planProductBacklogItem(
        String aTenantId, String aProductId,
        String aSummary, String aCategory,
        String aBacklogItemType, String aStoryPoints) {
        Product product =
            productRepository.productOfId(
                    new TenantId(aTenantId),
                    new ProductId(aProductId));
        BacklogItem plannedBacklogItem =
            product.planBacklogItem(
                    aSummary,
                    aCategory,
                    BacklogItemType.valueOf(aBacklogItemType),
                    StoryPoints.valueOf(aStoryPoints));
        backlogItemRepository.add(plannedBacklogItem);
    }
    ...
}
```

So we’ve solved the transaction failure issue by modeling it away. Any number of BacklogItem, Release, and Sprint instances can now be safely created by simultaneous user requests. That’s pretty simple.

> 这样，通过将 BacklogItem 分开处理，我们解决了先前的事务问题。多个用户请求可以同时创建任何数量的 BacklogItem、Release 和 Sprint 实例。这是非常简单的。

However, even with clear transactional advantages, the four smaller Aggregates are less convenient from the perspective of client consumption. Perhaps instead we could tune the large Aggregate to eliminate the concurrency issues. By setting our Hibernate mapping optimistic-lock option to false, we make the transaction failure domino effect go away. There is no invariant on the total number of created BacklogItem, Release, or Sprint instances, so why not just allow the collections to grow unbounded and ignore these specific modifications on Product? What additional cost would there be for keeping the large-cluster Aggregate? The problem is that it could actually grow out of control. Before thoroughly examining why, let’s consider the most important modeling tip the SaaSOvation team needed.

> 然而，对客户端来说，这 4 个较小的聚合却多少会带来一些不便。或许，我们可以对先前的大聚合进行优化，以消除由并发带来的问题。在 Hibernate 中，我们可以将 optimistic-lock 设置成 false，这样便可以消除先前多米诺式的事务问题。既然对 BacklogItem、Release 和 Sprint 的实例数目没有限制，那么我们为什么不允许客户端顺其自然地向 Product 中添加这些实例呢？要维护一个庞大的聚合还存在哪些额外的成本？问题在于，随着时间的增长，这样的聚合将变得难以控制。在深入讨论之前，让我们先来看看 SaaSOvation 团队所需的最重要的建模原则。

## 10.2 RULE: MODEL TRUE INVARIANTS IN CONSISTENCY BOUNDARIES 原则：在一致性边界之内建模真正的不变条件

When trying to discover the Aggregates in a Bounded Context (2), we must understand the model’s true invariants. Only with that knowledge can we determine which objects should be clustered into a given Aggregate.

> 要从限界上下文（2）中发现聚合，我们需要了解模型中真正的不变条件。只有这样，我们才能决定什么样的对象可以放在一个聚合中。

An invariant is a business rule that must always be consistent. There are different kinds of consistency. One is transactional consistency, which is considered immediate and atomic. There is also eventual consistency. When discussing invariants, we are referring to transactional consistency. We might have the invariant

> 这里的不变条件表示一个业务规则，该规则应该总是保持一致的。存在多种类型的一致性，其中之一便是事务一致性，事务一致性要求立即性和原子性。同时，还存在最终一致性。在讨论不变条件时，我们讨论的是事务一致性。我们可能有以下不变条件：

c = a + b

Therefore, when a is 2 and b is 3, c must be 5. According to that rule and conditions, if c is anything but 5, a system invariant is violated. To ensure that c is consistent, we design a boundary around these specific attributes of the model:

> 当 a 等于 2，b 等于 3 时，c 必定等于 5。根据这条规则，如果 c 不为 5，那么我们便违背了系统的不变条件。为了保持 c 的一致性，我们应该在模型中为这些属性设计了一个边界：

```java
AggregateType1 {
    int a;
    int b;
    int c;
    operations ...
}
```

The consistency boundary logically asserts that everything inside adheres to a specific set of business invariant rules no matter what operations are performed. The consistency of everything outside this boundary is irrelevant to the Aggregate. Thus, Aggregate is synonymous with transactional consistency boundary. (In this limited example, AggregateType1 has three attributes of type int, but any given Aggregate could hold attributes of various types.)

> 在上例中，聚合边界之内的所有内容组成了一套不变的业务规则，任何操作都不能违背这些规则。边界之外的任何东西与该聚合都是不相关的。因此，聚合表达了与事务一致性边界相同的意思（在该例中，AggregateType1 拥有 3 个 int 类型的属性，当然，任何聚合都可以拥有不同类型的属性）。

When employing a typical persistence mechanism, we use a single transaction2 to manage consistency. When the transaction commits, everything inside one boundary must be consistent. A properly designed Aggregate is one that can be modified in any way required by the business with its invariants completely consistent within a single transaction. And a properly designed Bounded Context modifies only one Aggregate instance per transaction in all cases. What is more, we cannot correctly reason on Aggregate design without applying transactional analysis.

> 对于一个典型的持久化机制来说，我们通常使用单事务[2]来管理一致性。在提交事务时，边界之内的所有内容都必须保持一致。对于一个设计良好的聚合来说，无论由于何种业务需求而发生改变，在单个事务中，聚合中的所有不变条件都是一致的。而对于一个设计良好的限界上下文来说，无论在哪种情况下，它都能保证在一个事务中只修改一个聚合实例。此外，在设计聚合时，我们必须将事务分析也考虑在内。

2. The transaction may be handled by a Unit of Work [Fowler, P of EAA].

Limiting modification to one Aggregate instance per transaction may sound overly strict. However, it is a rule of thumb and should be the goal in most cases. It addresses the very reason to use Aggregates.

> 在一个事务中只修改一个聚合实例，这听起来可能过于严格。但是，这却是设计聚合的重要经验原则，也是我们为什么要使用聚合的原因。

Whiteboard Time 白板时间

- List on your whiteboard all large-cluster Aggregates in your system.
- Make a note next to each of those Aggregates why it is a large cluster and any potential problems caused by its size.
- Next to that list, name any Aggregates that are modified in the same transaction with others.
- Make a note next to each of those Aggregates whether true or false invariants caused the formation of poorly designed Aggregate boundaries.

---

> - 在白板上列出你系统中所有的大聚合。
> - 在每个聚合名旁边记下笔记，包括该聚合之所以成为大聚合的原因、这将导致什么样的问题。
> - 另起一栏，列出那些在同一个事务中进行修改的聚合。
> - 在每个聚合名旁边记下笔记，看看不变条件是否影响了对聚合边界的设计。

The fact that Aggregates must be designed with a consistency focus implies that the user interface should concentrate each request to execute a single command on just one Aggregate instance. If user requests try to accomplish too much, the application will be forced to modify multiple instances at once.

> 前面我们提到，在设计聚合时，我们需要慎重地考虑一致性，这意味着每次客户请求应该只在一个聚合实例上执行一个命令方法。如果客户所请求的业务过多，那么有可能出现一次请求修改多个聚合实例的情况。

Therefore, Aggregates are chiefly about consistency boundaries and not driven by a desire to design object graphs. Some real-world invariants will be more complex than this. Even so, typically invariants will be less demanding on our modeling efforts, making it possible to design small Aggregates.

> 因此，在设计聚合时，我们主要关注的是聚合的一致性边界，而不是创建一个对象树。现实世界中的有些不变条件可能比这更加复杂。但是即便如此，通常情况下的不变条件所需要的建模代价并不大，所以，要设计出小的聚合是可能的。

## 10.3 RULE: DESIGN SMALL AGGREGATES 原则：设计小聚合

We can now thoroughly address this question: What additional cost would there be for keeping the large-cluster Aggregate? Even if we guarantee that every transaction would succeed, a large cluster still limits performance and scalability. As SaaSOvation develops its market, it’s going to bring in lots of tenants. As each tenant makes a deep commitment to ProjectOvation, SaaSOvation will host more and more projects and the management artifacts to go along with them. That will result in vast numbers of products, backlog items, releases, sprints, and others. Performance and scalability are nonfunctional requirements that cannot be ignored.

> 现在，我们可以全面地回答前面的问题了：要维护一个庞大的聚合还存在哪些额外的成本？对于大聚合，即便我们可以保证事务的成功执行，它依然有可能限制系统的性能和可伸缩性。SaaSOvation 公司的产品在上市之后，必将有大量的租户。随着每个租户对 ProjectOvation 的深入使用，SaaSOvation 公司需要运行更多的敏捷项目，另外还需要管理更多的项目资产。这样导致的结果是，ProjectOvation 系统中将存在大量的产品、待定项、发布和冲刺等。系统性能和可伸缩性虽然是非功能性需求，但是我们绝不应该予以忽视。

Keeping performance and scalability in mind, what happens when one user of one tenant wants to add a single backlog item to a product, one that is years old and already has thousands of backlog items? Assume a persistence mechanism capable of lazy loading (Hibernate). We almost never load all backlog items, releases, and sprints at once. Still, thousands of backlog items would be loaded into memory just to add one new element to the already large collection. It’s worse if a persistence mechanism does not support lazy loading. Even being memory conscious, sometimes we would have to load multiple collections, such as when scheduling a backlog item for release or committing one to a sprint; all backlog items, and either all releases or all sprints, would be loaded.

> 考虑一下系统性能和可伸缩性，假定一个存在了 1 年多的敏捷项目，其中已经包含有数以千计的待定项，如果一个租户的某个用户只是需要将一个待定项添加到产品中，会发生什么情况？假设我们使用了延迟加载的持久化机制（比如 Hibernate），我们几乎不用同时加载待定项、发布和冲刺。但是，为了添加一个待定项，我们依然需要先将所有的待定项集合元素加载到内存里，而这个数目是巨大的。对于那些不支持延迟加载的持久化机制来说，问题就更糟了。即便我们将内存使用考虑在内，有时我们仍然需要加载多个集合，比如将某个待定项加入到发布中，或者将某个待定项提交到冲刺中。此时，所有的待定项、发布或冲刺都需要加载进内存。

To see this clearly, look at the diagram in Figure 10.3 containing the zoomed composition. Don’t let the `0..*` fool you; the number of associations will almost never be zero and will keep growing over time. We would likely need to load thousands and thousands of objects into memory all at once, just to carry out what should be a relatively basic operation. That’s just for a single team member of a single tenant on a single product. We have to keep in mind that this could happen all at once with hundreds or thousands of tenants, each with multiple teams and many products. And over time the situation will only become worse.

> 为了清晰起见，请参考图 10.3。请不要被图中的“`0..*`”所欺骗了，对象之间的关联数目几乎不可能为 0，并且还会随着时间不断增加。为了完成一项基本的操作，我们可能需要将成百上千个对象一同加载进内存中，而这只是一个租户中的一个团队成员操作一个产品的情况。ProjectOvation 将拥有成百上千的租户，每个租户都有多个团队和多个产品。随着时间的增加，这种情况将变得更糟。

Image

Figure 10.3. With this Product model, multiple large collections load during many basic operations.

This large-cluster Aggregate will never perform or scale well. It is more likely to become a nightmare leading only to failure. It was deficient from the start because the false invariants and a desire for compositional convenience drove the design, to the detriment of transactional success, performance, and scalability.

If we are going to design small Aggregates, what does “small” mean? The extreme would be an Aggregate with only its globally unique identity and one additional attribute, which is not what’s being recommended (unless that is truly what one specific Aggregate requires). Rather, limit the Aggregate to just the Root Entity and a minimal number of attributes and/or Value-typed properties.3 The correct minimum is however many are necessary, and no more.

> 如果我们要设计小的聚合，那么，这里的“小”是什么意思呢？最极端的情况是，一个聚合只拥有全局标识和单个属性，当然，这并不是我们所推荐的做法（除非这正是需求所在）。好的做法是，使用根实体（Root Entity）来表示聚合，其中只包含最小数量的属性或值类型属性[3]。这里的“最小数量”表示所需的最小属性集合，不多也不少。

3. A Value-typed property is an attribute that holds a reference to a Value Object. I distinguish this from a simple attribute such as a string or numeric type, as does Ward Cunningham when describing Whole Value [Cunningham, Whole Value].

Which ones are necessary? The simple answer is: those that must be consistent with others, even if domain experts don’t specify them as rules. For example, Product has name and description attributes. We can’t imagine name and description being inconsistent, modeled in separate Aggregates. When you change the name, you probably also change the description. If you change one and not the other, it’s probably because you are fixing a spelling error or making the description more fitting to the name. Even though domain experts will probably not think of this as an explicit business rule, it is an implicit one.

> 哪些属性是所需的呢？简单的答案是：那些必须与其他属性保持一致的属性——虽然这不是领域专家所指定的原则。比如，一个 Product 拥有 name 和 description 属性，这里的 name 和 description 是需要保持一致的，将它们放在两个不同的聚合中显然是没有意义的。当我们修改 name 的时候，很有可能也会同时修改 description。如果你只修改了其中之一，你很有可能是在修改语法上的错误，或者使 description 能够更加匹配 name。虽然领域专家并不会将此作为一个显式的业务规则，但是它却是一个隐式的规则。

What if you think you should model a contained part as an Entity? First ask whether that part must itself change over time, or whether it can be completely replaced when change is necessary. Cases where instances can be completely replaced point to the use of a Value Object rather than an Entity. At times Entity parts are necessary. Yet, if we run through this design exercise on a case-by-case basis, many concepts modeled as Entities can be refactored to Value Objects. Favoring Value types as Aggregate parts doesn’t mean the Aggregate is immutable since the Root Entity itself mutates when one of its Value-typed properties is replaced.

> 在聚合中，如果你认为有些被包含的部分应该建模成一个实体，此时你该怎么办呢？首先，思考一下，这个部分是否会随着时间而改变，或者该部分是否能被全部替换。如果可以全部替换，那么请将其建模成值对象，而非实体。有时，建模成实体也是有必要的。但是很多情况下，许多建模成实体的概念都可以重构成值对象。优先选用值对象并不意味着聚合就是不变的，因为当值对象属性被替换成其他值时，根实体也就随之改变了。

There are important advantages to limiting internal parts to Values. Depending on your persistence mechanism, Values can be serialized with the Root Entity, whereas Entities can require separately tracked storage. Overhead is higher with Entity parts, as, for example, when SQL joins are necessary to read them using Hibernate. Reading a single database table row is much faster. Value objects are smaller and safer to use (fewer bugs). Due to immutability it is easier for unit tests to prove their correctness. These advantages are discussed in Value Objects (6).

> 将聚合的内部建模成值对象有很多好处的。根据你所选用的持久化机制，值对象可以随着根实体而序列化，而实体则需要单独的存储区域予以跟踪。此外，实体还会带来某些不必要的操作，比如，在使用 Hibernate 时，我们需要对多张表进行联合查询。对单张表进行读取要快得多，而使用值对象也更加方便与安全。再者，由于值对象是不变的，测试起来也相对简单，对此请参考值对象（6）。

On one project for the financial derivatives sector using Qi4j [Öberg], Niclas Hedhman4 reported that his team was able to design approximately 70 percent of all Aggregates with just a Root Entity containing some Value-typed properties. The remaining 30 percent had just two to three total Entities. This doesn’t indicate that all domain models will have a 70/30 split. It does indicate that a high percentage of Aggregates can be limited to a single Entity, the Root.

> 在一个使用 Qi4j[Öberg]的金融项目中，Niclas Hedhman[4]的团队将系统中 70%的聚合都设计成了包含值类型属性的根实体。其余的 30%也只包含 2 ～ 3 个实体。当然，这并不是说所有的领域模型都存在一个 70/30 的比例，而是说大量的聚合都可以建模成单个实体——根实体。

4. See also www.jroller.com/niclas/

The [Evans] discussion of Aggregates gives an example where having multiple Entities makes sense. A purchase order is assigned a maximum allowable total, and the sum of all line items must not surpass the total. The rule becomes tricky to enforce when multiple users simultaneously add line items. Any one addition is not permitted to exceed the limit, but concurrent additions by multiple users could collectively do so. I won’t repeat the solution here, but I want to emphasize that most of the time the invariants of business models are simpler to manage than that example. Recognizing this helps us to model Aggregates with as few properties as possible.

> 在[Evans]中，Eric Evans 讨论了一个聚合包含多个实体的情况。一个订单限制了其中所包含物品的最大数目。当多个用户同时添加物品时，情况就变得玄乎了。在单次添加物品时，系统不允许超过最大物品数，但是多个用户同时添加时，这些物品合起来却有可能超过最大物品数。这里，我并不会复述原书中的解决方法，而是强调在多数情况下，业务模型的不变条件要比那个例子简单得多。这种认识有助于我们设计小的聚合。

Smaller Aggregates not only perform and scale better, they are also biased toward transactional success, meaning that conflicts preventing a commit are rare. This makes a system more usable. Your domain will not often have true invariant constraints that force you into large-composition design situations. Therefore, it is just plain smart to limit Aggregate size. When you occasionally encounter a true consistency rule, add another few Entities, or possibly a collection, as necessary, but continue to push yourself to keep the overall size as small as possible.

> 小聚合不仅有性能和可伸缩性上的好处，它还有助于事务的成功执行，即它可以减少事务提交冲突。这样一来，系统的可用性也得到了增强。在你的领域中，迫使你设计大聚合的不变条件约束并不多。当你遇到这样的情况时，可以考虑添加实体或者是集合，但无论如何，我们都应该将聚合设计得尽量小。

### 10.3.1 Don’t Trust Every Use Case 不要相信每一个用例

Business analysts play an important role in delivering use case specifications. Much work goes into a large and detailed specification, and it will affect many of our design decisions. Yet, we mustn’t forget that use cases derived in this way don’t carry the perspective of the domain experts and developers of our close-knit modeling team. We still must reconcile each use case with our current model and design, including our decisions about Aggregates. A common issue that arises is a particular use case that calls for the modification of multiple Aggregate instances. In such a case we must determine whether the specified large user goal is spread across multiple persistence transactions, or if it occurs within just one. If it is the latter, it pays to be skeptical. No matter how well it is written, such a use case may not accurately reflect the true Aggregates of our model.

> 在交付用例规范时，业务分析人员扮演着非常重要的角色。他们将大量的精力放在了那些大而细的规范上，而这将在很大程度上影响我们的设计。此时，我们应该知道，以这种方式产生的用例并没有表达出领域专家的意图。对于每一个用例，我们依然需要用当前模型来进行验证，其中便包括聚合。此时容易出现的一个问题是，某个用例需要修改多个聚合实例。在这种情况下，我们需要搞清楚的是，对用户需求的实现是否分散在多个事务中，还是单个事务？如果是后者，那么我需要注意了。无论写得多好，这样的用例都不能准确地反映出模型中真正的聚合。

Assuming your Aggregate boundaries are aligned with real business constraints, it’s going to cause problems if business analysts specify what you see in Figure 10.4. Thinking through the various commit order permutations, you’ll see that there are cases where two of the three requests will fail.5 What does attempting this indicate about your design? The answer to that question may lead to a deeper understanding of the domain. Trying to keep multiple Aggregate instances consistent may be telling you that your team has missed an invariant. You may end up folding the multiple Aggregates into one new concept with a new name in order to address the newly recognized business rule. (And, of course, it might be only parts of the old Aggregates that get rolled into the new one.)

> 假设你的聚合边界与真实的业务约束是一致的，如果业务分析人员给了你如图 10.4 中的用例需求，问题也将随之而来。考虑不同的提交顺序，你会发现在有些情况下，3 次请求中的 2 次都会失败[5]。对于你的设计来说，这能说明什么呢？这个问题的答案将引导你更深层次地去理解自己的领域。试图保持多个聚合实例间的一致性通常意味着我们缺少了某些聚合不变条件。为了满足新的业务规则，你可能会将多个聚合组合在一起而创建一个新的概念（当然，有可能只是将原有聚合中的某些部分提取出来，然后创建一个新的聚合）。

5. This doesn’t address the fact that some use cases describe modifications to multiple Aggregates that span transactions, which would be fine. A user goal should not be viewed as synonymous with a transaction. We are concerned only with use cases that actually indicate the modification of multiple Aggregate instances in one transaction.

Image

Figure 10.4. Concurrency contention exists among three users who are all trying to access the same two Aggregate instances, leading to a high number of transactional failures.

So a new use case may lead to insights that push us to remodel the Aggregate, but be skeptical here, too. Forming one Aggregate from multiple ones may drive out a completely new concept with a new name, yet if modeling this new concept leads you toward designing a large-cluster Aggregate, that can end up with all the problems common to that approach. What different approach may help?

> 因此，新的用例可能引导我们重新对聚合进行建模，但是此时你依然需要谨慎行事。从多个聚合中创建一个新的聚合可能会引出一个全新的概念，该概念拥有全新的名字。但是，如果对这个新概念的建模导致了一个大的聚合，这样显然是不好的。那么，此时我们还可以采用什么方法呢？

Just because you are given a use case that calls for maintaining consistency in a single transaction doesn’t mean you should do that. Often, in such cases, the business goal can be achieved with eventual consistency between Aggregates. The team should critically examine the use cases and challenge their assumptions, especially when following them as written would lead to unwieldy designs. The team may have to rewrite the use case (or at least re-imagine it if they face an uncooperative business analyst). The new use case would specify eventual consistency and the acceptable update delay. This is one of the issues taken up later in this chapter.

> 一个用例可能要求在单个事务中维持聚合的一致性，但是，这并不意味着我们就必须这么做。通常来说，在这种情况下，业务目标都是可以通过聚合间的最终一致性来实现的。因此，我们需要带着批判性的态度来审查用例，并在必要的时候敢于挑战自己的假设。你的团队可能需要重新编写用例。新的用例需要包含最终一致性，并且应该包含可接受的更新延迟时间。对此，我们将在本章后面进行讨论。

## 10.4 RULE: REFERENCE OTHER AGGREGATES BY IDENTITY 原则：通过唯一标识引用其他聚合

When designing Aggregates, we may desire a compositional structure that allows for traversal through deep object graphs, but that is not the motivation of the pattern. [Evans] states that one Aggregate may hold references to the Root of other Aggregates. However, we must keep in mind that this does not place the referenced Aggregate inside the consistency boundary of the one referencing it. The reference does not cause the formation of just one whole Aggregate. There are still two (or more), as shown in Figure 10.5.

> 在设计聚合时，我们可能希望使用对象组合，因为这样我们可以对聚合中的对象树进行深度遍历。但是，这并不是使用聚合模式的动机。[Evans]写道，一个聚合可以引用另一个聚合的根聚合。然而，我们需要注意的是，此时被引用的聚合不应该放在引用聚合的一致性边界之内。同时，这种引用方式也并非创建了一个整体性的聚合。让我们看看图 10.5 中的例子。

Image

Figure 10.5. There are two Aggregates, not one.

In Java the association would be modeled like this:

> 在 Java 中，对象之间的关联可以通过以下方式实现：

```java
public class BacklogItem extends ConcurrencySafeEntity  {
    ...
    private Product product;
    ...
}
```

That is, the BacklogItem holds a direct object association to Product.

> 在上例中，一个 BacklogItem 直接关联了一个 Product。

In combination with what’s already been discussed and what’s next, this has a few implications:

> 结合前文已经讨论的和接下来即将讨论的，以上实现方式隐含着以下几点：

1. Both the referencing Aggregate (BacklogItem) and the referenced Aggregate (Product) must not be modified in the same transaction. Only one or the other may be modified in a single transaction.
2. If you are modifying multiple instances in a single transaction, it may be a strong indication that your consistency boundaries are wrong. If so, it is possibly a missed modeling opportunity; a concept of your Ubiquitous Language has not yet been discovered although it is waving its hands and shouting at you (see earlier in this chapter).
3. If you are attempting to apply point 2, and doing so influences a large-cluster Aggregate with all the previously stated caveats, it may be an indication that you need to use eventual consistency (see later in this chapter) instead of atomic consistency.

---

> 1. 引用聚合（BacklogItem）和被引用聚合（Product）不可以在同一个事务中进行修改。
> 2. 如果你试图在单个事务中修改多个聚合，这往往意味着此时的一致性边界是错误的。发生这样的情况通常是因为我们遗漏了某些建模点，或者尚未发现通用语言中的某个概念。
> 3. 如果你试图采用第 2 点，但却遇到了先前所讲的有关大聚合的种种麻烦，那么此时你可能需要使用最终一致性（请参考本章后续章节），而不是原子一致性。

If you don’t hold any reference, you can’t modify another Aggregate. So the temptation to modify multiple Aggregates in the same transaction could be squelched by avoiding the situation in the first place. But that is overly limiting since domain models always require some associative connections. What might we do to facilitate necessary associations, protect from transaction misuse or inordinate failure, and allow the model to perform and scale?

> 在不持有对象引用的情况下，我们是不能修改其他聚合的，因此我们可以避免在同一个事务中修改多个聚合。但是，这种方式的缺点在于限制性太强，因为在领域模型中我们总需要对象之间的关联关系来完成一些任务。那么，此时我们应该怎么办呢？

### 10.4.1 Making Aggregates Work Together through Identity References 通过标识引用使多个聚合协同工作

Prefer references to external Aggregates only by their globally unique identity, not by holding a direct object reference (or “pointer”). This is exemplified in Figure 10.6.

> 我们应该优先考虑通过全局唯一标识来引用外部聚合，而不是通过直接的对象引用，如图 10.6 所示。

Image

Figure 10.6. The BacklogItem Aggregate, inferring associations outside its boundary with identities

We would refactor the source to

> 因此，我们可以对 BacklogItem 做个重构：

```java
public class BacklogItem extends ConcurrencySafeEntity  {
    ...
    private ProductId productId;
    ...
}
```

Aggregates with inferred object references are thus automatically smaller because references are never eagerly loaded. The model can perform better because instances require less time to load and take less memory. Using less memory has positive implications for both memory allocation overhead and garbage collection.

> 自然地，通过这种方式创建的聚合也会变得更小，因为此时所关联的聚合是不会即时加载的。模型的性能也将随之变好，因为它需要更少的加载时间和更小的内存。更小的内存使用量不止在内存分配上有好处，对于垃圾回收也是有好处的。

### 10.4.2 Model Navigation 建模对象导航性

Reference by identity doesn’t completely prevent navigation through the model. Some will use a Repository (12) from inside an Aggregate for lookup. This technique is called Disconnected Domain Model, and it’s actually a form of lazy loading. There’s a different recommended approach, however: Use a Repository or Domain Service (7) to look up dependent objects ahead of invoking the Aggregate behavior. A client Application Service may control this, then dispatch to the Aggregate:

> 通过标识引用并不意外着我们完全丧失了对象导航性。有些人习惯在聚合中使用资源库（12）来定位其他聚合。这种技术称为失联领域模型（DisconnectedDomain Model），而事实上这只是延迟加载的一种形式。此外，我们还推荐另一种方法：在调用聚合行为方法之前，使用资源库或领域服务（7）来获取所需要的对象。在客户端中，应用服务可以对此做出控制，然后分发给聚合：

```java
public class ProductBacklogItemService ... {
    ...
    @Transactional
    public void assignTeamMemberToTask(
        String aTenantId,
        String aBacklogItemId,
        String aTaskId,
        String aTeamMemberId) {
        BacklogItem backlogItem =
            backlogItemRepository.backlogItemOfId(
                new TenantId(aTenantId),
                new BacklogItemId(aBacklogItemId));
        Team ofTeam =
            teamRepository.teamOfId(
                backlogItem.tenantId(),
                backlogItem.teamId());
        backlogItem.assignTeamMemberToTask(
                new TeamMemberId(aTeamMemberId),
                ofTeam,
                new TaskId(aTaskId));
    }
    ...
}
```

Having an Application Service resolve dependencies frees the Aggregate from relying on either a Repository or a Domain Service. However, for very complex and domain-specific dependency resolutions, passing a Domain Service into an Aggregate command method can be the best way to go. The Aggregate can then double-dispatch to the Domain Service to resolve references. Again, in whatever way one Aggregate gains access to others, referencing multiple Aggregates in one request does not give license to cause modification on two or more of them.

> 通过应用服务来处理依赖关系可以避免在聚合中使用资源库或领域服务。然而，如果要处理特定于领域的复杂依赖关系，在聚合的命令方法中使用领域服务却是最好的方法。这里再次重申一遍，不管使用哪种方式在一个聚合中引用另外的聚合，我们都不能在同一个事务中修改多个聚合实例。

Cowboy Logic 牛仔的逻辑

LB: “I’ve got two points of reference when I’m navigating at night. If it smells like beef on the hoof, I’m heading to the herd. If it smells like beef on the grill, I’m heading home.”

> LB：“当我在夜里行路时，我有两个参考点。当我闻到鲜牛肉的味道时，我知道我正朝着屠宰场走去；当我闻到烤牛肉的味道时，我便知道我回家了。”

Image

Limiting a model to using only reference by identity could make it more difficult to serve clients that assemble and render User Interface (14) views. You may have to use multiple Repositories in a single use case to populate views. If query overhead causes performance issues, it may be worth considering the use of theta joins or CQRS. Hibernate, for example, supports theta joins as a means to assemble a number of referentially associated Aggregate instances in a single join query, which can provide the necessary viewable parts. If CQRS and theta joins are not an option, you may need to strike a balance between inferred and direct object reference.

> 在模型中只使用唯一标识来引用对象的缺点在于：在客户端的用户界面（14）层，要组装多个聚合并予以显示将变得非常困难，我们不得不使用多个资源库。此时，如果对聚合的查询导致了性能问题，那么我们可以考虑 theta 联合查询或者 CQRS。比如，Hibernate 就支持 theta 联合查询。而如果 CQRS 和 theta 联合查询都不能满足我们的需求，那么就需要在标识引用和直接引用之间折中考虑了。

If all this advice seems to lead to a less convenient model, consider the additional benefits it affords. Making Aggregates smaller leads to better-performing models, plus we can add scalability and distribution.

> 如果以上所有的建议有损模型的使用方便性，那么我们可以转而考虑它们的其他好处——小聚合可以增强模型的性能和可伸缩性，另外它还有助于创建分布式系统。

### 10.4.3 Scalability and Distribution 可伸缩性和分布式

Since Aggregates don’t use direct references to other Aggregates but reference by identity, their persistent state can be moved around to reach large scale. Almost-infinite scalability is achieved by allowing for continuous repartitioning of Aggregate data storage, as explained by Amazon.com’s Pat Helland in his position paper “Life beyond Distributed Transactions: An Apostate’s Opinion” [Helland]. What we call Aggregate, he calls entity. But what he describes is still an Aggregate by any other name: a unit of composition that has transactional consistency. Some NoSQL persistence mechanisms support the Amazon-inspired distributed storage. These provide much of what [Helland] refers to as the lower, scale-aware layer. When employing a distributed store, or even when using a SQL database with similar motivations, reference by identity plays an important role.

> 当在一个聚合中引用其他聚合时，由于我们使用了标识引用而不是直接引用，此时我们便可以大规模地对聚合进行持久化。正如 Amazon 的 Pat Helland 在他的论文“Life beyond Distributed Transactions： An Apostate’s Opinion”[Helland]中所说，通过持续地对聚合数据存储进行再分配，我们几乎可以得到无限的伸缩性。Helland 将我们这里的聚合称为实体，但是它所描述的依然是聚合的概念，只是使用了不同的名字：一个拥有事务一致性的组合单元。有些 NoSQL 的持久化机制本身便支持 Helland 所提出的分布式存储。在使用分布式存储时，甚至在通过相似的方式使用 SQL 数据库时，通过标识来引用聚合扮演着重要的角色。

Distribution extends beyond storage. Since there are always multiple Bounded Contexts at play in a given Core Domain initiative, reference by identity allows distributed domain models to have associations from afar. When an Event-Driven approach is in use, message-based Domain Events (8) containing Aggregate identities are sent around the enterprise. Message subscribers in foreign Bounded Contexts use the identities to carry out operations in their own domain models. Reference by identity forms remote associations or partners. Distributed operations are managed by what [Helland] calls two-party activities, but in Publish-Subscribe [Buschmann et al.] or Observer [Gamma et al.] terms it’s multiparty (two or more). Transactions across distributed systems are not atomic. The various systems bring multiple Aggregates into a consistent state eventually.

> 当然，这里的分布式不只是关于存储的。在一个核心域中，通常存在多个限界上下文，使用标识引用使得我们可以将分布式的领域模型关联起来。在使用事件驱动架构时，基于消息的领域事件（8）包含了聚合标识，这样的领域事件将在整个企业范围之内传播。外部限界上下文中的消息订阅方将使用聚合标识在他们自己的领域模型中展开操作。标识引用形成了一种远程关联或者合作者（partner）关系。分布式操作通过双方活动（two-party activiy）进行管理[Helland]，但是在发布-订阅[Buschmann et al.]或者观察者模式[Gamma et al.]中，却是多方（multi-party）的。分布式系统中的事务并不是原子性的，各个系统中的聚合通过事件达到一致性。

## 10.5 RULE: USE EVENTUAL CONSISTENCY OUTSIDE THE BOUNDARY 原则：在边界之外使用最终一致性

There is a frequently overlooked statement found in the [Evans] Aggregate pattern definition. It bears heavily on what we must do to achieve model consistency when multiple Aggregates must be affected by a single client request:

> 在[Evans]对聚合模式的定义中，有一条经常被忽略。如果单次用户请求需要修改多个聚合实例，而此时我们又需要保证模型的一致性时，这一条便非常重要了：

Any rule that spans AGGREGATES will not be expected to be up-to-date at all times. Through event processing, batch processing, or other update mechanisms, other dependencies can be resolved within some specific time. [Evans, p. 128]

> 任何跨聚合的业务规则都不能总是保持处于最新状态。通过事件处理、批处理或者其他更新机制，我们可以在一定时间之内处理好他方依赖。[Evans，p.128]

Thus, if executing a command on one Aggregate instance requires that additional business rules execute on one or more other Aggregates, use eventual consistency. Accepting that all Aggregate instances in a large-scale, high-traffic enterprise are never completely consistent helps us accept that eventual consistency also makes sense in the smaller scale where just a few instances are involved.

> 因此，当在一个聚合上执行命令方法时，如果还需要在其他的聚合上执行额外的业务规则，那么请使用最终一致性。在一个大规模、高吞吐量的企业系统中，要使所有的聚合实例完全一致是不可能的。认识到这一点，你便知道在较小规模的系统中使用最终一致性也是有必要的。

Ask the domain experts if they could tolerate some time delay between the modification of one instance and the others involved. Domain experts are sometimes far more comfortable with the idea of delayed consistency than are developers. They are aware of realistic delays that occur all the time in their business, whereas developers are usually indoctrinated with an atomic change mentality. Domain experts often remember the days prior to computer automation of their business operations, when various kinds of delays occurred all the time and consistency was never immediate. Thus, domain experts are often willing to allow for reasonable delays—a generous number of seconds, minutes, hours, or even days—before consistency occurs.

> 问问你的领域专家，对于修改不同聚合实例之间的时间延迟，他们是否能够容忍。有时，领域专家甚至比开发者更能接受这种延迟。因为他们能意识到，在他们的业务中，延迟是客观存在的，而开发人员则总是期待着原子性操作。领域专家通常能回忆起在那个没有计算机的时代，他们的业务操作是什么样子。那时，总是存在各种各样的延迟，而一致性绝非立即之事。因此，领域专家通常是愿意接受那些有理由的延迟的——数秒钟、数分钟、数小时甚至数天的时间都是可以的。

There is a practical way to support eventual consistency in a DDD model. An Aggregate command method publishes a Domain Event that is in time delivered to one or more asynchronous subscribers:

> 在 DDD 中，有一种很实用的方法可以支持最终一致性，即一个聚合的命令方法所发布的领域事件及时地发送给异步的订阅方：

```java
public class BacklogItem extends ConcurrencySafeEntity  {
    ...
    public void commitTo(Sprint aSprint) {
        ...
        DomainEventPublisher
            .instance()
            .publish(new BacklogItemCommitted(
                    this.tenantId(),
                    this.backlogItemId(),
                    this.sprintId()));
    }
    ...
}
```

Each of these subscribers then retrieves a different yet corresponding Aggregate instance and executes its behavior based on it. Each of the subscribers executes in a separate transaction, obeying the rule of Aggregates to modify just one instance per transaction.

> 在接收到事件之后，每个订阅方都会获取自己的聚合实例，然后在该聚合上完成相应的操作。每个订阅方都在单独的事务中进行操作，也即满足了“在一次事务中只修改一个聚合实例”的原则。

What happens if the subscriber experiences concurrency contention with another client, causing its modification to fail? The modification can be retried if the subscriber does not acknowledge success to the messaging mechanism. The message will be redelivered, a new transaction started, a new attempt made to execute the necessary command, and a corresponding commit made. This retry process can continue until consistency is achieved, or until a retry limit is reached.6 If complete failure occurs, it may be necessary to compensate, or at a minimum to report the failure for pending intervention.

> 如果一个订阅方与其他客户端发生了并发竞争而使修改失败怎么办？此时，订阅方并不会向消息机制发回成功确认信号，所以消息会重发，然后开始一个新的事务重新触发更新操作。这个过程将持续进行直到一致性得到满足或者达到重试上限为止[6]。如果更新彻底失败，此时我们可以做个妥协，或者发出失败报告。

6. Consider attempting retries using Capped Exponential Back-off. Rather than defaulting to a retry every N fixed number of seconds, exponentially back off on retries while capping waits with an upper limit. For example, start at one second and back off exponentially, doubling until success or until reaching a 32-second wait-and-retry cap.

What is accomplished by publishing the BacklogItemCommitted Domain Event in this specific example? Recalling that BacklogItem already holds the identity of the Sprint it is committed to, we are in no way interested in maintaining a meaningless bidirectional association. Rather, the Event allows for the eventual creation of a CommittedBacklogItem so the Sprint can make a record of work commitment. Since each CommittedBacklogItem has an ordering attribute, it allows the Sprint to give each BacklogItem an ordering different from those of Product and Release, and that is not tied to the BacklogItem instance’s own recorded estimation of BusinessPriority. Thus, Product and Release hold similar associations, namely, ProductBacklogItem and ScheduledBacklogItem, respectively.

> 在上面的例子中，当 BacklogItemCommitted 领域事件发出之后，订阅方会做出什么反应呢？回忆一下，BacklogItem 已经维护了一个 Sprint 的唯一标识，要在它们之间维护双向关联并无多大意义。在接收到事件之后，订阅方会创建一个 CommittedBacklogItem，然后传给 Sprint。由于每个 CommittedBacklogItem 都拥有一个 ordering 属性，此时 Sprint 便可以为每个 BacklogItem 排序，该顺序与 Product 和 Release 中的 BacklogItem 顺序是不同的，另外，这里的顺序和 BacklogItem 的 BusinessPriority 是没有关系的。因此，Product 和 Release 所维护的关联是相似的，即它们分别维护了 ProductBacklogItem 和 ScheduledBacklogItem。

Whiteboard Time 白板时间

- Return to your list of large-cluster Aggregates and the two or more modified in a single transaction.
- Describe and diagram how you will break up the large clusters. Circle and note each of the true invariants inside each of the new small Aggregates.
- Describe and diagram how you will keep separate Aggregates eventually consistent.

---

> - 回到你先前所列的大聚合列表。
> - 想想如何拆分这些大聚合。在拆分后的小聚合中，圈出那些真正的不变条件，并做好笔记。
> - 描述一下，你将如何保证这些小聚合之间的最终一致性。

This example demonstrates how to use eventual consistency in a single Bounded Context, but the same technique can also be applied in a distributed fashion as previously described.

> 上面的例子向我们展示了如何在单个限界上下文中使用最终一致性，这种方式同样可以应用到那些分布式系统中。

### 10.5.1 Ask Whose Job It Is 谁的任务？

Some domain scenarios can make it very challenging to determine whether transactional or eventual consistency should be used. Those who use DDD in a classic/traditional way may lean toward transactional consistency. Those who use CQRS may tend toward eventual consistency. But which is correct? Frankly, neither of those tendencies provides a domain-specific answer, only a technical preference. Is there a better way to break the tie?

> 在有些场景下，我们很难决定是否应该使用事务一致性还是最终一致性。那些使用传统 DDD 手法的人可能更倾向于事务一致性，而那些使用 CQRS 的人则更倾向于采用最终一致性。但是哪种方法才是正确的呢？坦白地说，以上两种倾向都没有给出一个特定于领域的答案，而只是技术上的偏好而已。那么，是否有更好的方式来帮助我们选择呢？

Cowboy Logic 牛仔的逻辑

LB: “My son told me that he found on the Internet how to make my cows more fertile. I told him that’s the bull’s job.”

> LB：“我儿子告诉我说他在互联网上学到了如何使奶牛更加高产，我告诉他说那是公牛的任务。”

Image

Discussing this with Eric Evans revealed a very simple and sound guideline. When examining the use case (or story), ask whether it’s the job of the user executing the use case to make the data consistent. If it is, try to make it transactionally consistent, but only by adhering to the other rules of Aggregates. If it is another user’s job, or the job of the system, allow it to be eventually consistent. That bit of wisdom not only provides a convenient tie breaker, but it helps us gain a deeper understanding of our domain. It exposes the real system invariants: the ones that must be kept transactionally consistent. That understanding is much more valuable than defaulting to a technical leaning.

> 在与 Eric Evans 讨论了之后，我得到了一个简单而实用的指导原则。对于一个用例，问问是否应该由执行该用例的用户来保证数据的一致性。如果是，请使用事务一致性，当然此时依然需要遵循其他聚合原则。如果需要其他用户或者系统来保证数据一致性，请使用最终一致性。以上原则不仅有助于我们做出决定，还能帮助我们更深入地了解自己的领域。它向我们展示了真正的系统不变条件：那些必须使用事务一致性的不变条件。通过领域来理解问题比纯粹的技术学习更有价值。

This is a great tip to add to the Aggregate Rules of Thumb. Since there are other forces to consider, it may not always lead to the final choice between transactional and eventual consistency but will usually provide deeper insight into the model. This guideline is used later in the chapter when the team revisits their Aggregate boundaries.

> 对于聚合来说，以上原则是非常重要的。当然，由于我们还需要考虑其他因素，这个原则并不见得总是我们的最终选择。但无论如何，该原则通常能帮助我们更深层次地去了解自己的模型。在本章后面，当 SaaSOvation 的团队成员重新审视他们的聚合边界时，他们便使用了这个原则。

## 10.6 REASONS TO BREAK THE RULES 打破原则的理由

An experienced DDD practitioner may at times decide to persist changes to multiple Aggregate instances in a single transaction, but only with good reason. What might some reasons be? I discuss four reasons here. You may experience these and others.

> 对于有经验的 DDD 开发者来说，有时他们可能会选择在单个事务中更新多个聚合实例。但是，这么做的前提是：他们有充足的理由。那么，会有什么样的理由呢？

### 10.6.1 Reason One: User Interface Convenience 理由之一：方便用户界面

Sometimes user interfaces, as a convenience, allow users to define the common characteristics of many things at once in order to create batches of them. Perhaps it happens frequently that team members want to create several backlog items as a batch. The user interface allows them to fill out all the common properties in one section, and then one by one the few distinguishing properties of each, eliminating repeated gestures. All of the new backlog items are then planned (created) at once:

> 有些时候，出于方便考虑，用户界面可能允许用户一次性地给多个对象定义共有的属性，然后再对它们进行批量处理。比如，在 Scrum 中，团队成员可能会一次性地创建多个待定项。在用户界面中，他们可以先填入那些公有的待定项属性，然后再分别填入各个待定项的特有属性。所有的待定项将一次性地进行处理：

```java
public class ProductBacklogItemService ... {
    ...
    @Transactional
    public void planBatchOfProductBacklogItems(
        String aTenantId, String productId,
        BacklogItemDescription[] aDescriptions) {
        Product product =
            productRepository.productOfId(
                    new TenantId(aTenantId),
                    new ProductId(productId));

        for (BacklogItemDescription desc : aDescriptions) {
            BacklogItem plannedBacklogItem =
                product.planBacklogItem(
                    desc.summary(),
                    desc.category(),
                    BacklogItemType.valueOf(
                            desc.backlogItemType()),
                    StoryPoints.valueOf(
                            desc.storyPoints()));
            backlogItemRepository.add(plannedBacklogItem);
        }
    }
    ...
}
```

Does this cause a problem with managing invariants? In this case, no, since it would not matter whether these were created one at a time or in batch. The objects being instantiated are full Aggregates, which maintain their own invariants. Thus, if creating a batch of Aggregate instances all at once is semantically no different from creating one at a time repeatedly, it represents one reason to break the rule of thumb with impunity.

> 这会违背聚合的不变条件吗？在此例中，答案是否定的，因为重复创建单个待定项和批量创建多个待定项并无什么区别。我们所创建的实例都是整体性的聚合实例，它们会自行管理自己的不变条件。因此，在这种情况下，我们是有理由打破原则的。

### 10.6.2 Reason Two: Lack of Technical Mechanisms 理由之二：缺乏技术机制

Eventual consistency requires the use of some kind of out-of-band processing capability, such as messaging, timers, or background threads. What if the project you are working on has no provision for any such mechanism? While most of us would consider that strange, I have faced that very limitation. With no messaging mechanism, no background timers, and no other home-grown threading capabilities, what could be done?

> 最终一致性需要使用诸如消息、定时器或者后台线程之类的技术。如果你的项目并未采用这些技术，你应该怎么办呢？有人可能认为这非常奇怪，但是我的确遇到过这样的问题。在没有消息机制、没有定时器、没有后台线程的情况下，我们能做什么呢？

If we aren’t careful, this situation could lead us back toward designing large-cluster Aggregates. While that might make us feel as if we are adhering to the single transaction rule, as previously discussed it would also degrade performance and limit scalability. To avoid that, perhaps we could instead change the system’s Aggregates altogether, forcing the model to solve our challenges. We’ve already considered the possibility that project specifications may be jealously guarded, leaving us little room for negotiating previously unimagined domain concepts. That’s not really the DDD way, but sometimes it does happen. The conditions may allow for no reasonable way to alter the modeling circumstances in our favor. In such cases project dynamics may force us to modify two or more Aggregate instances in one transaction. However obvious this might seem, such a decision should not be made too hastily.

> 一不小心，我们就可能陷入设计大聚合的陷阱中。虽然这种方式满足了单一事务原则，但是，就像先前所讨论的，它将在很大程度上降低系统的性能和可伸缩性。为了避免这样的情况，我们可能会大规模地修改系统中的聚合，这样，我们便是在修改模型来解决问题。我们知道，项目规范不是轻易就能修改的，所以此时留给我们的空间并不大。虽然这并不是 DDD 的做法，但是它的确是有可能发生的。此时，我们是没有理由修改模型的。在这种情况下，我们可以考虑在单个事务中修改多个聚合实例。但是，我们不应该急切地做出这样的决定，而是应该慎重行事。

Cowboy Logic 牛仔的逻辑

AJ: “If you think that rules are made to be broken, you’d better know a good repairman.”

> AJ：“如果你认为规则是用来打破的，那么请找一个好的修理师。”

Image

Consider an additional factor that could further support diverging from the rule: user-aggregate affinity. Are the business workflows such that only one user would be focused on one set of Aggregate instances at any given time? Ensuring user-aggregate affinity makes the decision to alter multiple Aggregate instances in a single transaction more sound since it tends to prevent the violation of invariants and transactional collisions. Even with user-aggregate affinity, in rare situations users may face concurrency conflicts. Yet each Aggregate would still be protected from that by using optimistic concurrency. Anyway, concurrency conflicts can happen in any system, and even more frequently when user-aggregate affinity is not our ally. Besides, recovering from concurrency conflicts is straightforward when encountered at rare times. Thus, when our design is forced to, sometimes it works out well to modify multiple Aggregate instances in one transaction.

> 再考虑一下另一个可以打破原则的因素：用户-聚合亲和度（user-aggregateaffinity）。思考是否存在这么一种业务流：在某个时间，对于一组聚合实例，只有一个用户在处理它们。保证用户-聚合亲和度使我们更有理由在单个事务中修改多个聚合实例，因为这样不会违背聚合的不变条件，同时还可以避免事务冲突。即便在这种情况下，并发冲突也是有可能发生的。然而，要从并发冲突中恢复也是很直接的。因此，有时在单个事务中修改多个聚合是能够正常工作的。

### 10.6.3 Reason Three: Global Transactions 理由之三：全局事务

Another influence considered is the effects of legacy technologies and enterprise policies. One such might be the need to strictly adhere to the use of global, two-phase commit transactions. This is one of those situations that may be impossible to push back on, at least in the short term.

> 此外，我们还需要考虑遗留技术和企业政策所带来的影响。在这种情况下，我们通常需要使用全局的两阶段提交事务。但是，至少从短期看来，我们是不可能消除全局事务的。

Even if you must use a global transaction, you don’t necessarily have to modify multiple Aggregate instances at once in your local Bounded Context. If you can avoid doing so, at least you can prevent transactional contention in your Core Domain and actually obey the rules of Aggregates as far as you are able. The downside to global transactions is that your system will probably never scale as it could if you were able to avoid two-phase commits and the immediate consistency that goes along with them.

> 即便我们必须使用全局事务，这也并不意味着我们必须在本地限界上下文中一次性地修改多个聚合实例。如果可以避免全局事务，我们至少可以在自己的模型中消除事务竞争，从而满足聚合原则。全局事务的负面影响在于，我们的系统很难有好的伸缩性。

### 10.6.4 Reason Four: Query Performance 理由之四：查询性能

There may be times when it’s best to hold direct object references to other Aggregates. This could be used to ease Repository query performance issues. These must be weighed carefully in the light of potential size and overall performance trade-off implications. One example of breaking the rule of reference by identity is given later in the chapter.

> 有时，最好的方式还是在一个聚合中维护对其他聚合的直接引用，这有利于提高资源库的查询性能。当然，此时我们需要多方位权衡。在本章后面的一个例子中，我们便采用了直接引用对象这种方式。

### 10.6.5 Adhering to the Rules 遵循原则

You may experience user interface design decisions, technical limitations, stiff policies, or other factors in your enterprise environment that require you to make some compromises. Certainly we don’t go in search of excuses to break the Aggregate Rules of Thumb. In the long run, adhering to the rules will benefit our projects. We’ll have consistency where necessary, and support for optimally performing and highly scalable systems.

> 有很多因素都需要我们做出妥协，比如用户界面上的考虑、技术限制、生硬的企业政策等。当然，我们不应该去找各种借口来打破聚合原则。从长远看来，遵循聚合原则对整个项目是有益的。我们将尽可能地保证一致性，并且致力于创建高性能的、高可伸缩性的系统。

## 10.7 GAINING INSIGHT THROUGH DISCOVERY 通过发现，深入理解

With the rules of Aggregates in use, we’ll see how adhering to them affects the design of the SaaSOvation Scrum model. We’ll see how the project team rethinks their design again, applying newfound techniques. That effort leads to the discovery of new insights into the model. Their various ideas are tried and then superseded.

> 接下来，你将看到聚合原则是如何影响 SaaSOvation 团队设计他们的 Scrum 模型的。你将看到产品团队如何重新思考他们的设计。这些有助于他们深入理解自己的模型。

### 10.7.1 Rethinking the Design, Again 重新思考设计

After the refactoring iteration that broke up the large-cluster Product, the BacklogItem now stands alone as its own Aggregate. It reflects the model presented in Figure 10.7. The team composed a collection of Task instances inside the BacklogItem Aggregate. Each BacklogItem has a globally unique identity, its BacklogItemId. All associations to other Aggregates are inferred through identities. That means its parent Product, the Release it is scheduled within, and the Sprint to which it is committed are referenced by identities. It seems fairly small.

> 在对大的 Product 聚合进行拆分之后，BacklogItem 也变成了聚合，如图 10.7 所示。SaaSOvation 团队在 BacklogItem 中维护了一个 Task 的集合。每一个 BacklogItem 都有一个全局的唯一标识 BacklogItemId。BacklogItem 对其他聚合的引用都是通过标识引用完成的，包括 Product、Release 和 Sprint。此时的 BacklogItem 已经足够小了。

Image

Figure 10.7. The fully composed BacklogItem Aggregate

With the team now jazzed about designing small Aggregates, could they possibly overdo it in that direction?

> 现在，他们都知道了应该设计小的聚合，问题就在于，他们是否会把事情做得过度？

Image

Despite the good feeling coming out of that previous iteration, there was still some concern. For example, the story attribute allowed for a good deal of text. Teams developing agile stories won’t write lengthy prose. Even so, there is an optional editor component that supports writing rich use case definitions. Those could be many thousands of bytes. It was worth considering the possible overhead.

> 在上一个迭代中，团队成员们从大聚合 Product 中拆出了较小的 BacklogItem 聚合，他们感觉非常不错。但是，还有一些问题他们应该考虑，比如文本类型的 story 属性。在敏捷项目中，一个用户故事的描述通常不会太长。但是，有一个编辑器组件却允许用户输入很长的描述，此时的 story 属性可能包含成百上千个字节。因此，我们有必要考虑一下这种情况。

Given this potential overhead and the errors already made in designing the large-cluster Product of Figures 10.1 and 10.3, the team was now on a mission to reduce the size of every Aggregate in the Bounded Context. Crucial questions arose. Was there a true invariant between BacklogItem and Task that this relationship must maintain? Or was this yet another case where the association could be further broken apart, with two separate Aggregates being safely formed? What would be the total cost of keeping the design as is?

> 这种情况同时也出现在图 10.1 和图 10.3 所示的 Product 中，现在，团队正致力于缩小限界上下文中的每个聚合。关键的问题来了：在 BacklogItem 和 Task 之间是否存在真正的不变条件？或者我们应该将它们拆分开来，然后形成各自的聚合？保持原有设计的成本何在？

A key to their making a proper determination lay in the Ubiquitous Language. Here is where an invariant was stated:

> 做出决定的关键在于正确地使用通用语言。以下是团队成员提出的不变条件：

- When progress is made on a backlog item task, the team member will estimate task hours remaining.
- When a team member estimates that zero hours are remaining on a specific task, the backlog item checks all tasks for any remaining hours. If no hours remain on any tasks, the backlog item status is automatically changed to done.
- When a team member estimates that one or more hours are remaining on a specific task and the backlog item’s status is already done, the status is automatically regressed.

---

> - 当 BacklogItem 中的 Task 有进展时，团队成员需要估计该 Task 的剩余时间。
> - 当某个团队成员估计某个 Task 的剩余时间为零时，BacklogItem 将检查所有的 Task，如果所有的 Task 的剩余时间都为零，那么该 BacklogItem 的状态将被标记为完成。
> - 当某个团队成员估计出某个 Task 的剩余时间不为零，而此时 BacklogItem 已经被标记为完成状态，那么该 BacklogItem 的状态将被自动调回。

This sure seemed like a true invariant. The backlog item’s correct status is automatically adjusted and is completely dependent on the total number of hours remaining on all its tasks. If the total number of task hours and the backlog item status are to remain consistent, it seems as if Figure 10.7 does stipulate the correct Aggregate consistency boundary. However, the team should still determine what the current cluster could cost in terms of performance and scalability. That would be weighed against what they might save if the backlog item status could be eventually consistent with the total task hours remaining.

> 这看起来的确是一个不变条件，BacklogItem 的状态将自动调整，并且完全依赖于所包含 Task 的所有剩余时间。如果我们需要在 BacklogItem 和所有 Task 的总剩余时间之间保持一致，那么图 10.7 所表示的聚合一致性边界则是正确的。然而，我们依然需要考虑这种设计所带来的性能和可伸缩性影响。此时，我们可以将其与另一种情况进行比较：在 BacklogItem 与所有 Task 的总剩余时间之间维持最终一致性。

Some will see this as a classic opportunity to use eventual consistency, but we won’t jump to that conclusion just yet. Let’s analyze a transactional consistency approach, then investigate what could be accomplished using eventual consistency. We can then draw our own conclusion as to which approach is preferred.

> 有人可能认为，这是使用最终一致性的一个典型场景。但是，我们还不能轻易地得出这样的结论。让我们先看看在使用事务一致性时的情况如何，然后再讨论最终一致性。最后，得出自己的结论。

### 10.7.2 Estimating Aggregate Cost 估算聚合成本

As Figure 10.7 shows, each Task holds a collection of EstimationLogEntry instances. These logs model the specific occasions when a team member enters a new estimate of hours remaining. In practical terms, how many Task elements will each BacklogItem hold, and how many EstimationLogEntry elements will a given Task hold? It’s hard to say exactly. It’s largely a measure of how complex any one task is and how long a sprint lasts. But some back-of-the-envelope (BOTE) calculations might help [Bentley].

> 在图 10.7 中，每一个 Task 都拥有一个 EstimationLogEntry 实例的集合。一个 EstimationLogEntry 记录了团队成员对 Task 剩余时间的一次估计。在实际使用中，一个 BacklogItem 将拥有多少个 Task，而一个 Task 又将拥有多少个 EstimationLogEntry 呢？对于此，我们很难给出确切的答案，因为这取决于 Task 的复杂程度和一个 Sprint 的持续时间。但是，我们依然可以通过 back-of-theenvelope（BOTE）这种粗略的方法予以估算[Bentley]。

Task hours are usually reestimated each day after a team member works on a given task. Let’s say that most sprints are either two or three weeks in length. There will be longer sprints, but a two- to three-week time span is common enough. So let’s select a number of days somewhere between ten and 15. Without being too precise, 12 days works well since there may actually be more two-week than three-week sprints.

> 一个 Task 的剩余时间通常会在团队成员完成一天的工作之后进行重新估算。让我们假设，多数的 Sprint 都会持续 2 ～ 3 周的时间。当然，有些 Sprint 可能会持续很长时间，但是通常来说 2 ～ 3 周已经足够了。因此，让我们将一个 Sprint 的持续时间设为 10 ～ 15 天。在不需要特别精确的情况下，我们可以将 Sprint 的持续时间设为 12 天，因为实际上持续 2 周的 Sprint 比持续 3 周的 Sprint 更多。

Next, consider the number of hours assigned to each task. Remembering that tasks must be broken down into manageable units, we generally use a number of hours between four and 16. Normally if a task exceeds a 12-hour estimate, Scrum experts suggest breaking it down further. But using 12 hours as a first test makes it easier to simulate work evenly. We can say that tasks are worked on for one hour on each of the 12 days of the sprint. Doing so favors more complex tasks. So we’ll figure 12 reestimations per task, assuming that each task starts out with 12 hours allocated to it.

> 接下来，让我们考虑一下分配给每个 Task 的小时数。我们必须将任务分为一些可管理的单元。通常情况下，我们给每个 Task 分配的小时数在 4 ～ 16 小时之间。经常地，如果一个 Task 的剩余时间超过了 12 小时，那么 Scrum 专家便会建议对该 Task 做进一步拆分。但是，这里我们将 Task 的剩余时间设成了 12 小时，这样有助于对 Task 时间的均等分配，比如对于一个持续 12 天的 Sprint，我们可以每天给每个 Task 分配 1 小时的工作时间。

The question remains: How many tasks would be required per backlog item? That too is a difficult question to answer. What if we thought in terms of there being two or three tasks required per Layer (4) or Hexagonal Port-Adapter (4) for a given feature slice? For example, we might count three for the User Interface Layer (14), two for the Application Layer (14), three for the Domain Layer, and three for the Infrastructure Layer (14). That would bring us to 11 total tasks. It might be just right or a bit slim, but we’ve already erred on the side of numerous task estimations. Let’s bump it up to 12 tasks per backlog item to be more liberal. With that we are allowing for 12 tasks, each with 12 estimation logs, or 144 total collected objects per backlog item. While this may be more than the norm, it gives us a chunky BOTE calculation to work with.

> 到这里，我们还是没有解决这个问题：一个 BacklogItem 可以包含多少个 Task？要回答这个问题也是困难的。我们假设，系统中的每一个层（4）或者六边形端口-适配器（4）都需要 2 ～ 3 个 Task。比如，用户界面层（14）需要 3 个 Task；应用层（14）需要 2 个 Task；领域层需要 3 个 Task；基础设施层（14）也需要 3 个 Task。这样一来，我们便有 11 个 Task 了。这个数目可能正好，或者还是有点少，但是我们已经对各种 Task 进行了估算。让我们给每一个 BacklogItem 分配 12 个 Task。此时，又由于我们为每个 Task 预估了 12 个 EstimationLogEntry，那么一个 BacklogItem 将总共包含 144 个集合元素。虽然这可能多于常规，但是它至少给我们提供了一个默认的预估值。

There is another variable to be considered. If Scrum expert advice to define smaller tasks is commonly followed, it would change things somewhat. Doubling the number of tasks (24) and halving the number of estimation log entries (6) would still produce 144 total objects. However, it would cause more tasks to be loaded (24 rather than 12) during all estimation requests, consuming more memory on each. The team will try various combinations to see if there is any significant impact on their performance tests. But to start they will use 12 tasks of 12 hours each.

> 我们还需要考虑另一个不变条件。如果 Scrum 专家建议采用较小的 Task，那么以上估算就得随之改变了。将 Task 的数目上调成 24，而将每个 Task 所包含的 EstimationLogEntry 数目下调成 6，此时我们所得到的依然是 144 个对象。然而，这种方法将导致的问题是：在所有的估算请求中，我们需要加载更多的 Task，从而会消耗更多的内存。团队可以尝试不同的分配组合，然后观察每种组合对性能的影响。但是，作为开始，他们将维持先前的分配方式。

### 10.7.3 Common Usage Scenarios 常见用例场景

Now it’s important to consider common usage scenarios. How often will one user request need to load all 144 objects into memory at once? Would that ever happen? It seems not, but the team needs to check. If not, what’s the likely high-end count of objects? Also, will there typically be multiclient usage that causes concurrency contention on backlog items? Let’s see.

> 现在，是考虑常见的用例场景的时候了。要一次性地加载所有的 144 个对象，这样的用户请求频率会有多高？这种情况会发生吗？看来似乎没有发生的可能，但是我们需要核实。如果不会发生这样的情况，那么我们依然需要知道加载对象数目的平均期望值。另外，是否存在因为多个用户同时访问而产生并发竞争的情况？

The following scenarios are based on the use of Hibernate for persistence. Also, each Entity type has its own optimistic concurrency version attribute. This is workable because the changing status invariant is managed on the BacklogItem Root Entity. When the status is automatically altered (to done or back to committed), the Root’s version is bumped. Thus, changes to tasks can happen independently of each other and without impacting the Root each time one is modified, unless the result is a status change. (The following analysis could need to be revisited if using, for example, document-based storage, since the Root is effectively modified every time a collected part is modified.)

> 在以下场景中，我们使用了 Hibernate 作为持久化机制。此外，每一种实体类型都维护了用于乐观并发的版本号。这是可行的，因为对状态的更新是通过根实体 BacklogItem 来管理的。当状态自动更改时，根实体的版本号也将随之更新。因此，对某个 Task 的修改不会影响到其他的 Task，并且不会影响到根实体，除非对 Task 的修改将导致根实体状态的变化（在使用基于文档的存储时，由于每次集合的更改都会导致对根实体的修改，因此，对于下面的分析，我们需要回过头来重新考虑）。

When a backlog item is first created, there are zero contained tasks. Normally it is not until sprint planning that tasks are defined. During that meeting tasks are identified by the team. As each one is called out, a team member adds it to the corresponding backlog item. There is no need for two team members to contend with each other for the Aggregate, as if racing to see who can enter new tasks more quickly. That would cause collision, and one of the two requests would fail (for the same reason simultaneously adding various parts to Product previously failed). However, the two team members would probably soon figure out how counterproductive their redundant work is.

> 在刚创建一个 BacklogItem 时，它并不包含任何 Task。通常来说，直到召开冲刺计划会议时，Scrum 团队才会开始创建 Task，然后将 Task 添加到相应的 BacklogItem 中。此时，他们没有必要争着添加 Task，比如两个成员比赛，看谁能以更快的速度添加 Task。如果真是这样，结果将导致并发冲突，两个请求当中只有一个能够成功（与先前的同时向 Product 中添加内容是一个道理）。然而，这两个成员立即便会意识到，这种方式反而降低了效率。

If the developers learned that multiple users do indeed regularly want to add tasks together, it would change the analysis significantly. That understanding could immediately tip the scales in favor of breaking BacklogItem and Task into two separate Aggregates. On the other hand, this could also be a perfect time to tune the Hibernate mapping by setting the optimistic-lock option to false. Allowing tasks to grow simultaneously could make sense in this case, especially if they don’t pose performance and scalability issues.

> 如果的确存在多个用户同时添加 Task 的情况，那么我们的分析将大作修改。此时，我们应该考虑将 BacklogItem 和 Task 分成两个不同的聚合。另一方面，这也正是将 Hibernate 的 optimistic-lock 设置成 false 的时候。允许同时添加多个 Task 对于有些场景来说是有意义的，特别是当这样做并不会带来性能和可伸缩性问题的时候。

If tasks are at first estimated at zero hours and later updated to an accurate estimate, we still don’t tend to experience concurrency contention, although this would add one additional estimation log entry, pushing our BOTE total to 13. Simultaneous use here does not change the backlog item status. Again, it advances to done only by going from greater than zero to zero hours, or regresses to committed if already done and hours are changed from zero to one or more—two uncommon events.

> 如果 Task 的预估算剩余时间为零，我们依然不会遇到并发竞争的情况，但是这将导致 EstimationLogEntry 的 BOTE 数目变成 13。同时添加多个 Task 并不会修改 BacklogItem 的状态。只有当总共剩余时间从非零变成零时，或者从零变成非零时，BacklogItem 的状态才会改变——这是两个不常见的事件。

Will daily estimations cause problems? On day one of the sprint there are usually zero estimation logs on a given task of a backlog item. At the end of day one, each volunteer team member working on a task reduces the estimated hours by one. This adds a new estimation log to each task, but the backlog item’s status remains unaffected. There is never contention on a task because just one team member adjusts its hours. It’s not until day 12 that we reach the point of status transition. Still, as each of any 11 tasks is reduced to zero hours, the backlog item’s status is not altered. It’s only the very last estimation, the 144th on the 12th task, that causes automatic status transition to the done state.

> 每天都对剩余时间进行估算会造出问题吗？在一个 Sprint 的第一天，其中所包含的 EstimationLogEntry 数通常为零。该天结束时，每个团队成员都会将相应 Task 的剩余时间减 1。这将向 Task 中添加一个新的 EstimationLogEntry，但是此时 BacklogItem 的状态并没有改变。对于某个 Task 来说，是不会出现并发竞争的，因为只有一个成员修改该 Task 的剩余时间数。只有在第 12 天时，我们才会修改 BacklogItem 的状态。另外，其他 Task 也不会造成 BacklogItem 状态的改变。只有在最后一次估算时，即第 144 次估算，才有可能导致 BacklogItem 状态的变化。

This analysis led the team to an important realization. Even if they altered the usage scenarios, accelerating task completion by double (six days) or even mixing it up completely, it wouldn’t change anything. It’s always the final estimate that transitions the status, which modifies the Root. This seemed like a safe design, although memory overhead was still in question.

> 通过以上分析，团队成员们意识到了很重要的一点。即便他们修改用例场景，将任务完成时间缩短一半（6 天），他们依然无法改变任何东西。不管怎么样，只有在最后一次估算时，根实体的状态才会发生改变。这看来是一种安全的设计，虽然此时的内存消耗依然是一个问题。

### 10.7.4 Memory Consumption 内存消耗

Now to address the memory consumption. Important here is that estimates are logged by date as Value Objects. If a team member reestimates any number of times on a single day, only the most recent estimate is retained. The latest Value of the same date replaces the previous one in the collection. At this point there’s no requirement to track task estimation mistakes. There is the assumption that a task will never have more estimation log entries than the number of days the sprint is in progress. That assumption changes if tasks were defined one or more days before the sprint planning meeting, and hours were reestimated on any of those earlier days. There would be one extra log for each day that occurred.

> 现在，让我们来讨论一下内存消耗。有一点非常重要：每次估算都是按天进行的，并且采用了值对象来保存。如果一个团队成员在一天中进行了反复的估算，那么只有最后一次估算得以保留。后一次估算的值对象将替换掉同一天中的前一次估算。此时，还没有跟踪错误估算的需求，基本的假设是：某个 Task 所包含的 EstimationLogEntry 数目不应该超过 Sprint 所持续的天数。当然，如果 Task 在先于冲刺计划会议之前（比如提前 1 天或好几天）就创建好了，那么此时的假设也应该随之更改，另外，我们还需要重新估算在先前那些天中，一个 Task 所消耗的小时数。每多 1 天，EstimationLogEntry 也应该随之增加。

What about the total number of tasks and estimates in memory for each reestimation? When using lazy loading for the tasks and estimation logs, we would have as many as 12 plus 12 collected objects in memory at one time per request. This is because all 12 tasks would be loaded when accessing that collection. To add the latest estimation log entry to one of those tasks, we’d have to load the collection of estimation log entries. That would be up to another 12 objects. In the end the Aggregate design requires one backlog item, 12 tasks, and 12 log entries, or 25 objects maximum total. That’s not very many; it’s a small Aggregate. Another factor is that the higher end of objects (for example, 25) is not reached until the last day of the sprint. During much of the sprint the Aggregate is even smaller.

> 在每次重新估算时，所有 Task 和 EstimationLogEntry 的内存使用情况如何呢？对于一次请求，当采用延迟加载时，我们至多会一次性地向内存中加载 12+12 个集合对象。这是因为，在访问 Task 集合时，所有的 12 个 Task 实例都将加载到内存中；而要向某个 Task 添加 EstimationLogEntry，我们则需要加载整个 EstimationLogEntry 集合，即另外的 12 个对象。最终，我们需要加载一个 BacklogItem、12 个 Task 和 12 个 EstimationLogEntry，即最多 25 个对象。这样的内存消耗量并不大，此时的 BacklogItem 也是一个小聚合。另一方面，加载所有 25 个对象的情况也只会发生在冲刺的最后一天。在冲刺的执行过程中，BacklogItem 会更小。

Will this design cause performance problems because of lazy loads? Possibly, because it actually requires two lazy loads, one for the tasks and one for the estimation log entries for one of the tasks. The team will have to test to investigate the possible overhead of the multiple fetches.

> 延迟加载会造成性能上的影响吗？可能会，因为此时我们事实上需要两次延迟加载，一次是加载 Task，另一次则是加载 EstimationLogEntry。对此，团队成员需要进行性能测试。

There’s another factor. Scrum enables teams to experiment in order to identify the right planning model for their practices. As explained by [Sutherland], experienced teams with a well-known velocity can estimate using story points rather than task hours. As they define each task, they can assign just one hour to each task. During the sprint they will reestimate only once per task, changing one hour to zero when the task is completed. As it pertains to Aggregate design, using story points reduces the total number of estimation logs per task to just one and almost eliminates memory overhead.

> 还有另外一点：为了帮助团队做出正确的计划，Scrum 允许团队进行计划试验。[Sutherland]提到，有经验的团队可以通过用户故事点数（story point）而不是 Task 时间来估算速度。在他们定义 Task 时，他们可以为每个 Task 只分配 1 小时的时间。在冲刺执行过程中，对于每个 Task，他们只会重新估算一次，即当 Task 完成时将时间由 1 小时改成零。使用用户故事点数可以减少一个 Task 中的 EstimationLogEntry 数目，并且可以优化对内存的消耗。

Image

Later on, ProjectOvation developers will be able to analytically determine (on average) how many actual tasks and estimation log entries exist per backlog item by examining real production data.

> 之后，ProjectOvation 的开发者们将使用真实的产品数据来分析一个 BacklogItem 所包含的 Task 数和 EstimationLogEntry 的数目。

The foregoing analysis was enough to motivate the team to test against their BOTE calculations. After inconclusive results, however, they decided that there were still too many variables for them to be confident that this design dealt well with their concerns. There were enough unknowns to consider an alternative design.

> 对于测试 BOTE 估算来说，先前的分析已经足够了。然而，在没有明确结果的情况下，他们认为依然存在很多不可预测的因素，这些因素足以使他们采用另外的设计。

### 10.7.5 Exploring Another Alternative Design 探索另外的设计

Is there another design that could contribute to Aggregate boundaries more fitting to the usage scenarios?

> 有没有更好的设计比前面的用例场景能更好地处理聚合边界呢？

To be thorough, the team wanted to think through what they would have to do to make Task an independent Aggregate, and if that would actually work to their benefit. What they envisioned is seen in Figure 10.8. Doing this would reduce part composition overhead by 12 objects and reduce lazy load overhead. In fact, this design gave them the option to eagerly load estimation log entries in all cases if that would perform best.

> 团队成员希望找到一种方式将 Task 设计成单独的聚合，他们的方案如图 10.8 所示。这样做的好处在于，他们将 12 个 EstimationLogEntry 从 BacklogItem 中彻底分离出来，对于延迟加载来说，这也是有好处的。事实上，这使得他们在加载 EstimationLogEntry 时可以采用即时加载的方式。

Image

Figure 10.8. BacklogItem and Task modeled as separate Aggregates

The developers agreed not to modify separate Aggregates, both the Task and the BacklogItem, in the same transaction. They had to determine if they could perform a necessary automatic status change within an acceptable time frame. They’d be weakening the invariant’s consistency since the status couldn’t be consistent by transaction. Would that be acceptable? They discussed the matter with the domain experts and learned that some delay between the final zero-hour estimate and the status being set to done, and vice versa, would be acceptable.

> 开发者们达成了一致：不要在同一个事务中同时修改 Task 和 BacklogItem。他们需要决定的是：是否可以在一个可接受的时间范围之内对 BacklogItem 的状态进行更新。这样做的结果是：他们可能会弱化不变条件的一致性，因为此时的一致性不再通过事务来达到。这是可以接受的吗？他们与领域专家进行了讨论，得知这种情况是可以接受的。

### 10.7.6 Implementing Eventual Consistency 实现最终一致性

It looks as if there could be a legitimate use of eventual consistency between separate Aggregates. Here is how it could work.

> 这样看来，他们便有理由在不同的聚合之间使用最终一致性了。

When a Task processes an estimateHoursRemaining() command, it publishes a corresponding Domain Event. It does that already, but the team would now leverage the Event to achieve eventual consistency. The Event is modeled with the following properties:

> 当执行 Task 的 estimateHoursRemaining（）命令方法时，它将发布相应的事件。在这之前，该方法已经具备这样的功能了，但是他们这里需要考虑的是使用事件来达到最终一致性。该事件具有以下属性：

```java
public class TaskHoursRemainingEstimated implements DomainEvent {
    private Date occurredOn;
    private TenantId tenantId;
    private BacklogItemId backlogItemId;
    private TaskId taskId;
    private int hoursRemaining;
    ...
}
```

A specialized subscriber would now listen for these and delegate to a Domain Service to coordinate the consistency processing. The Service would

> 一个特定的订阅方将对该事件进行监听，当事件到达时，它会委派给领域服务来协调对一致性的处理。该领域服务将：

- Use the BacklogItemRepository to retrieve the identified BacklogItem.
- Use the TaskRepository to retrieve all Task instances associated with the identified BacklogItem.
- Execute the BacklogItem command named estimateTaskHoursRemaining(), passing the Domain Event’s hoursRemaining and the retrieved Task instances. The BacklogItem may transition its status depending on parameters.

---

> - 通过 BacklogItemRepository 获取指定的 BacklogItem。
> - 通过 TaskRepository 获取 BacklogItem 所关联的所有 Task 实例。
> - 执行 BacklogItem 的 estimateTaskHoursRemaining（）命令方法，传入的参数包含有领域事件中的 hoursRemaining 和所有获取到的 Task 实例。根据传入的参数，BacklogItem 可能会自动更新自身的状态•。

The team should find a way to optimize this. The three-step design requires all Task instances to be loaded every time a reestimation occurs. When using our BOTE estimate and advancing continuously toward done, 143 out of 144 times that’s unnecessary. This could be optimized pretty easily. Instead of using the Repository to get all Task instances, they could simply ask it for the sum of all Task hours as calculated by the database:

> 团队应该找到一种方法来优化以上过程。在每次重新估算剩余时间的时候，上面的 3 个步骤需要将所有的 Task 实例加载进内存。在使用 BOTE 估算时，144 次估算中的 143 次都是没有必要的。当然，优化起来也是比较简单的。与其使用资源库来获取所有的 Task 实例，他们可以简单地使资源库直接返回所有 Task 的剩余时间：

```java
public class HibernateTaskRepository implements TaskRepository {
    ...
    public int totalBacklogItemTaskHoursRemaining(
            TenantId aTenantId,
            BacklogItemId aBacklogItemId) {
        Query query = session.createQuery(
            "select sum(task.hoursRemaining) from Task task "
            + "where task.tenantId = ? and "
            + "task.backlogItemId = ?");
        ...
    }
}
```

Eventual consistency complicates the user interface a bit. Unless the status transition can be achieved within a few hundred milliseconds, how would the user interface display the new state? Should they place business logic in the view to determine the current status? That would constitute a smart UI anti-pattern. Perhaps the view would just display the stale status and allow users to deal with the visual inconsistency. That could easily be perceived as a bug, or at least be very annoying.

> 最终一致性可能会在一定程度上使用户界面变得复杂。在事件延迟的几百个毫秒期间，用户界面如何显示新的状态呢？它们应该在用户界面层中加入业务逻辑以决定当前的状态吗？这样做将导致智能 UI 这种反模式。或许它们可以显示老的状态，然后让用户自行处理显示上的不一致性。但是，这很有可能被看成是一个 bug，或者至少是很烦人的。

The view could use a background Ajax polling request, but that could be quite inefficient. Since the view component could not easily determine exactly when checking for a status update is necessary, most Ajax pings would be unnecessary. Using our BOTE numbers, 143 of 144 reestimations would not cause the status update, which is a lot of redundant requests on the Web tier. With the right server-side support the clients could instead depend on Comet (aka Ajax Push). Although a nice challenge, that would introduce a completely new technology that the team had no experience using.

> 在显示状态时，它们可以通过“拉取”的方式使用 Ajax，但是这却是非常低效的。由于显示组件并不确切地知道何时应该检查状态更新，多数 Ajax 请求都是没有必要的。在使用 BOTE 估算时，144 次重新估算中的 143 次都不会导致 BacklogItem 状态的变化，因此，这些请求对于 Web 层来说是多余的。更好的方式是采用 Comet（即 Ajax 推送）。虽然这是一个不错的挑战，但是对于团队成员来说，这却是一项全新的技术。

On the other hand, perhaps the best solution is the simplest. They could opt to place a visual cue on the screen that informs the user that the current status is uncertain. The view could suggest a time frame for checking back or refreshing. Alternatively, the changed status will probably show on the next rendered view. That’s safe. The team would need to run some user acceptance tests, but it looked hopeful.

> 另一方面，最好的方式可能也是最简单的方式。它们可以在界面上直接告诉用户：此时的状态是不正确的。用户界面将定期检查状态并刷新。这样一来，改变之后的状态可能会在下一次界面刷新时予以显示。这是安全的。当然，团队成员还需要进行用户验收测试，但是这种方式看起来是很有希望的。

### 10.7.7 Is It the Team Member’s Job? 这是 Scrum 团队成员的任务吗？

One important question has thus far been completely overlooked: Whose job is it to bring a backlog item’s status into consistency with all remaining task hours? Do team members using Scrum care if the parent backlog item’s status transitions to done just as they set the last task’s hours to zero? Will they always know they are working with the last task that has remaining hours? Perhaps they will and perhaps it is the responsibility of each team member to bring each backlog item to official completion.

> 到这里，我们还忽略了一个很重要的问题：应该由谁来负责维护 BacklogItem 与所有 Task 剩余时间之间的一致性？当 Scrum 的团队成员将最后一个 Task 的剩余时间设置为零后，BacklogItem 将变成完成状态。问题在于，他们会关心这些吗？他们知道自己所工作的 Task 就是最后一个 Task 吗？可能吧，也许每个团队成员都应该承担这样的职责。

On the other hand, what if there is another project stakeholder involved? For example, the product owner or some other person may desire to check the candidate backlog item for satisfactory completion. Maybe someone wants to use the feature on a continuous integration server first. If others are happy with the developers’ claim of completion, they will manually mark the status as done. This certainly changes the game, indicating that neither transactional nor eventual consistency is necessary. Tasks could be split off from their parent backlog item because this new use case allows it. However, if it is really the team members who should cause the automatic transition to done, it would mean that tasks should probably be composed within the backlog item to allow for transactional consistency. Interestingly, there is no clear answer here either, which probably indicates that it should be an optional application preference. Leaving tasks within their backlog item solves the consistency problem, and it’s a modeling choice that can support both automatic and manual status transitions.

> 另一方面，如果一个项目还存在其他利益相关方，又该怎么办呢？比如，产品负责人有可能需要检查一个 BacklogItem 的状态，也或者有人想率先使用部署在持续集成服务器上的系统功能。对于由程序自动完成的状态转换，如果其他人表示满意，那么他们可以手动地将状态设成完成。这显然改变了游戏规则，因为，此时不管是事务一致性还是最终一致性都是没有必要的。一个 Task 可能会从其所属的 BacklogItem 中分离出来，因为这是新的用例所允许的。然而，如果真的应该由 Scrum 团队成员来发起对 BacklogItem 状态的改变，这就意味着 Task 应该包含在 BacklogItem 之内以允许事务一致性。有趣的是，对于这个问题，也没有明确的答案。这或许意味着，我们应该将该功能以一个可选择的偏好设置提供给客户。将 Task 包含在 BacklogItem 之内可以解决一致性问题，同时，这种方式能够同时支持对 BacklogItem 状态的自动更新和手动更新。

This valuable exercise uncovered a completely new aspect of the domain. It seems as if teams should be able to configure a workflow preference. They won’t implement such a feature now, but they will promote it for further discussion. Asking “whose job is it?” led them to a few vital perceptions about their domain.

> 这次练习是很有意义的，它揭示出了领域中另一个崭新的方面。看来，SaaSOvation 的团队应该为系统添加一个工作流偏好设置。他们不会立即实现这个功能，但是他们会在之后的讨论中提出来。通过询问“谁的责任？”这个问题，SaaSOvation 的团队成员们进一步理解了他们的领域。

Image

Next, one of the developers made a very practical suggestion as an alternative to this whole analysis. If they were chiefly concerned with the possible overhead of the story attribute, why not do something about that specifically? They could reduce the total storage capacity for the story and in addition create a new useCaseDefinition property. They could design it to lazy load, since much of the time it would never be used. Or they could even design it as a separate Aggregate, loading it only when needed. With that idea they realized this could be a good time to break the rule to reference external Aggregates only by identity. It seemed like a suitable modeling choice to use a direct object reference and declare its object-relational mapping so as to lazily load it. Perhaps that made sense.

> 后来，其中一个开发者提出了一个非常实用的建议，该建议可以作为另一种分析问题的途径。如果他们特别关心由 story 属性所带来的负面影响，那么他们为什么不对此做些什么呢？他们可以减少 story 属性的存储空间，然后再引入一个 useCaseDefinisiton 属性。此外，还可以采用延迟加载的方式，因为多数时间 story 属性是不会被用到的。也或者，他们甚至可以为 story 属性创建一个单独的聚合，在需要的时候才进行加载。此时便是打破原则的好时候啦，即不再通过对象标识来引用外部聚合，而是直接维护对象引用，然后在 ORM 中将其设置成延迟加载。

### 10.7.8 Time for Decisions 决定的时候到了

This level of analysis can’t continue all day. There needs to be a decision. It’s not as if going in one direction now would negate the possibility of going another route later. Open-mindedness is now blocking pragmatism.

> 这种层面的分析不能够一直持续下去，总会到做决定的时候。现在我们决定走这条路，并不意味这之后我们就不能走其他的路。此时，开放的思想限制了实用性。

Based on all this analysis, currently the team was shying away from splitting Task from BacklogItem. They couldn’t be certain that splitting it now was worth the extra effort, the risk of leaving the true invariant unprotected, or allowing users to experience a possible stale status in the view. The current Aggregate, as they understood it, was fairly small. Even if their common worst case loaded 50 objects rather than 25, it would still be a reasonably sized cluster. For now they planned around the specialized use case definition holder. Doing that was a quick win with lots of benefits. It added little risk, because it will work now, and it will also work in the future if they decide to split Task from BacklogItem.

> 基于以上所有分析，团队并不打算将 Task 从 BacklogItem 中分离出来。他们还不清楚这样的分离是否会带来风险，比如不变条件将得不到保护，或者用户无法看到实时的状态等。当前的聚合已经相当小了。即便在最坏的情况下，也只有 50 个对象加载进内存，而这所消耗的内存并不算大。因此，他们决定暂时保留先前的做法。这是有很多好处的，首先风险并不大，因为目前的实现方案已经工作得很好；另外，如果之后他们决定将 Task 从 BacklogItem 中分离出来，它依然可以工作。

The option to split it in two remained in their hip pocket just in case. After further experimentation with the current design, running it through performance and load tests, as well investigating user acceptance with an eventually consistent status, it will become clearer which approach is better. The BOTE numbers could prove to be wrong if in production the Aggregate is larger than imagined. If so, the team will no doubt split it into two.

> 将来，在有必要的情况下，他们依然会考虑对 BacklogItem 和 Task 的拆分。在对当前的设计方案进行了性能测试、负载测试和用户验收测试之后，他们应该知道什么样的方案是更好的。在产品环境中，BOTE 估算可能是错误的，因为产品环境中的聚合实例很有可能比想象中的多。在这种情况下，对 BacklogItem 和 Task 的拆分便是毫无疑问的了。

If you were a member of the ProjectOvation team, which modeling option would you have chosen? Don’t shy away from discovery sessions as demonstrated in the case study. That entire effort would require 30 minutes, and perhaps as much as 60 minutes at worst. It’s well worth the time to gain deeper insight into your Core Domain.

> 如果你是 ProjectOvation 团队的一员，你会选择哪种设计方案？不要回避像先前案例研究中那样的发现讨论会议，这样的会议通常只会持续 30 分钟，最坏的情况也不过 60 分钟。但是，如果你想在更深层次上了解自己的领域，那么这些时间是值得的。

## 10.8 IMPLEMENTATION 实现

The more prominent factors summarized and highlighted here can make implementations more robust but should be investigated more thoroughly in Entities (5), Value Objects (6), Domain Events (8), Modules (9), Factories (11), and Repositories (12). Use this amalgamation as a point of reference.

> 这里，我们主要强调那些有助于增强实现健壮性的因素。但是，我们还应该全面地在实体（5）、值对象（6）、领域服务（8）、模块（9）、工厂（11）和资源库（12）中对聚合的实现进行探讨。

### 10.8.1 Create a Root Entity with Unique Identity 创建具有唯一标识的根实体

Model one Entity as the Aggregate Root. Examples of Root Entities in the preceding modeling efforts are Product, BacklogItem, Release, and Sprint. Depending on the decision made to split Task from BacklogItem, Task may also be a Root.

> 将实体建模成聚合根（Aggregat Root）。在前面的例子中，Product、BacklogItem、Release 和 Sprint 都可以作为根实体。如果我们将 Task 从 BacklogItem 中分离，那么 Task 也是一个根实体。

The refined Product model finally led to the declaration of the following Root Entity:

> 对 Product 实体的优化最终导致了以下根实体：

```java
public class Product extends ConcurrencySafeEntity  {
    private Set<ProductBacklogItem> backlogItems;
    private String description;
    private String name;
    private ProductDiscussion productDiscussion;
    private ProductId productId;
    private TenantId tenantId;
    ...
}
```

Class ConcurrencySafeEntity is a Layer Supertype [Fowler, P of EAA] used to manage surrogate identity and optimistic concurrency versioning, as explained in Entities (5).

> 这里的 ConcurrencySafeEntity 是一个层超类型[Fowler，P of EAA]，它用于管理委派标识和乐观并发的版本号，请参考实体（5）。

A Set of ProductBacklogItem instances not previously discussed has been, perhaps mysteriously, added to the Root. This is for a special purpose. It’s not the same as the BacklogItem collection that was formerly composed here. It is for the purpose of maintaining a separate ordering of backlog items.

> 先前，我们并没有讨论到 ProductBacklogItem。这里，Product 维护了一个 ProductBacklogItem 的集合。这是故意而为之的。但是，ProductBacklogItem 和前面所讨论的 BacklogItem 是不同的。ProductBacklogItem 集合的作用在于维护一个有序的待定项集合。

Each Root must be designed with a globally unique identity. The Product has been modeled with a Value type named ProductId. That type is the domain-specific identity, and it is different from the surrogate identity provided by ConcurrencySafeEntity. How a model-based identity is designed, allocated, and maintained is further explained in Entities (5). The implementation of ProductRepository has nextIdentity() generate ProductId as a UUID:

> 每个聚合根必须拥有一个全局的唯一标识。Product 的唯一标识以值对象 ProductId 表示。ProductId 是和领域相关的标识，它和 ConcurrencySafeEntity 中的委派标识是不一样的。关于领域模型的唯一标识，请参考实体（5）。ProductRepository 的实现中包含了 nextIdentity（）方法来生成以 UUID 所表示的 ProductId：

```java
public class HibernateProductRepository implements ProductRepository  {
    ...
    public ProductId nextIdentity() {
        return new ProductId(java.util.UUID.randomUUID().toString().toUpperCase());
    }
    ...
}
```

Using nextIdentity(), a client Application Service can instantiate a Product with its globally unique identity:

> 使用 nextIdentity（）方法，客户端中的应用服务便可以创建一个具有全局唯一标识的 Product 实例：

```java
public class ProductService ... {
   ...
   @Transactional
   public String newProduct(
        String aTenantId, aProductName, aProductDescription) {
        Product product =
            new Product(
                new TenantId(aTenantId),
                this.productRepository.nextIdentity(),
                "My Product",
                "This is the description of my product.",
                new ProductDiscussion(
                        new DiscussionDescriptor(
                            DiscussionDescriptor.UNDEFINED_ID),
                        DiscussionAvailability.NOT_REQUESTED));
        this.productRepository.add(product);
        return product.productId().id();
    }
    ...
}
```

The Application Service uses ProductRepository to both generate an identity and then persist the new Product instance. It returns the plain String representation of the new ProductId.

> 在上例中，应用服务使用了 ProductRepository 来同时生成实体标识和持久化 Product 实例。其中的 newProduct（）方法返回一个用 String 类型表示的 ProductId。

### 10.8.2 Favor Value Object Parts 优先使用值对象

Choose to model a contained Aggregate part as a Value Object rather than an Entity whenever possible. A contained part that can be completely replaced, if its replacement does not cause significant overhead in the model or infrastructure, is the best candidate.

> 我们应该尽量地将根实体所包含的其他聚合建模成值对象，而不是实体。在不至于对模型或基础设施造成明显影响的情况下，采用值对象全部替换的方式是最好的选择。

Our current Product model is designed with two simple attributes and three Value-typed properties. Both description and name are String attributes that can be completely replaced. The productId and tenantId Values are maintained as stable identities; that is, they are never changed after construction. They support reference by identity rather than direct to object. In fact, the referenced Tenant Aggregate is not even in the same Bounded Context and thus should be referenced only by identity. The productDiscussion is an eventually consistent Value-typed property. When the Product is first instantiated, the discussion may be requested but will not exist until sometime later. It must be created in the Collaboration Context. Once the creation has been completed in the other Bounded Context, the identity and status are set on the Product.

> 当前的 Product 包含了 2 个简单属性和 3 个值对象属性。其中的 description 和 name 都是 String 类型，它们是可以被全部替换的。另外，productId 和 tenantId 值对象被建模成了稳定的标识，即在 Product 创建之后，它们将不再改变。它们支持标识引用，而不是直接对象引用。事实上，Product 所引用的 Tenant 甚至都不在相同的限界上下文中，因此只能使用标识引用。Product 中的 productDiscussion 是一个具有最终一致性的值对象属性。在 Product 创建之初，用户可能会要求创建产品 Discussion，但是只有在一段时间之后，该 Discussion 才会存在。另外，产品 Discussion 必须在协作上下文中进行创建，在创建完成之后，本地上下文将在 Product 中为 productDiscussion 设置标识和状态。

There are good reasons why ProductBacklogItem is modeled as an Entity rather than a Value. As discussed in Value Objects (6), since the backing database is used via Hibernate, it must model collections of Values as database entities. Reordering any one of the elements could cause a significant number, even all, of the ProductBacklogItem instances to be deleted and replaced. That would tend to cause significant overhead in the infrastructure. As an Entity, it allows the ordering attribute to be changed across any and all collection elements as often as a product owner requires. However, if we were to switch from using Hibernate with MySQL to a key-value store, we could easily change ProductBacklogItem to be a Value type instead. When using a key-value or document store, Aggregate instances are typically serialized as one value representation for storage.

> 我们将 ProductBacklogItem 建模成了一个实体，而非值对象。这是有原因的。正如在值对象（6）中所讨论的，由于我们采用了 Hibernate 来访问数据库，对于值对象集合来说，Hibernate 必须为其中的元素创建数据库实体。对集合元素的重新排序将删除或替换大量的 ProductBacklogItem 实例，这将对基础设施造成严重影响。作为实体，ProductBacklogItem 允许对 ordering 属性的任意修改，只要这是产品负责人所需的。然而，如果我们打算从 Hibernate 转向 MySQL 的键值对存储，我们可以轻易地将 ProductBacklogItem 变成值对象。在使用键值对或文档存储时，聚合实例通常都被序列化成一个值展现予以存储。

### 10.8.3 Using Law of Demeter and Tell, Don’t Ask 使用迪米特法则和“告诉而非询问”原则

Both Law of Demeter [Appleton, LoD] and Tell, Don’t Ask [PragProg, TDA] are design principles that can be used when implementing Aggregates, both of which stress information hiding. Consider the high-level guiding principles to see how we can benefit:

> 在实现聚合时，我们可以采用迪米特法则（Law of Demeter）[Appleton，LoD]和告诉而非询问原则（Tell，Don't Ask）[PragProg，TDA]，它们都强调信息隐藏。让我们仔细了解一下这两个高层次的指导原则：

- Law of Demeter: This guideline emphasizes the principle of least knowledge. Think of a client object and another object the client object uses to execute some system behavior; refer to the second object as a server. When the client object uses the server object, it should know as little as possible about the server’s structure. The server’s attributes and properties—its shape—should remain completely unknown to the client. The client can ask the server to perform a command that is declared on its surface interface. However, the client must not reach into the server, ask the server for some inner part, and then execute a command on the part. If the client needs a service that is rendered by the server’s inner parts, the client must not be given access to the inner parts to request that behavior. The server should instead provide only a surface interface and, when invoked, delegate to the appropriate inner parts to fulfill its interface.

> - 迪米特法则：强调了“最小知识”原则。考虑一个客户端对象需要调用系统中其他对象的行为方法的场景，此时我们可以将后者称为服务对象。在客户端对象使用服务对象时，它应该尽量少地知道服务对象的内部结构。客户端对象不应该知道任何关于服务对象属性的信息。客户端对象可以根据表层接口调用服务对象上的命令方法。然而，客户端对象不应该渗入到服务对象的内部。如果客户端所需服务位于服务对象的内部，那么此时客户端对象便不应该访问这样的服务。对于服务对象来说，它只应该提供表层接口，在接口方法被调用时，它将操作委派给内部方法以完成功能。对迪米特法则做一个简单的总结：任何对象的任何方法只能调用以下对象中的方法：（1）该对象自身，（2）所传入的参数对象，（3）它所创建的对象，（4）自身所包含的其他对象，并且对那些对象有直接访问权。

Here’s a basic summary of the Law of Demeter: Any given method on any object may invoke methods only on the following: (1) itself, (2) any parameters passed to it, (3) any object it instantiates, (4) self-contained part objects that it can directly access.

- Tell, Don’t Ask: This guideline simply asserts that objects should be told what to do. The “Don’t Ask” part of the guideline applies to the client as follows: A client object should not ask a server object for its contained parts, then make a decision based on the state it got, and then make the server object do something. Instead, the client should “Tell” a server what to do, using a command on the server’s public interface. This guideline has very similar motivations as Law of Demeter, but Tell, Don’t Ask may be easier to apply broadly.

> - 告诉而非询问原则：一个对象不应该被告知如何执行操作。对于客户端来说，这里的“非询问”表示：客户端对象不应该首先询问服务对象，然后根据询问结果调用服务对象中的方法，而是应该通过调用服务对象的公共接口的方式来“告诉”服务对象所要执行的操作。该原则和迪米特原则存在相似之处，但是使用起来更加简单。

Given these guidelines, let’s see how we apply the two design principles to Product:

> 有了以上原则，让我们看看如何将它们用在 Product 中：

```java
public class Product extends ConcurrencySafeEntity  {
    ...
    public void reorderFrom(BacklogItemId anId, int anOrdering) {
        for (ProductBacklogItem pbi : this.backlogItems()) {
            pbi.reorderFrom(anId, anOrdering);
        }
    }

    public Set<ProductBacklogItem> backlogItems() {
        return this.backlogItems;
    }
    ...
}
```

The Product requires clients to use its method reorderFrom() to execute a state-modifying command in its contained backlogItems. That is a good application of the guidelines. Yet, method backlogItems() is also public. Does this break the principles we are trying to follow by exposing ProductBacklogItem instances to clients? It does expose the collection, but clients may use those instances only to query information from them. Because of the limited public interface of ProductBacklogItem, clients cannot determine the shape of Product by deep navigation. Clients are given least knowledge. As far as clients are concerned, the returned collection instances may have been created only for the single operation and may represent no definite state of Product. Clients may never execute state-altering commands on the instances of ProductBacklogItem, as its implementation indicates:

> Product 要求客户端执行其 reorderFrom（）方法，该方法将进一步执行每个 ProductBacklogItem 的命令方法以修改自身状态。这是一个很好的例子。但是，这里的 backlogItems（）方法也是公有的。这是否违背了“信息隐藏”的总原则呢，因为我们将 ProductBacklogItem 集合也暴露给了客户端？这的确会将 ProductBacklogItem 集合暴露给客户端，但是客户端只能在这些集合元素上进行查询操作。由于 ProductBacklogItem 接口上的限制，客户端并不能从中了解到 Product 的内部。客户端所获得的信息被最小化了。对于客户端来说，它也只会将所得到的 ProductBacklogItem 集合用于查询，此外，这些 ProductBacklogItem 可能并不能反映出 Product 的确切状态。客户端决不能直接执行 ProductBacklogItem 中的命令方法，以下是 ProductBacklogItem 的实现：

```java
public class ProductBacklogItem extends ConcurrencySafeEntity  {
    ...
    protected void reorderFrom(BacklogItemId anId, int anOrdering) {
        if (this.backlogItemId().equals(anId)) {
            this.setOrdering(anOrdering);
        } else if (this.ordering() >= anOrdering) {
            this.setOrdering(this.ordering() + 1);
        }
    }
    ...
}
```

Its only state-modifying behavior is declared as a hidden, protected method. Thus, clients can’t see or reach this command. For all practical purposes, only Product can see it and execute the command. Clients may use only the Product public reorderFrom() command method. When invoked, the Product delegates to all its internal ProductBacklogItem instances to perform the inner modifications.

> ProductBacklogItem 唯一可以修改状态的方法被声明成了 protected。因此，该方法对于客户端来说是不可见的，更不用说调用了。在实际应用中，只有 Product 能够调用 ProductBacklogItem 的命令方法。客户端只能使用 Product 的 reorderFrom（）公有方法。在调用时，Product 将委派给所有的 ProductBacklogItem 以完成实际的功能。

The implementation of Product limits knowledge about itself, is more easily tested, and is more maintainable, due to the application of these simple design principles.

> 由于应用了以上设计原则，Product 的实现对于其自身来说也达到了“最小知识”的目的。另外，以这种方式实现的 Product 也更利于测试和维护。

You will need to weigh the competing forces between use of Law of Demeter and Tell, Don’t Ask. Certainly the Law of Demeter approach is much more restrictive, disallowing all navigation into Aggregate parts beyond the Root. On the other hand, the use of Tell, Don’t Ask allows for navigation beyond the Root but does stipulate that modification of the Aggregate state belongs to the Aggregate, not the client. You may thus find Tell, Don’t Ask to be a more broadly applicable approach to Aggregate implementation.

> 我们需要在迪米特法则和“告诉而非询问”原则之间进行权衡。前者的限制性更强，它只允许客户端通过聚合根进行访问。另一方面，“告诉而非询问”原则则允许客户端访问聚合根的内部，但是它也要求对聚合状态的修改应该属于聚合本身，而不是客户端。因此，在多数情况下，“告诉而非询问”原则将更加适用。

### 10.8.4 Optimistic Concurrency 乐观并发

Next, we need to consider where to place the optimistic concurrency version attribute. When we contemplate the definition of Aggregate, it could seem safest to version only the Root Entity. The Root’s version would be incremented every time a state-altering command is executed anywhere inside the Aggregate boundary, no matter how deep. Using the running example, Product would have a version attribute, and when any of its describeAs(), initiateDiscussion(), rename(), or reorderFrom() command methods are executed, the version would always be incremented. This would prevent any other client from simultaneously modifying any attributes or properties anywhere inside the same Product. Depending on the given Aggregate design, this may be difficult to manage, and even unnecessary.

> 接下来，我们需要考虑在何处放置乐观并发的版本号。在我们定义聚合时，最安全的方法便是只为根实体创建版本号。每次在聚合内部执行状态修改命令时，根实体的版本号都会随之增加。对于前面的例子来说，Product 将拥有一个 version 属性，当执行 describeAs（）、initiateDiscussion（）、rename（）或者 reorderFrom（）方法时，version 属性都会增加。这样可以避免多个客户在同一个 Product 内部同时修改属性状态。根据聚合的设计方式，有时这是很难控制的，甚至是没有必要的。

Assuming we are using Hibernate, when the Product name or description is modified, or its productDiscussion is attached, the version is automatically incremented. That’s a given, because those elements are directly held by the Root Entity. However, how do we see to it that the Product version is incremented when any of its backlogItems are reordered? Actually, we can’t, or at least not automatically. Hibernate will not consider a modification to a ProductBacklogItem part instance as a modification to the Product itself. To solve this, perhaps we could just change the Product method reorderFrom(), dirtying some flag or just incrementing the version on our own:

> 假设我们使用了 Hibernate，当 Product 的 name、description 或者 productDiscussion 属性被修改时，version 将自动增加。这是很自然的，因为这些属性是根实体所直接持有的。然而，如果我们修改了 backlogItems 中任何一个元素的顺序，此时的 version 应该增加吗？事实上，这是不可以的，或者至少不能自动地增加 version 值。Hibernate 并不会将对 ProductBacklogItem 的修改看作是对 Product 的修改。要解决这个问题，我们可以修改 Product 的 reorderFrom（）方法，手动地增加 version 的值：

```java
public class Product extends ConcurrencySafeEntity  {
    ...
    public void reorderFrom(BacklogItemId anId, int anOrdering) {
        for (ProductBacklogItem pbi : this.backlogItems()) {
            pbi.reorderFrom(anId, anOrdering);
        }
        this.version(this.version() + 1);
    }
    ...
}
```

One problem is that this code always dirties the Product, even when a reordering command actually has no effect. Further, this code leaks infrastructural concerns into the model, which is a less desirable domain modeling choice if it can be avoided. What else can be done?

> 以上实现的一个问题在于：无论 reorderFrom（）方法是否产生了修改状态的效果，version 的值总是会增加的。此外，这种方式使基础设施泄漏到了模型中，这并不是领域建模的一个好做法。那么，我们还可以做些什么呢？

Cowboy Logic 牛仔的逻辑

AJ: “I’m thinkin’ that marriage is a sort of optimistic concurrency. When a man gets married, he is optimistic that the gal will never change. And at the same time, she’s optimistic that he will.”

> AJ：“我在想，婚姻就像乐观并发一样。当一个男人结婚时，他很乐观地认为女方不会改变；而当一个女人结婚时，她很乐观地认为男人一定会改变。”

Image

Actually in the case of the Product and its ProductBacklogItem instances, it’s possible that we don’t need to modify the Root’s version when any backlogItems are modified. Since the collected instances are themselves Entities, they can carry their own optimistic concurrency version. If two clients reorder any of the same ProductBacklogItem instances, the last client to commit changes will fail. Admittedly, overlapping reordering would rarely if ever happen, because it’s usually only the product owner who reorders the product backlog items.

> 事实上，对于上面的 Product 和 ProductBacklogItem 来说，当修改 backlogItems 时，我们没有必要修改根实体 Product 的版本号。由于 ProductBacklogItem 自身也是实体，它们可以维护自己的 version 属性。如果 2 个客户同时修改同一个 ProductBacklogItem 的顺序，那么后一个提交的客户将失败。实际上，这种情况几乎不会发生，因为只有产品负责人才会对待定项重新排序。

Versioning all Entity parts doesn’t work in every case. Sometimes the only way to protect an invariant is to modify the Root version. This can be accomplished more easily if we can modify a legitimate property on the Root. In this case, the Root’s property would always be modified in response to a deeper part modification, which in turn causes Hibernate to increment the Root’s version. Recall that this approach was described previously to model the status change on BacklogItem when all of its Task instances have been transitioned to zero hours remaining.

> 为每个实体创建版本号并不对所有的场景都适用。有时，唯一可以保护不变条件的做法便是直接修改根实体的版本号。当然，在可能的情况下，更简单的方法是修改根实体上的属性。在这种情况下，当我们对根实体进行深度修改时，直接位于根实体之下的某些属性也总能得到修改，进而使得 Hibernate 增加根实体的 version 值。回想一下，在先前的 BacklogItem 和 Task 的例子中，我们已经采用了这种方法，即当所有 Task 的剩余时间变成零时，BacklogItem 的 status 属性也将随之改变。

However, that approach may not be possible in all cases. If not, we may be tempted to resort to using hooks provided by the persistence mechanism to manually dirty the Root when Hibernate indicates a part has been modified. This becomes problematic. It can usually be made to work only by maintaining bidirectional associations between child parts and the parent Root. The bidirectional associations allow navigation from a child back to the Root when Hibernate sends a life cycle event to a specialized listener. Not to be forgotten, though, is that [Evans] generally discourages bidirectional associations in most cases. This is especially so if they must be maintained only to deal with optimistic concurrency, which is an infrastructural concern.

> 然而，这种方式也不是对所有场景都适用。在不适用的场景下，我们可能会求助于持久化机制，比如，当 Hibernate 发现聚合的有些部分被修改时，我们可以使用钩子（Hook）手动地修改根实体。但是，这样做也是有问题的。此时，我们需要在根实体和它所包含的子对象中维持双向关联。当 Hibernate 将对象生命周期事件发送到某个监听器时，该双向关联使得从子对象中去引用根实体。请不要忘记了，正如[Evans]所说，在多数情况下，使用双向关联都是不被鼓励的。而如果这样做只是为了支持乐观并发，那么就更不应该了，因为乐观并发只是一个基础设施层面上的关注点。

Although we don’t want infrastructural concerns to drive modeling decisions, we may be motivated to travel a less painful route. When modifying the Root becomes very difficult and costly, it could be a strong indication that we need to break down our Aggregates to just a Root Entity, containing only simple attributes and Value-typed properties. When our Aggregates consist of only a Root Entity, the Root is always modified when any part is modified.

> 虽然我们并不希望由基础设施相关的因素来影响我们的建模决定，我们依然可以选择一种没那么痛苦的做法。当对根实体的修改变得非常困难并且成本很高时，通常这意味着我们需要对根实体进行拆分了。此时，根实体应该只包含一些简单属性和值对象属性。当聚合只由一个根实体组成时，无论聚合的那部分发生了改变，根实体都能得到修改。

Finally, it must be acknowledged that the preceding scenarios are not a problem when an entire Aggregate is persisted as one value and the value itself prevents concurrency conflict. This approach can be leveraged when using MongoDB, Riak, Oracle’s Coherence distributed grid, or VMware’s GemFire. For example, when an Aggregate Root implements the Coherence Versionable interface and its Repository uses the VersionedPut entry processor, the Root will always be the single object used for concurrency conflict detection. Other key-value stores may provide similar conveniences.

> 最后，我们应该知道的是，如果整个聚合是通过单个值进行持久化的，并且该值本身可以避免并发冲突，那么前面的场景便不是问题了。在使用 MongoDB、Riak、Oracle 的 Coherence 分布式网格和 VMware 的 GemFire 时，我们便可以采用这种方式。比如，当一个聚合根实现了 Coherence 的 Versionable 接口，同时它的资源库采用了 VersionedPut 处理器，那么在进行并发冲突检测时，Coherence 总会并且只会使用该聚合根。

### 10.8.5 Avoid Dependency Injection 避免依赖注入

Dependency injection of a Repository or Domain Service into an Aggregate should generally be viewed as harmful. The motivation may be to look up a dependent object instance from inside the Aggregate. The dependent object could be another Aggregate, or a number of them. As stated earlier under “Rule: Reference Other Aggregates by Identity,” preferably dependent objects are looked up before an Aggregate command method is invoked, and passed in to it. The use of Disconnected Domain Model is generally a less favorable approach.

> 通常来说，向聚合中注入资源库或者领域服务是有害的。这样做的原因可能是希望在聚合内部查找一个所依赖对象的实例，所依赖的对象可能是另一个聚合，也有可能是一系列的聚合。在前面的“原则：通过唯一标识引用其他聚合”一节中我们已经讲到，对于所依赖的对象，我们应该在聚合命令方法执行之前进行查找，然后再将其传入命令方法。使用失联领域模型并不是一种值得推荐的方法。

Additionally, in a very high-traffic, high-volume, high-performance domain, with heavily taxed memory and garbage collection cycles, think of the potential overhead of injecting Repositories and Domain Service instances into Aggregates. How many extra object references would that require? Some may contend that it’s not enough to tax their operational environment, but theirs is probably not the kind of domain being described here. Still, take great care not to add unnecessary overhead that could be easily avoided by using other design principles, such as looking up dependencies before an Aggregate command method is invoked, and passing them in to it.

> 此外，在一个高吞吐量、高性能的领域中，内存吃紧，垃圾回收周期漫长，此时如果我们再将资源库和领域服务注入到聚合中，结果会怎么样？将会有多少额外的对象引用产生？有人可能会说，这并不足以对他们的运行环境造成影响，但是他们的运行环境可能并不是我们这里所描述的情形。无论如何，如果可以采用其他设计原则予以避免，那么我们就不应该给系统增加不必要的负担。比如，我们可以在调用聚合命令方法之前查找到所依赖的对象。

This is only meant to warn against injecting Repositories and Domain Services into Aggregate instances. Of course, dependency injection is quite suitable for many other design situations. For example, it could be quite useful to inject Repository and Domain Service references into Application Services.

> 当然，以上只是告诫大家不要在聚合中注入资源库和领域服务，而在其他多数情况下，依赖注入都是很适合的。比如，我们可以向应用服务中注入资源库和领域服务。

## 10.9 WRAP-UP 本章小结

We’ve examined how crucial it is to follow the Aggregate Rules of Thumb when designing Aggregates.

> 在本章中，你学到了遵循聚合设计原则的重要性。

- You experienced the negative consequences of modeling large-cluster Aggregates.
- You learned to model true invariants in consistency boundaries.
- You considered the advantages of designing small Aggregates.
- You now know why you should favor referencing other Aggregates by identity.
- You discovered the importance of using eventual consistency outside the Aggregate boundary.
- You saw various implementation techniques, including how you might use Tell, Don’t Ask and Law of Demeter.

---

> - 你学到了大聚合的负面影响。
> - 你学到了如何在一致性边界之内建模真正的不变条件。
> - 你学到了设计小聚合的优势。
> - 你学到了应该优先考虑通过标识引用其他聚合。
> - 你学到了在聚合边界之外使用最终一致性的重要性。
> - 你学到了不同的实现方法，包括如何使用“告诉而非询问”原则和迪米特法则。

If we adhere to the rules, we’ll have consistency where necessary and support optimally performing and highly scalable systems, all while capturing the Ubiquitous Language of our business domain in a carefully crafted model.

> 如果我们遵循聚合的设计原则，那么我们便可以获得很好的一致性，并且创建出高性能和高伸缩性的系统，同时还可以捕获到业务领域中的通用语言。
