---
title: 第 8 章 领域事件
date: 2021-01-07 16:25:13
permalink: /pages/678798/
categories:
  - 技术
  - 技术文档
  - 实现领域驱动设计
tags:
  - 
---
# 第 8 章 领域事件

History is the version of past events that people have decided to agree upon.

> 历史就是人们认同的过去所发生的事件。

——Napoleon Bonaparte

Use a Domain Event to capture an occurrence of something that happened in the domain. This is an extremely powerful modeling tool. Once you get the hang of using Domain Events, you will be addicted and wonder how you survived without them until now. To get started with them, all you have to do is find agreement on what your Events actually are.

> 使用领域事件（Domain Event）来捕获发生在领域中的一些事情。领域事件是一个功能强大的建模工具，一旦你使用了它，你便无法释手了。在一开始使用领域事件时，你要做的是对不同的事件进行定义。

Road Map to This Chapter

- Discover what Domain Events are, and when and why you should consider using them.
- Learn how Events are modeled as objects, and when they must be uniquely identified.
- Examine a lightweight Publish-Subscribe [Gamma et al.] pattern and how it fits with notifying clients.
- See which components publish Events and which ones are the subscribers.
- Consider why you’d want to develop an Event Store, how it can be done, and how one is used.
- Learn from SaaSOvation how Events are published to autonomous systems in different ways.

---

> - 学习什么是领域事件，什么时候并且为什么要使用领域事件。
> - 学习如何将领域事件建模成对象，何时应该为领域事件创建唯一的身份标识。
> - 学习一个轻量级的发布-订阅[Gamma et al.]模式。
> - 学习哪些组件用于发布事件，哪些组件用于订阅事件。
> - 学习为什么我们需要一个事件存储、如何实现事件存储、如何使用事件存储。
> - 学习 SaaSOvation 团队是如何通过不同的方式将领域事件发布给自治系统的。

## 8.1 THE WHEN AND WHY OF DOMAIN EVENTS 何时/为什么使用领域事件

Referencing [Evans], you will find no formal definition for Domain Events. The pattern was introduced in detail sometime after the book was published. To begin a discussion about implementing Events in the Domain (2), consider the contemporary definition:

> [Evans]书中并没有给出领域事件的正式定义。这种模式是在该书出版之后才提出来的。在讨论领域事件之前，让我们先来看看当前对领域事件的定义：

Something happened that domain experts care about.

> 领域专家所关心的发生在领域中的一些事件。

Model information about activity in the domain as a series of discrete events. Represent each event as a domain object. . . . A domain event is a full-fledged part of the domain model, a representation of something that happened in the domain. [Evans, Ref, p. 20]

> 将领域中所发生的活动建模成一系列的离散事件。每个事件都用领域对象来表示……领域事件是领域模型的组成部分，表示领域中所发生的事情。[Evans，Ref，p.20]

How can we determine if something that happens in the domain is important to the domain experts? As we have discussions with them, we must listen carefully for clues. Consider a few key phrases to listen for when domain experts talk:

> 我们如何确定哪些事件对领域专家是重要的呢？在我们与领域专家讨论时，我们需要仔细地听，找到领域事件的线索。考虑以下领域专家所说的关键词汇：

- “When . . .”
- “If that happens . . .”
- “Inform me if . . .” and “Notify me if . . .”
- “An occurrence of . . .”

---

> - “当……”
> - “如果发生……”
> - “当……的时候，请通知我”
> - “发生……时”

Of course, with the “Inform me if . . .” and “Notify me if . . .” expressions it’s not the notification that constitutes an Event. It’s just a statement of the fact that someone in the domain wants to be notified as a result of an important occurrence, and that likely means the need to model an explicit Event. In addition, domain experts might say things such as “If that happens, it isn’t important, but if this happens, it is important.” (Replace that and this with something meaningful in your domain.) Depending on your organizational culture, there could be other triggering phrases.

> 当然，对于“当……的时候，请通知我”，这里的通知本身并不能构成一个事件，而只是表明我们需要向外界发出通知。另外，领域专家可能还会说“如果发生这样的事情，它并不重要；如果发生那样的事情，它就很重要了（将“这样”和“那样”用你自己领域中的事件予以替换）。”根据你的组织文化，可能还有更多的事件用语。

Cowboy Logic 牛仔的逻辑

AJ: “In the event that I want my horse, I just yell, ‘Here, Trigger!’ and he comes runnin’. Of course, it never hurts to let him know I’m carryin’ a cube of sugar.”

> AJ：“当我需要我的马时，我只是吆喝：‘过来过来！’，然后马就跑过来了。

Image

There will probably be times when the spoken language of the experts doesn’t lead to a clear reason to model an Event, yet the business situation may still call for it. Domain experts may or may not be aware of these kinds of requirements, and they could become known only as a result of cross-team discussions. This tends to happen when Events must be broadcast to external services, where the systems in your enterprise have been decoupled and occurrences throughout the domain must be communicated across Bounded Contexts (2). Events like this get published, and subscribers are notified. As such Events are handled by subscribers, they may have far-reaching impact on local and remote Bounded Contexts.

> 有时，从领域专家的话中，我们看不出领域事件的迹象，但是业务需求依然有可能需要领域事件。领域专家有可能意识不到这些需求，只有在跨团队讨论之后他们才能意识到这些。发生这样的事情往往是由于领域事件需要发布到外部系统中，比如发布到另一个限界上下文中（2）。由于这样的事件由订阅方处理，它将对本地和远程上下文产生深远的影响。

Domain Experts and Events 领域专家和领域事件

Although domain experts may not initially be aware of the need for every kind of Event, they should understand the reasons for them as they are included in discussions about specific Events. Once there is clear consensus, new Events become a formal part of the Ubiquitous Language (1).

> 虽然领域专家在起初可能意识不到所有类型的领域事件，但是通过讨论之后，他们是应该能够了解到其中的原因的。当团队成员对领域事件达成一致之后，领域事件便是通用语言的正式组成部分了。

When Events are delivered to interested parties, in either local or foreign systems, they are generally used to facilitate eventual consistency. This is purposeful and by design. It can eliminate the need for two-phase commits (global transactions) and support of the rules of Aggregates (10). One rule of Aggregates states that only a single instance should be modified in a single transaction, and all other dependent changes must occur in separate transactions. So other Aggregate instances in the local Bounded Context may be synchronized using this approach. We also bring remote dependencies into a consistent state with latency. The decoupling helps provide a highly scalable and peak-performing set of cooperating services. It also allows us to achieve loose coupling between systems.

> 当领域事件到达目的地之后——无论是本地系统还是外部系统——我们通常都将领域事件用于维护事件的一致性。这是有意而为之的，并且是根据设计而来的。这样可以消除两阶段提交（全局事务），还可以支持聚合（10）原则。聚合的其中一个原则是，在单个事务中，只允许对一个聚合实例进行修改，由此产生的其他改变必须在单独的事务中完成。因此，本地限界上下文中的其他聚合实例便可以通过领域事件的方式予以同步。另外，领域事件还可以用于使远程依赖系统与本地系统保持一致。本地系统和远程系统的解耦有助于提高双方协作服务的可伸缩性。

Figure 8.1 shows how Events may originate, how they can be stored and forwarded, and where they may be used. Events may be consumed by the local, and foreign, Bounded Contexts.

> 图 8.1 向我们展示了领域事件的产生、存储、分发和使用。领域事件既可以由本地限界上下文所消费，也可以由外部的限界上下文消费。

Image

Figure 8.1. Aggregates create Events and publish them. Subscribers may store Events and then forward them to remote subscribers, or just forward them without storing. Immediate forwarding requires XA (two-phase commit) unless messaging middleware shares the model’s data store.

> 图 8.1 　聚合创建并发布事件。订阅方可以先存储事件，然后再将其转发到远程的订阅方中；或者不经存储，直接转发。除非消息中间件共享了模型的数据存储，不然即时转发需要 XA（两阶段提交）。

Also, think of times when your systems normally perform batch processing. Perhaps during off-peak hours (possibly nighttime) your systems process daily maintenance of some kind, deleting obsolete objects, creating ones that are needed to support newly formed business situations, bringing some objects into agreement with others, and even notifying certain users that important things have happened. Often performing such batch processes requires you to execute some complex queries in order to determine the business situations that require attention. The calculations and procedures to address them are costly, and synchronizing all the changes requires large transactions. What if those pesky batch processes could be made redundant?

> 现在，让我们来考虑一下系统中的批处理过程。在系统的非高峰时期，批处理过程通常进行一些系统维护工作，比如删除过期的对象、创建新的对象以支持新的业务需求、或者通知用户所发生的重要事件等。这样的批处理过程通常需要复杂的查询，并且需要庞大的事务支持。如果这些批处理过程存在冗余又会怎么样呢？

Now think of the actual occurrences that took place throughout the previous day that led to the need to play catch-up later. If each of those discrete occurrences were captured by a single Event, and published to listeners in your own system, would that simplify things? Indeed, it would eliminate the complex queries because you would know exactly what occurred and when, providing the context of what needs to happen as a result. You would just do it as you receive notification of each Event. The processing currently dealt with in I/O and processor-intensive batches would be spread out into short spurts throughout the day, and your business situations would be in harmony much more quickly, ready for users to take the next steps.

> 那么，让我们重新思考一下。对于系统中发生的每一件事情，我们都用事件的形式予以捕获，然后将事件发布给订阅方处理，这能达到简化系统的目的吗？答案是肯定的。它可以消除先前批处理过程中的复杂查询，因为我们能够准确地知道在何时发生了什么事情，限界上下文也由此知道“接下来应该做什么”。在接收到领域事件时，系统可以予以立即处理。这样一来，原本批量集中处理的过程可以分散成许多粒度较小的处理单元，业务需求也由此得到更快地满足，用户也可以及时地进行下一步操作。

Does every Aggregate command result in an Event? Just as important as recognizing the need for an Event is knowing when to disregard extraneous happenings in the domain that experts or the business as a whole don’t care about. Still, depending on the technical implementation aspects of the model or the goals of collaborating systems, it is possible that Events will be more prolific than domain experts directly require. Such is the case when using Event Sourcing (4, Appendix A).

> 聚合上的每一个命令方法都会产生事件吗？与何时需要使用领域事件同等重要的是，我们需要知道何时不应该使用领域事件。出于技术实现和协作系统上的考虑，有时领域事件可以提供比领域专家所要求的更多的功能，比如可以用于事件源（4，附录 A）。

I leave some of this to Integrating Bounded Contexts (13), but we’ll consider the essential modeling tools here.

> 我们将在集成限界上下文（13）中对此进行探讨，这里我们只讨论领域事件的核心方面。

## 8.2 MODELING EVENTS 建模领域事件

Let’s take a requirement from the Agile Project Management Context. The domain experts indicated the need for an Event in this way (italics added for emphasis):

> 让我们看看敏捷项目管理上下文中的一条需求：

Image

Allow each backlog item to be committed to a sprint. It may be committed only if it is already scheduled for release. If it is already committed to a different sprint, it must be uncommitted first. When the backlog item is committed, notify the sprint and other interested parties.

> 允许将每一个待定项提交到冲刺中。只有在待定项位于发布计划中时，才能进行提交。如果待定项已经提交到了另外的冲刺中，必须先将其回收才能进行新的提交。提交待定项时，通知对应的冲刺和相关兴趣方。

When modeling Events, name them and their properties according to the Ubiquitous Language in the Bounded Context where they originate. If an Event is the result of executing a command operation on an Aggregate, the name is usually derived from the command that was executed. The command is the cause of the Event, and hence the Event’s name is rightly stated in terms of the command having occurred in the past. Per the example scenario, when we commit a backlog item to a sprint, we publish an Event that explicitly models what happened in the domain:

> 在建模领域事件时，我们应该根据限界上下文中的通用语言来命名事件及其属性。如果事件由聚合上的命令操作产生，那么我们通常根据该操作方法的名字来命名领域事件。对于上面的例子，当我们向一个冲刺提交待定项时，我们将发布与之对应的领域事件：

Command operation: BacklogItem#commitTo(Sprint aSprint)

> 命令方法：BacklogItem#commitTo（Sprint aSprint）

Event outcome: BacklogItemCommitted

> 事件输出：BacklogItemCommitted

The Event name states what occurred (past tense) in the Aggregate after the requested operation succeeded: “The backlog item was committed.” The team could have modeled the name a bit more verbosely, such as BacklogItemCommittedToSprint, and that would work. However, in the Ubiquitous Language of Scrum, a backlog item is never committed to anything besides a sprint. In other words, backlog items are scheduled for release, not committed to a release. There would be no doubt that this Event was published as a result of using the commitTo() operation. Thus, the Event is sufficiently named as it is, and the more compact name is easier to read. If your team likes a more verbose name in a specific case, however, use it.

> 事件的名字表明了聚合上的命令方法在执行成功之后所发生的事情：“待定项提交完毕。”当然，我们还可以创建更详细的事件名字，比如 BacklogItemCommittedToSprint。但是，在 Scrum 的通用语言中，待定项只能提交到冲刺中。换句话说，待定项是不能提交到发布中的。因此，使用原先的 BacklogItemCommitted 已经足够了，并且更加简捷。如果你倾向于使用更详细的事件命名，也是可以的，这只是一个选择问题。

When publishing Events from Aggregates, it is important that the Event name reflect the past nature of the occurrence. It is not occurring now. It occurred previously. The best name to choose is the one that reflects that fact.

> 在聚合发布事件时，请注意我们应该使事件的名字反映过去发生的事情，即该事件并不是当前发生的，而是先前发生的。

After the right name is found, what properties should it have? For one, we need a timestamp that indicates when the Event occurred. In Java we could represent it as a java.util.Date:

> 在有了正确的事件名后，我们还需要什么样的事件属性呢？首先，我们需要一个时间戳来表示事件发生的时间。在 Java 中，可以使用 java.util.Date 类来表示。

```java
package com.saasovation.agilepm.domain.model.product;

public class BacklogItemCommitted implements DomainEvent {
    private Date occurredOn;
    ...
}
```

The minimal interface DomainEvent, implemented by all Events, ensures support of an occurredOn() accessor. It enforces a basic contract for all Events:

> 所有的领域事件都将实现 DomainEvent 接口，该接口定义了一个 occurredOn（）方法：

```java
package com.saasovation.agilepm.domain.model;

import java.util.Date;

public interface DomainEvent {
    public Date occurredOn();
}
```

Besides this, the team determines what other properties are necessary to represent a meaningful occurrence of what happened. Consider including whatever would be necessary to trigger the Event again. This normally includes the identity of the Aggregate instance on which it took place, or any Aggregate instances involved. Using this guidance, we might create properties of any parameters that caused the Event, if discussion proves they are useful. It’s also possible that some resulting Aggregate state transition values could be helpful to subscribers.

> 接下来，团队成员还需要考虑其他有意义的属性。考虑一下，是谁导致了领域事件的产生。这通常包括产生该领域事件的聚合和其他参与操作的聚合，也有可能是其他任何类型的数据属性。

Here’s what analysis of BacklogItemCommitted led to:

> 分析之后，我们可以得到以下 BacklogItemCommitted 事件：

```java
package com.saasovation.agilepm.domain.model.product;

public class BacklogItemCommitted implements DomainEvent {
    private Date occurredOn;
    private BacklogItemId backlogItemId;
    private SprintId committedToSprintId;
    private TenantId tenantId;
    ...
}
```

The team decided that the identity of the BacklogItem and that of the Sprint were essential. It was the BacklogItem that the Event occurred on, and the Sprint that it occurred with. But more was involved in this decision. The requirement that drove out the need for this Event indicated specifically that the Sprint must be notified that a certain BacklogItem was committed to it. Thus, an Event subscriber in the same Bounded Context must eventually inform the Sprint, and it can do so only if BacklogItemCommitted has the SprintId.

> 团队成员认为，BacklogItem 和 Sprint 的身份标识对于 BacklogItemCommitted 事件来说是最关键的。BacklogItem 是事件的发起方，而 Sprint 则是事件的参与方。当然，他们还讨论了更多的话题。该需求特别指出，当 BacklogItem 被提交到 Sprint 之后，该 Sprint 应该得到通知。因此，位于同一个限界上下文中的事件订阅方应该及时地通知 Sprint，但前提条件是 BacklogItemCommitted 事件中存在 SprintId。

Image

Additionally, in the multitenancy environment, recording the TenantId is always necessary, even though it was not passed as a command parameter. It is needed for both the local and foreign Bounded Contexts. Locally the team would need the TenantId to query the BacklogItem and the Sprint from their respective Repositories (12). Likewise, any foreign, remote systems that listen for a broadcast of this Event would need to know which TenantId it applies to.

> 此外，在一个多租户环境中，记录 TenantId 也是有必要的，虽然 TenantId 不会作为参数传给命令方法，但是它却是本地和远程限界上下文所必需的。在本地上下文中，我们需要 TenantId 来查询 BacklogItem 和 Sprint。同样，在远程上下文中，我们需要 TenantId 来查出领域事件的作用对象。

How do we model the behavioral operations supplied by Events? These are generally very simple because an Event is usually designed as immutable. First and foremost, the Event’s interface has the express purpose to convey the properties that reflect its cause. Most Events will have a constructor that permits only full state initialization, along with a complement of read accessors for each of its properties.

> 我们如何建模由事件提供的行为操作呢？通常来说，这是非常简单的，因为领域事件通常都被设计成不变的。事件所携带的属性能够反映出该事件的来源。多数事件的构造函数都只允许全状态初始化，同时，事件对象还提供了访问不同属性的 getter 方法。

Based on that, here’s what the ProjectOvation team did:

> 基于此，ProjectOvation 团队做了以下实现：

```java
package com.saasovation.agilepm.domain.model.product;

public class BacklogItemCommitted implements DomainEvent {
    ...
    public BacklogItemCommitted(
            TenantId aTenantId,
            BacklogItemId aBacklogItemId,
            SprintId aCommittedToSprintId) {
        super();
        this.setOccurredOn(new Date());
        this.setBacklogItemId(aBacklogItemId);
        this.setCommittedToSprintId(aCommittedToSprintId);
        this.setTenantId(aTenantId);
    }

    @Override
    public Date occurredOn() {
        return this.occurredOn;
    }

    public BacklogItemId backlogItemId() {
        return this.backlogItemId;
    }

    public SprintId committedToSprintId() {
        return this.committedToSprintId;
    }

    public TenantId tenantId() {
        return this.tenant;
    }
    ...
}
```

With this Event published, a subscriber in the local Bounded Context can use it to notify the Sprint that a certain BacklogItem was recently committed to it:

> 在该事件发布时，本地上下文的订阅方可以用该事件来通知相应的 Sprint：

```java
MessageConsumer.instance(messageSource, false)
    .receiveOnly(
            new String[] { "BacklogItemCommitted" },
            new MessageListener(Type.TEXT) {
        @Override
        public void handleMessage(
            String aType,
            String aMessageId,
            Date aTimestamp,
            String aTextMessage,
            long aDeliveryTag,
            boolean isRedelivery)
        throws Exception {
            // first de-duplicate message by aMessageId
            ...
            // get tenantId, sprintId, and backlogItemId from JSON
            ...

            Sprint sprint =
                    sprintRepository.sprintOfId(tenantId, sprintId);
            BacklogItem backlogItem =
                    backlogItemRepository.backlogItemOfId(
                        tenantId,
                        backlogItemId);
            sprint.commit(backlogItem);
        }
    });
```

Per the system requirements, after handling the specific "BacklogItemCommitted" message, the Sprint is consistent with the BacklogItem that was recently committed to it. How the subscriber receives this Event is discussed later in this chapter.

> 根据系统需求，在处理了 BacklogItemCommitted 消息之后，Sprint 与刚才所提交的 BacklogItem 达到了最终一致性。我们将在本章后续内容中讨论订阅方是如何接收领域事件的。

Image

The team realized that there might be a bit of a problem here. How is the Sprint updating transaction managed? We could have the message handler do that, but either way the code found in the handler needs some refactoring. It would be best for it to delegate to an Application Service (14) to harmonize with the Hexagonal Architecture (4). Doing so would allow the Application Service to manage the transaction, which is a natural application concern. In that case the handler would now look like this:

> 团队成员意识到，这种方式还存在一个小问题。Sprint 如何处理更新事务呢？我们可以让消息处理器来处理事务。但是，无论如何我们都需要相应地重构代码。最好的方式是将事务处理委派给应用服务（14），这是一种很自然的选择，同时这种方式能够很好地融入六边形架构（4）中。如此一来，代码将变成：

```java
MessageConsumer.instance(messageSource, false)
    .receiveOnly(
            new String[] { "BacklogItemCommitted" },
            new MessageListener(Type.TEXT) {
        @Override
        public void handleMessage(
            String aType,
            String aMessageId,
            Date aTimestamp,
            String aTextMessage,
            long aDeliveryTag,
            boolean isRedelivery)
        throws Exception {
            // get tenantId, sprintId, and backlogItemId from JSON
            String tenantId = ...
            String sprintId = ...
            String  backlogItemId = ...

            ApplicationServiceRegistry
                    .sprintService()
                    .commitBacklogItem(
                            tenantId, sprintId, backlogItemId);
        }
    });
```

In this example Event de-duplication is unnecessary because committing a BacklogItem to a Sprint is an idempotent operation. If the specific BacklogItem is already committed to the Sprint, the current request to commit it again is ignored.

> 在上面的例子中，我们没有必要消除对事件的重复提交，因为向 Sprint 提交 BacklogItem 是一个幂等操作。如果某个 BacklogItem 已经提交给了 Sprint，当再次提交时，Sprint 将予以忽略。

It may be necessary to provide additional state and behavior if subscribers require more than the indication of the Event’s cause. This could be conveyed by enriched state (more properties) or operations that derive richer state. Subscribers thus avoid querying back on the Aggregate from which the Event was published, which could be needlessly difficult or expensive. Event enrichment may be more common when using Event Sourcing because an Event used for persistence may need additional state when also published out of the Bounded Context. Examples of Event enrichment are provided in Appendix A.

> 除了事件的来源信息，如果订阅方还需要进行更多的操作，那么我们可以向事件中添加额外的状态和行为。这样，订阅方便不用回头再对聚合进行查询，而只需要对所接收到的事件进行查询即可。富有行为和状态的领域事件在事件源中更加常见，因为那些需要持久化并进而发布到外部限界上下文的领域事件需要更多的额外状态，请参考附录 A。

Whiteboard Time 白板时间

- List the kinds of Events that already occur in your domain but that aren’t being captured.
- Make note of how making them an explicit part of your model would improve your design.

---

> - 列出你领域中已经存在但是还未被捕获的领域事件
> - 想想如何将这些事件显现在自己的领域模型中。

It might be easiest to identify Aggregates that have dependencies on the state of other Aggregates, where eventual consistency is necessary.

> 最容易识别出的便是当一个聚合依赖于另外一个聚合的时候，此时我们需要保证它们之间的最终一致性。

To derive richer state using operations, make sure that any additional Event behaviors are Side-Effect Free, as discussed in Value Objects (6), protecting the object’s immutability.

> 正如在值对象（6）中所讨论的，我们需要确保这些额外的事件行为是无副作用的，这样可以保证对象的不变性。

### 8.2.1 With Aggregate Characteristics 创建具有聚合特征的领域事件

Sometimes Events are designed to be created by direct request from clients. This is done in response to some occurrence that is not the direct result of executing behavior on an instance of an Aggregate in the model. Possibly a user of the system initiates some action that is considered an Event in its own right. When that happens, the Event can be modeled as an Aggregate and retained in its own Repository. Since it represents some past occurrence, its Repository would not permit its removal.

> 有时，领域事件并不由聚合中的命令方法产生，而是直接由客户方所发出的请求产生。此时，领域事件可以建模成一个聚合，并且可以拥有自己的资源库。但是，又由于领域事件表示的是发生在过去的事情，因此资源库是不能对事件进行删除的。

When Events are modeled in this way, like Aggregates they become part of the model’s structure. Thus, they are not just a record of some past occurrence, although they are that also.

> 和聚合一样，由这种方式所创建的事件应该成为模型结构的一部分。因此，它们不再仅仅表示过去发生的事情。

The Event is still designed as immutable, but it may be assigned a generated unique identity. It is possible, however, that the identity can be supported by a number of the Event’s properties. Even if unique identity could be determined by a set of properties, it may be best to assign a generated unique identity as discussed in Entities (5). This would allow the Event to undergo various design changes over time without risking its uniqueness among all others.

> 此时的领域事件依然应该设计成不变的，但是它们将拥有唯一标识。对于领域事件而言，我们可以使用事件属性来表示唯一标识。然而，即便事件的唯一标识可以由一组属性来决定，最好的方式还是采用生成的唯一标识，请参考实体（5）。这样，如果设计有变化，我们依然可以保证事件的唯一性。

When an Event is modeled in this fashion, it can be published via messaging infrastructure at the same time as it is added to its Repository. The client could call on a Domain Service (7) to create the Event, add it to its Repository, and then publish it over a messaging infrastructure. With this approach, both the Repository and the messaging infrastructure must be backed by the same persistence instance (data source), or a global transaction (aka XA and two-phase commit) would be necessary to guarantee that both commit successfully.

> 由这种方式所创建的事件可以通过消息设施进行分发，同时又可以将其添加到资源库中。客户方可以通过调用领域服务（7）来创建事件，然后将其添加到资源库中，再通过消息设施进行发布。在这种情况下，资源库和消息设施必须使用相同的持久化实例（数据源），或者使用全局事务（即 XA 和两阶段提交），以此来保证对事件的成功提交。

After the messaging infrastructure successfully saves the new Event message to its persistence store, it would then asynchronously send it on to any queue listener, topic/exchange subscribers, or actor if using the Actor Model.1 If the messaging infrastructure uses a persistence store that is separate from that used by the model, and if it does not support global transactions, your Domain Service would have to see that it is first saved in the Event Store, which in this case would also act as a queue for out-of-band publishing. Each Event in the Store would be processed by a forwarding component that would send it out over the messaging infrastructure. This technique is discussed in detail later in this chapter.

> 在消息设施成功存储事件之后，它将异步地将事件发送给消息队列监听器、话题订阅方或者 Actor Model[1]中的 Actor 等。如果消息设施所使用的存储和模型所使用的存储是分离的，并且消息设施不支持全局事务，那么在调用领域服务时，事件必须已经存在于消息存储中。消息转发组件将对消息存储中的每一个事件进行处理，然后通过消息设施将事件发布出去。对此，我们将在本章后续内容做详细讨论。

1. See Erlang’s and Scala’s Actor Model of concurrency. In particular, Akka is worth considering if using Scala or Java.

### 8.2.2 Identity 身份标识

Let’s clarify the reasons for assigning unique identity. At times it may be necessary to distinguish Events one from another, but the need may be rare. In the Bounded Context where the Event is caused, created, and published, there will tend to be little reason to compare one Event to another, if ever. But what if, for some reason, Events must be compared? And what if an Event is designed as an Aggregate?

> 这里，我们再讨论一下领域事件为什么需要唯一标识。有时，我们需要对不同的事件进行区分。在创建、发布事件的限界上下文中，我们几乎没有理由对不同事件进行比较。但是，如果我们的确需要对不同的事件进行比较，我们应该怎么办呢？再者，如果此时的事件被设计成了聚合，我们又该怎么办呢？

It may be enough to allow Event identity to be represented by its properties, as is the case with Value Objects. The Event’s name/type along with the identities of the Aggregate(s) involved in the cause, as well as a timestamp of when the Event occurred, may be enough to distinguish it from others.

> 对于领域事件来说，使用属性来表示唯一标识似乎已经足够了，就像值对象一样。使用事件的名字、产生事件的聚合标识和事件时间戳已经足以对不同的事件进行区分了。

In cases where an Event is modeled as an Aggregate, or in other cases when Events must be compared and their combined properties do not distinguish them, we may assign an Event a formal unique identity. But there may be other reasons to assign unique identity.

> 当领域事件被建模成了聚合；或者我们需要对不同的事件进行比较，但是事件的属性又不足以区分事件时，我们便需要为事件创建唯一标识。当然，还有其他的原因。

Unique identity may be necessary when Events are published outside the local Bounded Context where they occur, when messaging infrastructure forwards them along. In some situations individual messages can be delivered more than once. This would happen if the message sender crashes before the messaging infrastructure confirms that the message was sent.

> 当我们需要将领域事件发布到外部限界上下文中时，为事件创建唯一标识也是有必要的。在有些情况下，单条消息可能会被多次分发，比如，在消息设施确定消息发出之前，消息发布器便瘫痪了。

Whatever may cause a message’s redelivery, the solution is to get the remote subscribers to detect duplicate message delivery and ignore messages already received. To help with this, some messaging infrastructures provide a unique message identity as part of the header/envelope around its body, making it unnecessary for the model to generate one. Even if the messaging system doesn’t itself automatically provide a unique identity for all messages, publishers can assign one either to the Event itself or to the message. In either case, remote subscribers can use the unique identity to manage de-duplication when messages are delivered more than once.

> 不管是什么原因导致了对消息的重新分发，消息订阅方都需要检查出重复的消息，并且将其忽略掉。为了达到这样的目的，有些消息设施在消息头中加入了唯一性的消息标识，此时我们自己的领域模型是不能生成这样的标识的。即便消息设施不会自动地向消息中加入唯一标识，消息的发送方也会向事件本身或者消息中加入这样的标识信息。不管采用哪种方法，远程的订阅方都有机会知道一条消息是否是重复发送的。

Is there a need for equals() and hashCode() implementations? These would most often be necessary only if the local Bounded Context used them. Events sent via messaging infrastructure are sometimes not reconstituted as their native typed objects when received by subscribers but are consumed as, for example, XML, JSON, or key-value maps. On the other hand, when an Event is designed as an Aggregate and saved to its own Repository, the Event type should provide both of these standard methods.

> 有必要为领域事件提供 equals（）和 hashCode（）方法吗？有，但是通常来说，只有当事件用于本地限界上下文中时，我们才这么做。对于通过消息设施发送的事件，有时订阅方接收的并不是事件对象本身，而是以 XML、JSON 或键值对等表示的事件数据。另一方面，当一个事件被设计成聚合并且保存在资源库中时，那么事件应该为这些数据展现形式提供相应的方法支持。

## 8.3 PUBLISHING EVENTS FROM THE DOMAIN MODEL 从领域模型中发布领域事件

Avoid exposing the domain model to any kind of middleware messaging infrastructure. Those kinds of components live only in the infrastructure. And while the domain model might at times use such infrastructure indirectly, it would never explicitly couple to it. We’ll use an approach that completely avoids the use of infrastructure.

> 我们应该避免将领域模型暴露给任何类型的消息中间件。这些消息中间件只存在于基础设施层中。虽然有时领域模型会间接地与基础设施层打交道，但是它们绝不会显式地耦合起来。我们所采用的方法将彻底地避免对基础设施的使用。

One of the simplest and most effective ways to publish Domain Events without coupling to components outside the domain model is to create a lightweight Observer [Gamma et al.]. For the sake of naming I use Publish-Subscribe, which is acknowledged by [Gamma et al.] as another name for the same pattern. The examples in that pattern and my use of it are lightweight because there is no network involved in subscribing to Events and publishing them. All registered subscribers execute in the same process space with the publisher and run on the same thread. When an Event is published, each subscriber is notified synchronously, one by one. This also implies that all subscribers are running within the same transaction, perhaps controlled by an Application Service that is the direct client of the domain model.

> 一种简单高效的发布领域事件的方法便是使用观察者（Observer）模式[Gammaet al.]，这种方法可以在领域模型和外部组件之间进行解耦。出于命名的原因，我将使用“发布-订阅”来表示该模式，这也是[Gamma et al.]书中给观察者模式的别名。我这里给出的例子是非常轻量级的，因为无论是订阅事件还是发布事件，其中都没有网络的参与。消息的订阅方和发布方位于相同的进程空间中，并且运行在相同的线程中。当事件发布时，每一个订阅方都会同步地得到通知。这也意味着所有的订阅方都运行在相同的事务中，也许它们都被相同的应用服务所管理，而应用服务则是领域模型的直接客户。

Considering the two halves of Publish-Subscribe separately helps to explain them in a DDD context.

> 为了更好地理解 DDD 中的领域事件，我们将分别讨论对消息的发布和订阅。

### 8.3.1 Publisher 发送方

Perhaps the most common use of Domain Events is when an Aggregate creates an Event and publishes it. The publisher resides in a Module (9) of the model, but it doesn’t model some aspect of the domain. Rather, it provides a simple service to Aggregates that need to notify subscribers of Events. The following is a DomainEventPublisher, which adheres to this definition. An abstract view of how the DomainEventPublisher is used can be found in Figure 8.2.

> 也许使用领域事件最常见的便是，由聚合创建一个事件，然后将其发布出去。此时的发送方位于模型的某个模块（9）中，但是它并没有表达出多少领域概念，而是向聚合中添加了一个简单的服务，该服务用于通知订阅方所发生的领域事件。以下是一个 DomainEventPublisher，顾名思义，该类用于发布领域事件，请参考图 8.2。

```java
package com.saasovation.agilepm.domain.model;

import java.util.ArrayList;
import java.util.List;

public class DomainEventPublisher {
    @SuppressWarnings("unchecked")
    private static final ThreadLocal<List> subscribers =
            new ThreadLocal<List>();
    private static final ThreadLocal<Boolean> publishing =
            new ThreadLocal<Boolean>() {
        protected Boolean initialValue() {
            return Boolean.FALSE;
        }
    };

    public static DomainEventPublisher instance() {
        return new DomainEventPublisher();
    }

    public DomainEventPublisher() {
        super();
    }

    @SuppressWarnings("unchecked")
    public <T> void publish(final T aDomainEvent) {
        if (publishing.get()) {
            return;
        }
        try {
            publishing.set(Boolean.TRUE);
            List<DomainEventSubscriber<T>> registeredSubscribers =
                    subscribers.get();
            if (registeredSubscribers != null) {
                Class<?> eventType = aDomainEvent.getClass();
                for (DomainEventSubscriber<T> subscriber :
                     registeredSubscribers) {
                    Class<?> subscribedTo =
                            subscriber.subscribedToEventType();
                    if (subscribedTo == eventType ||
                        subscribedTo == DomainEvent.class) {
                        subscriber.handleEvent(aDomainEvent);
                    }
                }
            }
        } finally {
            publishing.set(Boolean.FALSE);
        }
    }

    public DomainEventPublisher reset() {
        if (!publishing.get()) {
            subscribers.set(null);
        }
        return this;
    }

    @SuppressWarnings("unchecked")
    public <T> void subscribe(DomainEventSubscriber<T> aSubscriber) {
        if (publishing.get()) {
            return;
        }
        List<DomainEventSubscriber<T>> registeredSubscribers =
                subscribers.get();
        if (registeredSubscribers == null) {
            registeredSubscribers =
                    new ArrayList<DomainEventSubscriber<T>>();
            subscribers.set(registeredSubscribers);
        }
        registeredSubscribers.add(aSubscriber);
    }
}
```

Image

Figure 8.2. An abstract view of the sequence interactions between the lightweight Observer, User Interface (14), Application Services, and the Domain Model (1)

Since every incoming request from users of the system is handled on a separate dedicated thread, we divide subscribers by thread. So the two ThreadLocal variables, subscribers and publishing, are allocated per thread. When interested parties use the subscribe() operation to register themselves, the subscriber object reference is added to the thread-bound List. Any number of subscribers may be registered per thread.

> 由于每一个用户请求都将在单独的线程中予以处理，我们将通过线程来区分消息发送方。因此，对于上例中的两个 ThreadLocal 变量，subscribers 和 publishing，每个线程都会拥有自己的实例。当订阅方通过 subscribe（）方法向 DomainEventPublisher 进行注册时，该订阅方将被加入到所属线程的 List 中。每个线程都可以有多个注册的订阅方。

Depending on the application server, threads may be pooled and reused request by request. We don’t want subscribers registered on the thread for a previous request to remain registered for the next request that reuses the thread. When a new user request is received by the system, it should use the reset() operation to clear any previous subscribers. This ensures that subscribers will be limited only to those registered from that point forward. On the presentation tier (“User Interface” in Figure 8.2), for example, we might intercept each request using a filter. The intercepting component would in some way cause a reset():

> 根据不同的应用服务器，有些服务器可能会维护一个线程池，不同的请求有可能重用同一个线程。对于在先前请求线程中注册的订阅方，我们不希望它在同一个线程的下一个请求到来时依然处于注册状态。当系统接收到一个新的用户请求时，我们应该调用 reset（）方法来清除掉先前的订阅方。这样保证了只有在执行了 reset（）之后注册的订阅方才能处理事件。在展现层（即图 8.2 中的“UserInterface”），我们可以使用过滤器（filter）来拦截每个请求。该拦截组件将调用 reset（）方法：

```java
// in a Web filter component when user request is received
DomainEventPublisher.instance().reset();
...

// later in an Application Service during same request
DomainEventPublisher.instance().subscribe(subscriber);
```

Following the execution of this code—by two separate components, as seen in Figure 8.2—there will be just one registered subscriber for the thread. From the implementation of method subscribe() you can see that subscribers may be registered only when the publisher is not in the process of publishing. This prevents problems such as concurrent modification exceptions on the List. This problem is manifest if subscribers call back on the publisher to add new subscribers in response to a handled Event.

> 随着代码的执行——图 8.2 中的两个分离组件——线程中只能有一个注册的订阅方。通过 subscribe（）方法的实现我们知道，只有当发送方没有进行发送操作时，我们才能注册订阅方。这可以避免线程同步问题，比如两段代码同时修改一个 List。

Next, note how an Aggregate publishes an Event. Continuing with the running example, when BacklogItem’s commitTo() executes successfully, BacklogItemCommitted is published:

> 当一个订阅方在处理事件时，如果它反过来再向发送方中添加一个新的订阅方，那么上面的线程同步问题便是非常明显的。

```java
public class BacklogItem extends ConcurrencySafeEntity {
    ...
    public void commitTo(Sprint aSprint) {
        ...
        DomainEventPublisher
            .instance()
            .publish(new BacklogItemCommitted(
                    this.tenantId(),
                    this.backlogItemId(),
                    this.sprintId()));
    }
    ...
}
```

When publish() is executed on DomainEventPublisher, it iterates through all registered subscribers. Invoking subscribedToEventType() on each subscriber allows it to filter out all subscribers not subscribed to the specific Event type. Subscribers answering DomainEvent.class to this filter query will receive all Events. All qualified subscribers are sent the published Event by way of their handleEvent() method. After all subscribers have been either filtered or notified, the publisher completes.

> 在 DomainEventPulisher 执行 publish（）方法时，它将依次遍历所有注册的订阅方。此时，DomainEventPulisher 将调用每个订阅方的 subscribedToEventType（）方法来判断该订阅方是否可以处理一个特定类型的事件。如果订阅方返回的是 DomainEvent.class，则表明该订阅方可以处理任何类型的领域事件。所有有资格处理事件的订阅方都将使用 handleEvent（）方法来处理事件。在过滤或通知完所有的订阅方之后，发布过程执行完毕。

As with subscribe(), publish() does not allow nested requests to publish Events. The thread-bound Boolean named publishing is checked and must be false for publish() to iterate and dispatch.

> 和 subscribe（）方法一样，publish（）方法在发布事件时是不允许嵌套请求的。所以在执行 publish（）方法，我们首先需要检查 Boolean 类型的线程变量 publishing，只有在该变量为 false 时，我们才执行发布操作。

How is Event publishing extended to reach remote Bounded Contexts, supporting autonomous services? We’ll get to that soon, but let’s look closer at local subscribers.

> 对事件的发布如何延伸到远程的限界上下文，从而支持自治性服务呢？我们将在本章的后面进行讨论，这里我们只将关注点放在本地限界上下文的订阅方上。

### 8.3.2 Subscribers 订阅方

What components register subscribers to Domain Events? Generally speaking, Application Services (14), and sometimes Domain Services, will. The subscriber may be any component that is running on the same thread as the Aggregate that publishes the Event, and that can subscribe prior to the Event being published. This means that the subscriber is registered in the method execution path that uses the domain model.

> 由什么组件向领域事件注册订阅方呢？通常来说，这种功能由应用服务（14）完成，有时也由领域服务完成。订阅方可以是任何类型的组件，只要它和发布事件的聚合位于相同的线程中，并且在发布事件之前可以完成注册即可。这意味着，事件订阅方是在使用领域模型的方法执行流中进行注册的。

Cowboy Logic 牛仔的逻辑

LB: “I want a subscription to the The Fence Post so I can find even more corny things to say in this book.”

> LB：“我想订阅一份《The Fence Post》，以便在本书中有更多可说的。”

Image

Since Application Services are the direct client of the domain model when using Hexagonal Architecture, they are in an ideal position to register a subscriber with the publisher before they execute Event-generating behavior on Aggregates. Here’s one example of an Application Service that subscribes:

> 在使用六边形架构时，由于应用服务是领域模型的直接客户，它可以作为注册订阅方的理想场所，即在应用服务调用聚合方法产生事件之前，它可以先对订阅方进行注册。以下是应用服务注册订阅方的一个例子：

```java
public class BacklogItemApplicationService ... {
   public void commitBacklogItem(
           Tenant aTenant,
           BacklogItemId aBacklogItemId,
           SprintId aSprintId) {
       DomainEventSubscriber subscriber =
               new DomainEventSubscriber<BacklogItemCommitted>() {

           @Override
           public void handleEvent(BacklogItemCommitted aDomainEvent) {
               // handle event here ...
           }

           @Override
           public Class<BacklogItemCommitted> subscribedToEventType() {
               return BacklogItemCommitted.class;
           }
       }

       DomainEventPublisher.instance().subscribe(subscriber);

       BacklogItem backlogItem =
               backlogItemRepository
                       .backlogItemOfId(aTenant, aBacklogItemId);

       Sprint sprint = sprintRepository.sprintOfId(aTenant, aSprintId);

       backlogItem.commitTo(sprint);
   }
}
```

In this (contrived) example, BacklogItemApplicationService is an Application Service, with a service method commitBacklogItem(). The method instantiates an instance of an anonymous DomainEventSubscriber. The Application Service task coordinator then registers the subscriber with the DomainEventPublisher. Finally, the service method uses Repositories to get instances of BacklogItem and Sprint and executes the backlog item’s commitTo() behavior. When completed, method commitTo() publishes an Event of type BacklogItemCommitted.

> 在上例中，BacklogItem ApplicationSer vice 是一个应用服务，它拥有一个 commitBacklogItem（）服务方法。该方法将实例化一个匿名的 DomainEventSubscirber。然后，应用服务的任务协调器向 DomainEventPublisher 注册该 DomainEventSubscirber。最后，commitBacklogItem（）方法通过资源库获取到 BacklogItem 和 Sprint，再执行 BacklogItem 的 commitTo（）方法。当该方法执行完后，它将发布一个 BacklogItemCommitted 事件。

What the subscriber does with the Event is not shown in this example. It could send an e-mail about the fact that a BacklogItemCommitted, if that made any sense. It might store the Event in an Event Store. It could forward the Event via a messaging infrastructure. Usually in these last two cases—saving to an Event Store and forwarding using messaging infrastructure—we wouldn’t make a use-case-specific Application Service to handle the Event in this way. Instead we’d design a single subscriber component to do that. An example of a single-responsibility component that saves to an Event Store is found in the section “Event Store.”

> 上例并没有包含订阅方如何处理事件的代码。订阅方可以向外发送一封 E-mail 以告知 BacklogItemCommitted 事件的发生；也可以将该事件存放在事件存储中；或者通过消息设施将该事件转发出去。对于后两种情形，我们并不会创建一个特定于用例的应用服务，而是设计一个订阅组件予以处理。在“事件存储”一节中，你将看到这样的例子。在该例中，一个具有单一职责的组件负责将领域事件保存到事件存储中。

Be Careful about What the Event Handler Does 对于事件处理器，你要小心了

Remember, the Application Service controls the transaction. Don’t use the Event notification to modify a second Aggregate instance. That breaks a rule of thumb to modify one Aggregate instance per transaction.

> 应用服务控制着事务。不要在事件通知过程中修改另外一个聚合实例，因为这样破坏了聚合的一大原则：在一个事务中，只对一个聚合进行修改。

One thing the subscriber should not do is get another Aggregate instance and execute modifying command behavior on it. This would violate the modify-single-aggregate-instance-in-single-transaction rule of thumb, as discussed in Aggregates (10). As [Evans] indicates, the consistency of all Aggregate instances other than the one used in the single transaction must be enforced by asynchronous means.

> 事件订阅方不应该在另一个聚合上执行命令方法，因为这样将破坏“在单个事务中只修改单个聚合实例”的原则，请参考聚合（10）。正如[Evans]所讲，所有聚合实例之间的最终一致性必须通过异步的方式予以处理。

Forwarding the Event via a messaging infrastructure would allow asynchronous delivery to out-of-band subscribers. Each of those asynchronous subscribers could arrange to modify an additional Aggregate instance in one or more separate transactions. The additional Aggregate instances could be in the same Bounded Context or in others. Publishing the Event outward to any number Bounded Contexts of other Subdomains (2) emphasizes the word Domain in the term Domain Event. In other words, Events are a domain-wide concept, not just a concept in a single Bounded Context. The contract of Event publishing should have the potential to be at least as broad as the enterprise, or even broader. Yet, wide broadcast does not forbid delivery of Events by consumers in the same Bounded Context. Refer back to Figure 8.1.

> 通过消息设施转发事件可以异步地将事件发送到不同的订阅方。每一个订阅方都可以在各自单独的事务中修改额外的聚合实例。这些额外的聚合实例可以位于相同的限界上下文中，也可以位于不同的限界上下文中。将事件分发到不同限界上下文的子域中，这里的“子域”强调了领域事件中的“领域”一词。换句话说，这里的事件是领域范围内的概念，而不是限界上下文中的概念。事件发布的契约应该放在整个企业范围之内，或者更大的范围。但是，大范围的事件分发并不意味着我们不能在相同的限界上下文中对事件进行分发。请参考图 8.1。

Sometimes it is necessary for Domain Services to register subscribers. The motivation for doing so would be similar to the reasons that Application Services do, but in this case there would be domain-specific reasons to listen for Events.

> 有时，有必要使用领域服务来注册事件订阅方。这样的动机可能和让应用服务来注册订阅方一样，但是此时我们可能有特定于领域的原因。

## 8.4 SPREADING THE NEWS TO REMOTE BOUNDED CONTEXTS 向远程限界上下文发布领域事件

There are several possible ways for remote Bounded Contexts to become aware of Events that occur in your Bounded Context. The primary idea is that some form of messaging takes place, and an enterprise messaging mechanism is needed. To be clear, the mechanism being spoken of here goes well beyond the simple, lightweight Publish-Subscribe components just discussed. Here we are discussing what takes over where the lightweight mechanism leaves off.

> 有多种方法可以将本地限界上下文中产生的事件发送到远程限界上下文中。首先，可以使用消息机制。需要明确的是，这里讨论的概念要比先前的发布-订阅概念宽泛得多。这里我们讨论的是那些轻量级的发布-订阅机制无法处理的情况。

There are numerous such messaging components available, and they are generally classed as middleware. From the open source ActiveMQ, RabbitMQ, Akka, NServiceBus, and MassTransit, to the various commercially licensed products, there are plenty of options. We might also home-grow a form of messaging based on REST resources, where autonomous systems are the interested parties that reach out to the publishing system, requesting all Event notifications that they have not previously consumed. All of these fall under the umbrella of Publish-Subscribe [Gamma et al.], with varying degrees of advantage or disadvantage. Much depends on the budget, taste, functional requirements, and nonfunctional qualities sought by the teams involved.

> 存在多种消息组件，它们通常称为中间件。在开源社区有 ActiveMQ、RabbitMQ、Akka、NserviceBus 和 MassTransit 等。另外还存在很多商业化的消息中间件产品。当然，我们也可以通过 REST 资源的方式自己实现一套消息机制，此时，作为订阅客户方的自治系统将与消息的发布系统彻底分离，他们所请求的每一条消息通知都是先前没有处理过的。以上所有的消息系统都采用发布-订阅模式[Gamma et al.]，它们都有各自的优缺点。各个开发团队可以根据自身的预算、功能需求和质量需求而采用最适合自己的消息系统。

The use of any such messaging mechanism between Bounded Contexts requires that we adopt a commitment to eventual consistency. It can’t be fought. The changes in one model that influence changes in one or more other models will not be fully consistent for some elapsed period of time. What is more, depending on the traffic to individual systems and the effects they have on others, it may be that the systems as a whole may never be fully consistent at any one instant in time.

> 在不同的限界上下文之间采用这些消息系统时，我们必须保证最终一致性。在一个模型中的改变可能需要很长一段时间才能反映到另一个模型中。此外，根据各个系统的吞吐量和它们对其他系统的影响程度，在某个时间点，所有交互系统作为一个整体有可能根本就无法达到最终一致性。

### 8.4.1 Messaging Infrastructure Consistency 消息设施的一致性

With all the chatter about eventual consistency, it might surprise you that at least two mechanisms in a messaging solution must always be consistent with each other: the persistence store used by the domain model, and the persistence store backing the messaging infrastructure used to forward the Events published by the model. This is required to ensure that when the model’s changes are persisted, Event delivery is also guaranteed, and that if an Event is delivered through messaging, it indicates a true situation reflected by the model that published it. If either of these is out of lockstep with the other, it will lead to incorrect states in one or more interdependent models.

> 对于最终一致性，我们至少需要在两种存储之间保持最终一致性：领域模型所使用的持久化存储和消息设施所使用的持久化存储。这样保证了在持久化领域模型时，相应的领域事件也总能够得以发布。如果这两者没有得到同步，有可能导致模型处于不正确的状态。

How is model and Event persistence consistency accomplished? There are three basic ways:

> 那么，我们如何保证领域模型存储和事件存储之间一致性呢？有三种基本的方式：

1. Your domain model and messaging infrastructure share the same persistence store (for example, a data source). This will allow the changes to the model and the insertion of the new message to commit under the same local transaction. It has the advantage of relatively good performance. It has the possible disadvantage that the messaging system’s storage areas (such as database tables) must reside in the same database (or schema) as your model’s, which may be a matter of taste. Of course, this is not a viable option if your choice of model store and your messaging mechanism’s store cannot be shared.
2. Your domain model’s persistence store and your messaging persistence store are controlled under a global, XA transaction (two-phase commit). This has the advantage that you can keep model and messaging storage separated from each other. It has the disadvantage that global transactions require special support, which may not be available for all persistence stores or messaging systems. Global transactions tend to be expensive and perform poorly. It is also possible that either the model’s store or the messaging mechanism’s store, or both, isn’t XA compatible.
3. You create a special storage area (for example, a database table) for Events in the same persistence store that is used to store your domain model. This is an Event Store, as discussed later in this chapter. It is similar to option 1; however, this storage area is not owned and controlled by your messaging mechanism but instead by your Bounded Context. An out-of-band component that you create uses the Event Store to publish all stored, unpublished Events through the messaging mechanism. This has the advantage that your model and your Events are guaranteed to be consistent within a single, local transaction. It has the further advantages that are characteristic of an Event Store, including the ability to produce REST-based notification feeds. This approach allows the use of a messaging infrastructure whose message store is completely private. Given that a middleware messaging mechanism can be used after Event storage, this approach has the disadvantage that the Event forwarder must be custom-developed in order to send through the messaging mechanism, and that clients must be designed to de-duplicate incoming messages (see “Event Store”).

---

> 1. 领域模型和消息设施共享持久化存储（比如，数据源）。在这种情况下，对模型的修改和对事件的提交发生在同一个本地事务中。这种方式的优点在于性能很高，而缺点在于消息系统的存储区域（比如数据库表）必须和领域模型位于同一个数据库中。当然，如果你的领域模型和消息机制不能共享持久化存储，这种方式便不合适了。
> 2. 领域模型的持久化存储和消息持久化存储由全局的 XA 事务（两阶段提交）所控制。这种方式的优点在于模型和消息所使用的持久化存储可以分开；缺点在于全局事务需要额外的支持，但不见得所有的存储机制都支持全局事务。全局事务的成本是很高的，而性能却很差。有可能出现的情况是，要么领域模型存储不支持 XA 事务，要么消息存储不支持 XA 事务，要么两者都不支持。
> 3. 在领域模型的持久化存储中，创建一个特殊的存储区域（比如一张数据库表），该区域用于存储领域事件。这便是一个事件存储（Event Store），对此我们将在本章后面予以讨论。这种方式和方式 1 相似，但是，此时的事件存储区域不再由消息机制所拥有和控制，而是你的限界上下文。同时，你需要创建一个消息外发组件将事件存储中的所有消息通过消息机制发送出去。这种方式的优点在于：模型修改和事件提交可以同时位于单个本地事务中。另一个额外的优点是，我们可以发布基于 REST 的事件通知。使用这种方式时，消息机制所使用的消息存储是完全私有的。在将领域事件保存到事件存储之后，我们需要使用一个消息中间件来发送消息。因此，这种方式的缺点是，我们可能需要定制开发一个消息转发组件来发送消息，同时客户方需要对消息进行消重处理（请参考“事件存储”）。

It is the third approach that I use in my examples. While there are disadvantages to this approach, there are also several advantages that are made clear under “Event Store.” My choice of this one approach in no way negates the value of selecting in favor of a different set of trade-offs. You and your team must choose from among them.

> 在本书的例子中，我们采用了方式 3。虽然这种方式存在一些缺点，但是在“事件存储”中我们将看到，这种方式也是存在很多优点的。当然，我的选择并不能看作是唯一正确的选择，每种方式都存在自身的优缺点，你的团队需要根据实际情况做出适合于自己的选择。

### 8.4.2 Autonomous Services and Systems 自治服务和系统

Using Domain Events allows any number of your enterprise systems to be designed as autonomous services and systems. I use the term autonomous service to represent any coarse-grained business service, possibly thought of as a system or application, that operates largely independent of other such “services” in the enterprise. The autonomous service may have a number of service interface endpoints, meaning that it offers potentially many technical service interfaces to remote clients. A high degree of independence from other systems is achieved by avoiding in-band remote procedure calls (RPCs), where a user request is satisfied only by successful completion of an API request to a remote system.

> 通过使用领域事件，我们可以将任何企业系统设计成自治服务和系统。这里的自治服务表示一个设计良好的业务服务，我们可以将其看成一个系统或者应用程序。在整个企业范围之内，这些自治服务相互独立的完成各自的功能。自治服务可能拥有多个服务接口端点，表明该自治服务向远程客户方提供了多种技术上的服务接口。自治服务可以避免对远程过程调用（RPC）的使用，这可以带来更高程度的独立性。

Since there may be times when the remote system is either completely unavailable or under heavy load, RPC may affect the success of the dependent system. This risk multiples as the number of systems with RPC APIs that a given system depends on increases. Thus, avoiding in-band RPC greatly eases dependency and related instances of complete failure and/or unacceptable performance caused by unavailable or low-throughput remote systems.

> 远程系统有可能不可用或者处于超负荷状态，此时 RPC 可能会影响客户方的成功调用。随着 RPC API 的增加，这种风险也将随之增大。因此，避免对 RPC 的使用可以大大地简化系统之间的依赖，并且可以减少由远程系统不可用所带来的彻底请求失败。

Rather than calling out to other systems, use asynchronous messaging to achieve a greater degree of independence between systems—autonomy. As messages carrying Domain Events from Bounded Contexts around the enterprise are received, execute behavior on your model that reflects the meaning of those Events within your Bounded Context. This does not mean that you simply replicate data or make exact copies of objects from other business services into your business service. True, some data may be copied between systems. At a minimum, copied data will include some unique identities of foreign Aggregates. But the objects in one system will seldom if ever be exact copies of objects from surrounding ones. If that probable modeling error exists, see Bounded Contexts (2) and Context Maps (3) for reasons why it is problematic and for ways to avoid it. In fact, if Domain Events are correctly designed, they will rarely if ever carry entire objects as part of their state.

> 在与远程系统交互时，客户方可以不用主动地发起请求调用，而是可以通过异步的消息来达到更高层次的独立性——自治性。当携带远程限界上下文中领域事件的消息抵达之后，本地上下文将对该事件做出相应的处理，比如调用本地聚合上的命令方法等。但是，这并不意味着我们只是简单地将消息中的对象复制到自己的业务系统中。诚然，数据复制是不可避免的，比如我们至少需要复制远程上下文中聚合的唯一标识。然而，我们几乎没有可能对远程上下文所传来的对象进行整体复制。如果发生了这样的建模错误，请参考限界上下文（2）和上下文映射图（3），这两个章节向我们解释了这样做为什么是错误的，并且如何避免这些错误。事实上，在领域事件设计正确的情况下，它们极少会携带远程上下文中的某个对象的所有信息。

The Event will hold some limited amount of command parameters and/or Aggregate state that will convey enough meaning to allow subscribing Bounded Contexts to react correctly. Certainly if any given Event does not hold enough information for any given subscriber, the domain-wide contract of the Event must be altered in order to supply what is needed. This probably spells designing an explicitly new version of the Event or a completely different one.

> 领域事件将携带有限的命令参数和聚合状态，这些信息足以使作为订阅方的限界上下文做出相应的操作。否则，该事件在领域范围之内的契约应该进行修改，结果将导致一个新的事件契约版本，或者一个完全不同的事件。

It is also true that in some cases the use of RPC cannot be easily avoided. Some legacy systems may be capable of providing only RPC. Also, when translating a concept or set of concepts from a foreign Bounded Context to your local Bounded Context is very difficult to do, extrapolating sufficient meaning from multiple Events may tend to increase complexity. If you must nearly replicate the concepts, objects, and their associations from the foreign model in your own model, you may need to consider sticking with RPC. This must be considered on a case-by-case basis, and I suggest not giving in to RPC too easily. If it can’t be avoided, either surrender to RPC or try to influence the team that owns the foreign model to find a way to simplify their design. Admittedly the latter may be very difficult, if not impossible.

> 有时，RPC 是不可避免的。有些遗留系统可能只向客户方提供了 RPC 的调用方式。另外，有时将一个外部限界上下文中的概念翻译成本地上下文中的概念是存在困难的，而从不同事件中抽取信息以达到这样的翻译目的又会增加复杂度。如果你希望尽可能全面地将外部模型复制到本地模型中，那么此时便可以考虑使用 RPC。当然，这不能成为一种优选的解决方案，我建议尽量不要使用 RPC。如果 RPC 确实是不可避免的，此时要么采用 RPC，要么可以说服外部模型的团队简化他们的设计。应该承认的是，后一种方法是非常困难的。

### 8.4.3 Latency Tolerances 容许时延

Won’t the potentially long latency periods before a message is received—where eventual consistency represents delays of more than a few milliseconds—cause problems? Certainly this is a matter to consider carefully, given that out-of-sync data could influence wrong and even damaging actions. We must ask how long between consistent states is acceptable, and how much delay is too great. Domain experts will likely be very much in tune with what constitutes acceptable and unacceptable delays. It may surprise developers to learn that most times, several seconds, minutes, hours, or even days between consistent states is completely tolerable. This is not to say that it is always true. But we must not assume that in any given domain, near-consistent time frames are always imperative.

> 发送事件和接收事件之间的时间延迟会导致问题吗？需要肯定的是，我们应该细心地应对这种情况，因为数据的不同步可能导致非常严重的负面影响。我们必须知道多长的时间延迟是可以接受的，多长是可能导致问题的。对于此，领域专家可能是非常清楚的。可能令开发者感到惊讶的是，数秒钟、数分钟、数小时甚至好几天的事件时延都是可以接受的。当然，这种说法并不总是对的，但是我们应该知道，长时间的事件延迟是有可能发生的。

Sometimes the following question will lead to an informative answer: How did the business work prior to computers, or how would it work without them now? Perhaps not even the very simplest of paper-based systems is ever immediately consistent. It would only make sense, then, that automated computer systems could also tolerate and even thrive in an eventually consistent manner. We might conclude that eventual consistency makes better business sense.

> 有时，回答以下问题有助于我们更好地理解事件时延：在没有计算机之前业务是如何开展的，如今，将我们手中的计算机扔掉，我们的业务又将如何开展？也许最简单的基于纸张的系统也不见得有多好的最终一致性。因此，自动化的计算机系统也是有理由存在事件延时的。

Imagine a Subdomain used to plan future team activities. As any of the individual activities becomes approved, a Domain Event is published that reflects the approval: TeamActivityApproved. This one follows any number of other Events that have already been published about the genesis and definition of all now-approved activities. Another Bounded Context reacts to the approval by scheduling the latest readied activity to start sometime in relation to all other approved activities.

> 想一个用于计划团队未来活动的子域。当任何一个团队活动被批准时，系统都将发布一个 TeamActivityApproved 领域事件。在该事件发布之前，还可能存在其他已经发布的事件。另一个限界上下文将等待所有的事件到达之后才启动团队活动。

We know that any given activity is specified and approved at least weeks before it begins. That being so, would it matter if the Event necessary to cause placement of the approved activity in the schedule were to be received minutes, hours, or possibly even days following approval? Maybe days wouldn’t be acceptable. However, if the outage of a system caused the Event to be delayed for a number of hours—probably an unlikely situation—would hours without having the activity on the schedule be a completely intolerable delay? No, because it is a rare system outage that must be worked around, and the activity is still weeks off anyway. Since that is so, certainly a typical delay of perhaps as much as a few seconds—at the outer limits—for the same Event to arrive under completely normal circumstances would be not only tolerable, but acceptable. In fact any actual delays may not even be perceptible.

> 我们知道，一项活动在启动之前，必须提前两周得到批准。因此，事件延时并不是一个大问题，数分钟、数小时甚至数天的延时都是可以接受的。比如，由于系统失效导致了事件延迟了几个小时，这种故障对于该场景来说是完全可以接受的。

Cowboy Logic 牛仔的逻辑

AJ: “Is that a Kentucky ‘shortly’?”

> AJ：“肯塔基人经常说‘一小会儿’，对吧？”•

LB: “It might be a New York ‘minute.’”

> LB：“对，纽约人说的是‘一分钟’。”

Image

Just as much as this example may prove true, other business services will demand higher throughput. Maximum latency tolerances should be well understood and systems should have the architectural qualities to meet them and possibly even out-perform them. High availability and scalability must be designed into autonomous services and their supporting messaging infrastructure in order to dutifully fulfill stringent enterprise nonfunctional requirements.

> 有些业务服务可能需要更高的吞吐量，此时我们需要好好地考虑最大容许时延，系统的架构应该满足在事件时延上的需求。对于自治服务和支持它们的消息设施来说，我们应该在可用性和可伸缩性上下足功夫，以便更好地完成那些非功能性的需求。

## 8.5 EVENT STORE 事件存储

Maintaining a store of all Domain Events for a single Bounded Context has several potential benefits. Consider what you could do if you were to store a discrete Event for every model command behavior that is ever executed. You could

> 对于单个限界上下文的所有领域事件来说，为它们维护一个事件存储是有好处的。考虑一下，如果你要存储由每个模型的命令方法所产生的离散领域事件，你将怎么做？你有可能：

1. Use the Event Store as a queue for publishing all Domain Events through a messaging infrastructure. This is one of the primary uses in this book. It allows integrations between Bounded Contexts, where remote subscribers react to the Events in terms of their own contextual needs. (See the previous section, “Spreading the News to Remote Bounded Contexts.”)
2. You may use the same Event Store to feed REST-based Event notifications to polling clients. (This is logically the same as point 1, but different in actual use.)
3. Examine a historical record of the result of every command that has ever been executed on the model. This could help trace bugs, not only in the model but also in clients. It’s important to grasp that an Event Store is not just an audit log. Audit logs may helpful for debugging, but they rarely carry the complete results of each Aggregate command outcome.
4. Use the data in trending, forecasting, and for other business analytics. Many times businesses have no idea how such historical data can be used until they later realize that they need it. Unless an Event Store is maintained from the start, the historical data will be unavailable as needs arise.
5. Use the Events to reconstitute each Aggregate instance when it is retrieved from its Repository. This is a required part of what is known as Event Sourcing. It is done by applying to an Aggregate instance all previously stored Events in chronological order. You may produce snapshots of any number of stored Events (for example, groups of 100) to optimize instance reconstitution.
6. Given an application of the preceding point, undo blocks of changes to an Aggregate. This is possible by preventing (perhaps by removal or marking as obsolete) certain Events from being used to reconstitute a given Aggregate instance. You may also patch Events or insert additional Events to correct bugs in the Event stream.

---

> 1. 将事件存储作为一个消息队列来使用，该消息队列的作用是将所有的领域事件通过消息设施发布出去。这种方法是本书中首要使用的方法，它允许在不同的限界上下文之间进行集成，此时远程的订阅方将对领域事件做出反应以满足自身上下文的需求（请参考“向远程限界上下文发布领域事件”一节）。
> 2. 将相同的事件存储用于基于 REST 的事件通知（在逻辑上，这和第 1 点是相同的，但在实际使用时却存在不同）。
> 3. 检查由模型的命令方法所产生的所有结果的历史记录。这可以用于跟踪 bug，不只是跟踪自己模型中的 bug，还可以跟踪客户方中的 bug。因此，此时的事件存储不再只是一个简单的审计日志。审计日志对于调试来说是有用的，但是却很少包含由聚合命令方法所产生的完整结果。
> 4. 使用事件存储中的数据来进行业务预测和分析。很多时候，业务人员只有在需要使用这些数据的时候才能意识到这些历史数据的重要性，而在没有事件存储来维护这些数据的时候，他们便捉襟见肘了。
> 5. 当从资源库中获取一个聚合实例时，使用事件来重建该聚合实例。对于事件源来说，这是一个必要的组成部分。重建聚合通过顺序地应用发生在该聚合上的所有事件来完成。你可以将任意数量的事件用于聚合重建（比如，以 100 个事件进行分组）。
> 6. 撤销对聚合的操作。为了达到这一点，我们可以在重建聚合时避免应用某一些事件（比如通过移除事件或使事件过期等方式）。另外，我们还可以添加一些事件补丁或者插入一些额外的事件来修复系统中的 bug。

Depending on your reasons to create an Event Store, it will have certain characteristics. Since the examples presented here are primarily motivated by benefits 1 and 2, our Event Store is basically concerned with holding serialized Events in the order in which they occurred. This does not mean that we couldn’t use the Events to realize all of the first four benefits, because the second two are possible based on the fact that we are making a record of all significant Events in the domain. Achieving benefits 3 and 4 is, therefore, further application of what’s accomplished by the first two. However, we will not be attempting to leverage the Event Store for points 5 and 6 in this chapter.

> 根据使用初衷的不同，事件存储将表现出不同的特征。由于本书中使用的例子主要是关于以上的第 1 点和第 2 点，我们在使用事件存储时将主要关注于顺序地将事件序列化到事件存储中。当然，这并不意味着我们就无法享受到第 3 点和第 4 点的好处，因为这两点是建立在第 1 点和第 2 点基础之上的。因此，在有了第 1 点和第 2 点之后，我们可以进而享受到由第 3 点和第 4 点的好处。然而，在本章中，我们不会谈及到上面的第 5 点和第 6 点。

Several steps are necessary to realize benefits 1 and 2. The steps are summarized in Figure 8.3. Let’s first discuss the steps covered in that sequence diagram and the components involved. We’ll do so through the project experiences of SaaSOvation.

> 要达到上面的第 1 点和第 2 点，我们需要几个步骤，请参考图 8.3。我们首先将讨论图 8.3 中的不同步骤和其中所包含的组件。我们将通过 SaaSOvation 团队的经历来讲解。

Image

Figure 8.3. The IdentityAccessEventProcessor anonymously subscribes to all Events of the model. It delegates to EventStore, which serializes each to a StoredEvent and saves it.

For whatever reasons we use an Event Store, one of the first things we need to do is create a subscriber that will receive every Event that is published out of the model. The team decided to do that using an aspect-oriented hook that can insert itself in the execution path of every Application Service in the system.

> 不管是出于什么原因而使用事件存储，我们首先要做的便是创建事件的订阅方。SaaSOvation 团队成员决定通过面向切面（Aspect-Oriented）的方式在每个应用层的执行流中插入对订阅方的注册功能。

Image

Here’s what the SaaSOvation team did for the Identity and Access Context. The following component has the single responsibility to see to it that all Domain Events get stored:

> 以下是 SaaSOvation 团队在身份与访问上下文中的实现代码，它保证了所有的领域事件都能得到保存。

```java
@Aspect
public class IdentityAccessEventProcessor {
    ...
    @Before(
    "execution(* com.saasovation.identityaccess.application.*.*(..))")
    public void listen() {
        DomainEventPublisher
            .instance()
            .subscribe(new DomainEventSubscriber<DomainEvent>() {
                public void handleEvent(DomainEvent aDomainEvent) {
                    store(aDomainEvent);
                }

                public Class<DomainEvent> subscribedToEventType() {
                    return DomainEvent.class; // all domain events
                }
            });
    }

    private void store(DomainEvent aDomainEvent) {
        EventStore.instance().append(aDomainEvent);
    }
}
```

It’s a simple Event processor, and a similar one could be used by any other Bounded Context with the same mission. It’s designed as an aspect (using Spring’s AOP) that intercepts all Application Service method invocations. When an Application Service method is executed, this processor arranges to listen for all Domain Events that get published due to the Application Service’s interaction with the model. The processor registers a subscriber with the thread-bound instance of DomainEventPublisher. This subscriber’s filter is wide open, which is indicated by its answering DomainEvent.class from subscribedToEventType(). Returning that class indicates that the subscriber wants to receive all Events. When its handleEvent() is invoked, it delegates to store(), which in turn delegates to class EventStore to append the Event to the end of the actual Event Store.

> 以上是一个非常简单的事件处理器，在其他限界上下文中我们也可以采用相似的方法。该事件处理器使用了一个切面（Spring AOP）来拦截所有的应用层方法。当执行一个应用层方法时，消息处理器将对模型中所发布的所有事件进行监听。事件处理器向当前线程中的 DomainEventPublisher 实例注册了一个 DomainEventSubscriber。通过 subscribedToEventType（）方法所返回的 DomainEvent.class 我们知道，该 DomainEventSubscriber 可以处理任何类型的领域事件。在执行 handleEvent（）方法时，该 DomainEventSubscriber 将委派给 store（）方法，store（）方法进而委派给 EventStore 实例的 append（）方法。

Here’s a look at the EventStore component’s append() method:

> 下面是 EventStore 的 append（）方法：

```java
package com.saasovation.identityaccess.application.eventStore;
...
public class EventStore ... {
    ...
    public void append(DomainEvent aDomainEvent) {
        String eventSerialization =
            EventStore.objectSerializer().serialize(aDomainEvent);
        StoredEvent storedEvent =
                new StoredEvent(
                        aDomainEvent.getClass().getName(),
                        aDomainEvent.occurredOn(),
                        eventSerialization);
        this.session().save(storedEvent);
        this.setStoredEvent(storedEvent);
    }
}
```

Method store() serializes the DomainEvent instance, places that into a new StoredEvent instance, and then writes that new object to the Event Store. Here is a portion of class StoredEvent that holds the serialized DomainEvent:

> 这里的 store（）方法将对 DomainEvent 实例进行序列化，然后将其用于创建新的 StoredEvent 实例，最后将该 StoredEvent 保存到事件存储中。以下是 StoredEvent 类的部分代码：

```java
package com.saasovation.identityaccess.application.eventStore;
...
public class StoredEvent {
    private String eventBody;
    private long eventId;
    private Date occurredOn;
    private String typeName;

    public StoredEvent(
            String aTypeName,
            Date anOccurredOn,
            String anEventBody) {
        this();
        this.setEventBody(anEventBody);
        this.setOccurredOn(anOccurredOn);
        this.setTypeName(aTypeName);
    }
    ...
}
```

Each StoredEvent instance gets a unique sequence value autogenerated by the database and set as its eventId. Its eventBody contains the serialization of the DomainEvent. The serialization used here is JSON using the [Gson] library, but we could use another form. The typeName holds the name of the concrete class of the corresponding DomainEvent, and occurredOn is a copy of the same occurredOn in the DomainEvent.

> 每一个 StoredEvent 实例都有一个唯一的序列号 eventId，该序列号由数据库自动产生。StoredEvent 的 eventBody 包含了 DomainEvent 的序列化数据。在该例中，我们使用了[Gson]库将 DomainEvent 序列化成了 JSON 格式的数据，当然你也可以采用其他格式。StoredEvent 的 typeName 保存了领域事件的实际类名，而 occurredOn 则和 DomainEvent 中的 occurredOn 相同。

All StoredEvent objects are persisted into a MySQL table. Plenty of room is reserved for Event serializations, although 65,000 characters is no doubt far more storage than will ever be needed by a single instance:

> 所有的 StoredEvent 对象都将持久化到 MySQL 数据库中。此时，数据库应该为序列化后的事件数据保留足够的存储空间，这里我们使用了具有 65，000 字符宽度的 varchar 来保存序列化数据，这对于当前的事件实例来说已经足够了。

```sql
CREATE TABLE `tbl_stored_event` (
    `event_id` int(11) NOT NULL auto_increment,
    `event_body` varchar(65000) NOT NULL,
    `occurred_on` datetime NOT NULL,
    `type_name` varchar(100) NOT NULL,
    PRIMARY KEY (`event_id`)
) ENGINE=InnoDB;
```

That takes us through the high-level review of a few components necessary to build up the Event Store with all Event instances published by Aggregates in the domain model. We’ll look at more detail later. Let’s next see how these stored records of happenings in our model can be consumed by other systems.

> 以上，我们在一个较高层次上向大家展示了用于事件存储的必要组件。在本章后面，我们将讨论更多的细节。接下来，让我们看看其他系统是如何使用这些存储事件的。

## 8.6 ARCHITECTURAL STYLES FOR FORWARDING STORED EVENTS 转发存储事件的架构风格

Once the Event Store is populated, it is available to provide Events to be forwarded as notifications to interested parties. We’ll look at two styles of making these Events available. One style is through RESTful resources that are queried by clients, and the second style is by sending messages over a topic/exchange of a middleware messaging product.

> 一旦领域事件被保存在了事件存储中，我们便可以对这些事件进行转发以通知其他系统。我们将讨论两种转发事件的架构风格。一种是基于 REST 资源的方式，一种是基于消息中间件的方式。

Granted, the REST-based approach is not truly a forwarding technique. Yet, it is used to produce the same results as a Publish-Subscribe style, much as an e-mail client is a “subscriber” to e-mail messages “published” by an e-mail server.

> 诚然，基于 REST 的方式并不是一种真正意义上的转发技术。但是，它可以达到和发布-订阅风格相同的效果，就比如，一个 E-mail 客户方可以作为一个“订阅方”，它所订阅的便是由 E-mail 服务器所“发布”的 E-mail 信件。

### 8.6.1 Publishing Notifications as RESTful Resources 以 REST 资源的方式发布事件通知

The REST style of Event notification works best when used in an environment that follows the basic premises of Publish-Subscribe. That is, many consumers are interested in the same events that are available from a single producer. On the other hand, if you attempt to use the REST-based style as a Queue, the approach tends to break down. Here is a summary of the good and the bad of the RESTful approach:

> 在那些具有基本发布-订阅功能的系统环境中，采用 REST 风格的事件通知是最合适的。在这些环境中，一个发布方发布的事件存在着多个消费方。另一方面，如果你试图通过消息队列的方式来使用 REST 事件通知，就会出问题了。以下是 REST 风格事件通知的优缺点：

- If potentially many clients can go to a single well-known URI to request the same set of notifications, the RESTful approach works well. Essentially notifications are fanned out to any number of polling consumers. This follows the basic Publish-Subscribe pattern, even though it uses the pull model instead of the push model.2
- If one or a few consumers are required to pull from multiple producers for resources in order to get a single set of tasks to be performed in a specific sequence, you will probably quickly feel the pain of using a RESTful approach. This describes a Queue, where potentially many producers need to feed notifications to one or a few consumers, and the order of receipt may matter. A polling model is typically not a good choice for implementing Queues.

---

> - 如果多个客户方都可以通过单个 URI 来请求相同的事件通知，那么此时 REST 便是合适的。一个事件通知可以拥有任意多的消费方。虽然 REST 使用的是“拉”的方式，而不是“推”的方式[2]。
> - 如果一个或多个消费方需要从多个发布方中获取资源以顺序地完成一系列任务，那么此时你便会感到 REST 所带来的痛苦了。这实际上描述了一个消息队列，许多发送方同时为一个或多个消费方服务，此时事件的接收顺序是重要的。对于实现消息队列来说，“拉”的方式并不是一个好的选择。

The RESTful approach to publishing Event notifications is quite the opposite of those published using a typical messaging infrastructure. The “publisher” does not maintain a set of registered “subscribers” because nothing gets pushed to interested parties. Instead this approach requires REST clients to pull for notifications using a well-known URI.

> 与那些典型的消息设施相比，采用 REST 来发布事件通知是一种截然不同的风格。其中，“发布方”并不会持有注册的“订阅方”，因为 REST 不会对事件进行“推送”。相反，这种方式需要 REST 的客户方通过一个公认的 URI 来“拉取”事件通知。

Consider the RESTful approach from a high level. If you are familiar with the way Atom feeds are consumed on the Web, this approach will look very familiar. It’s actually based on Atom concepts.

> 让我们再从一个高的层次来考虑 REST。如果你理解 Web 领域中 Atom 的工作机制，那么你便能更好地理解基于 REST 的消息通知方式了，因为它们非常相似。事实上，REST 消息通知即是建立在 Atom 概念之上的。

Clients use the HTTP GET method to request what is known as the current log. The current log contains the very latest notifications that have been published. The client receives the current log with a number of notifications not to exceed a standard limit. Our examples use 20 as the maximum number of notifications for each log. The client navigates through each of the Events in the current log to find all that have not yet been consumed by its Bounded Context.

> 客户方通过 HTTP 的 GET 方法来请求所谓的当前日志（Current Log）。这里的当前日志表示所发布事件通知的最新版本。客户方所接收到的当前日志包含了若干数量的事件通知，通知数量不能超过标准上限。在本书的例子中，我们将每个当前日志所包含的通知数量设成 20。客户方将依次遍历当前日志中所有的事件通知，从中找出那些还没有被本地限界上下文所处理的事件通知。

How does a client consume Event notifications locally? It interprets the serialized Event by type, translating any pertinent data as appropriate to the local Bounded Context. This likely includes finding related Aggregate instances in its own model and executing commands based on the interpretation of applicable Events. Of course, Events must be applied in chronological order, since the oldest Events represent operations that took place earlier than newer ones. Unless the oldest Events are applied first in the order in which they occurred, the changes that are affected on the local model could well cause bugs.

> 那么，客户方在本地如何处理事件通知呢？它将根据事件类型把序列化数据翻译成本地限界上下文中的模型。在这个过程中，可能还会涉及到获取本地上下文中的聚合实例，然后根据事件信息在本地聚合实例上执行命令操作。当然，客户方必须按照顺序对事件进行处理，因为越老的事件越早发生。否则，在本地模型中有可能出现 bug。

In our implementation, the current log will have at most 19 notifications. It could have somewhat fewer than 19, even as few as zero. When the current log reaches 20 total notifications, it is automatically archived. If there are no new notifications available at the time the previous current log is archived, the new current log will be empty of notifications.

> 在我们的实现中，当前日志中最多包含 19 个事件通知。当当前日志中的事件达到 20 条之后，多余的将被自动地存档。如果在前一个日志存档之后不再有事件通知，那么新的当前日志将为空。

What’s an Archived Log All About? 存档日志到底是什么？

There’s nothing mysterious about an archived log. It just means that the specific log can no longer be altered by any action in the owning system, and clients are guaranteed that no matter how many times they ask for a particular archived log, it will always be the same.

> 存档日志没有什么神秘的。它只是表明：一个存档日志不能再被其所在的系统修改。同时，这也告诉客户方：无论他们请求多少次存档日志，所获得的数据都是相同的。

On the other hand, the current log will change up to the point where it becomes full and is finally archived. However, the only changes that can occur to the current log would be to add new notifications until it is full.

> 另一方面，对于当前日志来说，在事件通知的数量达到最大上限之前，都是可以修改的。当日志中的事件通知达到上限之后，当前日志将被存档。当然，修改当前日志的唯一方法便是向其中加入新的事件通知。

Events previously added to any log must never change. This is so because clients must have the guarantee that once they have applied a specific Event locally, it has been applied once and for all times.

> 在事件加入到日志中之后，该事件便不能再修改了，这主要是为了向客户方做出保证。

Thus, the current log may not always hold the newest or oldest notification that has yet to be applied locally. The oldest such Event may reside in the log previous to the current, or even the others before it. It’s all a matter of timing based on how frequently Events fill up a given finite log (in this case with just 20 entries) and how often clients pull for the logs. Figure 8.4 shows how notification logs chain together to provide a virtual array of individual notifications.

> 因此，当前日志中可能不会包含最新的或最老的事件通知。老的事件通知有可能存在于先前的存档日志中。这主要和日志的填充频率和客户方的请求频率有关。图 8.4 向我们展示了一个通知日志链。

Image

Figure 8.4. The current log and any number of linked archived logs form a virtual array of all Events from the most recent Event back to the very first Event. Here notifications 1 through 65 are depicted. Each of the archived logs contains the full 20-notification limit. The current log has not yet filled up and contains just five total notifications.

Assuming the log state depicted by Figure 8.4, let’s say that notifications 1 through 58 have already been applied locally. That means that notifications 59 through 65 have not yet been applied. If the client pulls the following URI, it will receive the current log:

> 在图 8.4 中，假设通知 1 到通知 58 已经被消费方处理过了，而通知 59 到通知 65 还未被处理过。当客户方通过 URI 发出请求时，他将收到当前日志：

//iam/notifications

The client reads from its own database a tracking record of the identity of the most recently applied notification, which in our example is 58. The onus is on the client, not the server, to track the next notification to apply. The client navigates from the top to the bottom through the current log in search of the notification with identity 58. It doesn’t find it there, so it continues to navigate back to the previous log, which is an archived log. The previous log is reached by use of a hypermedia link in the current log. One style is to allow hypermedia navigation to leverage a header:

> 在客户方的数据库中，保存了最近一次处理的通知号，在本例中即为 58。客户方应该知道需要处理的下一个通知号，而不是服务器端。客户方将从上到下依次遍历整个当前日志，以查找 58 号事件通知。它并没有找到该通知，于是再在先前的日志（即存档日志）中进行查找。先前日志通过超媒体链接的方式出现在当前日志中。使用超媒体链接的一种方式便是添加一个消息头：

```
HTTP/1.1 200 OK
Content-Type: application/vnd.saasovation.idovation+json
...
Link: <http://iam/notifications/61,80>; rel=self
Link: <http://iam/notifications/41,60>; rel=previous
...
```

Why Doesn’t the URI Reflect What’s Actually in the Current Log? URI 为什么没有反映出当前日志中实际包含的内容？

Note that although the current log presently has only notifications with identities 61 through 65, its URI is composed of the full identity range, 61 through 80, for example:

> 请注意，就本例来说，虽然当前日志中只包含了 61-65 号通知，但是 URI 依然包含了整个事件通知范围，即从 61 到 80，比如：

Link: <http://iam/notifications/61,80>; rel=self

That’s because the resource must remain stable over its entire lifetime. This allows for consistent access and for caching to work correctly.

> 这是因为，REST 资源必须在其整个生命周期中保持稳定性。这有助于资源访问的一致性，另外还有利于缓存的正常工作。

From the Link containing rel=previous, the URI is used for a GET, which retrieves the log previous to the current one:

> 对于包含了“rel=previous”的 Link 来说，该 URI 也用于 HTTP 的 GET 请求，它将获取当前日志的前一个存档日志：

//iam/notifications/41,60

Using this archived log, the client now finds the sought-after notification, the one with identity 58, after three probes on individual notifications (60, 59, then 58). Since this client has already applied that notification (identity 58), it does not apply notification 58 again. Instead, it now navigates in the other direction in search of all newer notifications. In this archived log it finds identity 59 and applies it. Then it finds 60 and applies it. It has now reached the top of this archived log, so it navigates to the rel=next resource, which is the current log:

> 通过该存档日志，客户方将找到与 58 号通知处于相同日志的事件通知（60、59、58）。由于客户方已经处理了 58 号通知，他将先找到并处理相同存档日志中的 59 号事件通知，然后是 60 号。此时，客户方已经处理完该存档日志中的所有事件通知。接下来，客户方将遍历“rel=next”资源，即当前日志：

```
HTTP/1.1 200 OK
Content-Type: application/vnd.saasovation.idovation+json
...
Link: <http://iam/notifications/61,80>; rel=next
Link: <http://iam/notifications/41,60>; rel=self
Link: <http://iam/notifications/21,40>; rel=previous
...
```

It finds in that log notifications with identities 61, 62, 63, 64, and 65, applying each in chronological order. It reaches the end of the current log and stops processing for now, because the current log never has a link header of rel=next.

> 客户方将从当前日志中找到第 61、62、63、64 和 65 号事件通知，然后依次进行处理。到此，客户方已经处理完当前日志中的所有事件通知，这时它将停止事件处理，因为在当前日志中不会出现“rel=next”链接消息头。

Sometime later the process repeats. The current log is requested by URI. Perhaps by now the activity in the source Bounded Context has caused the generation of significantly different logs by producing a number of new notifications. When the current log is now requested, it may have any number of new notifications. The client may have to navigate back one, two, or even more archived logs to find the most recently applied notification, which is presently the one with identity 65. As before, when the client finds notification 65, it will apply all newer ones in chronological order.

> 一段时间之后，客户方将重复该处理过程。此时如果再次请求当前日志，日志中有可能将出现一些新的事件通知。客户方可能需要向前查找，以找到最近一次处理过的事件通知，在本例中即为 65。和以前一样，当客户方找到 65 号通知之后，它将按顺序处理比 65 号通知更新的事件通知。

Any number of different client Bounded Contexts may request the notification logs. In fact, any Bounded Context that needs to know what Events have been produced by any other Bounded Context providing this kind of notification publisher may reach out to get the notifications as far back as the “beginning of time.” Of course, each client Bounded Context may actually be a client only if it has proper access to the source system (for example, security rights).

> 任何数量的客户限界上下文都可以请求通知日志。事实上，任何限界上下文都可能向发布事件的限界上下文发出请求，请求的内容甚至可以包括从最开始到现在所产生的所有事件通知。当然，客户方限界上下文需要足够的安全权限才能访问发布事件的限界上下文。

But won’t client polling of notification resources cause enormous amounts of unwanted traffic against your Web server? Not if your RESTful resources make effective use of caching. For example, the current log might be cached by the client itself for approximately one minute:

> 但是，这种“拉”的方式是否会使 Web 服务器处于超负荷状态呢？如果 REST 资源采用了有效的缓存机制，那么这便不是一个问题了。比如，客户方可以对当前日志进行缓存，缓存时长大约 1 分钟：

```
HTTP/1.1 200 OK
Content-Type: application/vnd.saasovation.idovation+json
...
Cache-Control: max-age=60
...
```

Every time the client polling precedes the one-minute caching, the client cache itself provides the previously retrieved current log. When the cache times out, the latest current log will be retrieved from the server resource. Archived logs may be cached longer since their contents never change, as demonstrated by this one-hour max-age:

> 在缓存时长之内，如果客户方再次发出请求，那么客户方的缓存将直接返回先前已经获取到的当前日志。当缓存过期时，客户方将再次从服务器端获取最新的当前日志。存档日志可以拥有更长的缓存时长，因为它们不会改变，比如：

```
HTTP/1.1 200 OK
Content-Type: application/vnd.saasovation.idovation+json
...
Cache-Control: max-age=3600
...
```

The client may use the current log max-age value as a timer/sleep threshold since it is unnecessary to perform GET requests continuously on cached resources. Sleep-induced decreased polling can benefit processing load on the client Bounded Context and on the source server. The resource provider will never receive the requests as long as the cache max-age has not expired. So an ill-behaved client can never hurt performance or availability of the notification producer, assuming the proper use of client caching. This highlights the benefits of using the Web and its built-in infrastructure to achieve tremendous performance and scalability benefits.

> 客户方可以将当前日志的 max-age 作为一个定时器使用，因为没有必要向缓存的资源发出 GET 请求。这种方式对于客户方和服务器端来说都是有益的。在缓存没有过期之前，服务器是不会收到来自客户方的请求的。因此，在适当采用缓存的情况下，客户方并不会对服务器的性能和可用性造成影响。这也显示出 Web 的好处——通过内建的缓存机制可以增强系统的性能和可伸缩性。

The server may also provide its own cache. Server caching of notification logs works really well because the contents of archived logs never change. Any client that requests a given archived notification log not only receives the resource, it also warms the cache for all other clients in need of the same resource. There is no need for the cache to refresh an archived log because the log is guaranteed immutable.

> 当然，服务器也可以提供缓存。对于事件通知日志来说，服务器缓存可以工作得很好，因为存档日志不会改变。客户方对存档日志的请求不止是可以获取到资源，同时，如果其他客户方再对相同的资源发出请求，服务器将直接返回缓存中的资源。此时的缓存不需要刷新存档日志，因为存档日志是不变的。

Wow! That was quite a bit of detail, and still more remains under Integrating Bounded Contexts (13). I suggest that you reference [Parastatidis et al., RiP] for various strategies on designing efficient RESTful Event notification systems. There you will find discussions on the advantages and disadvantages of the standard media type Atom-based notification logs, as well as a few reference implementations. Also, Jim Webber provides further insight on this approach in his presentation [Webber, REST & DDD]. One of the earliest references to this approach comes from Stefan Tilkov’s article on InfoQ [Tilkov, RESTful Doubts]. You can also watch my own presentation using this approach [Vernon, RESTful DDD].

> 好啦！以上已经够详细了，在集成限界上下文中（13）你将学到更多的细节知识。对于基于 REST 的事件通知，我建议读者参考一下[Parastatidis et al.，RiP]，其中包含了对基于 Atom 的通知日志的优缺点讨论，同时还有一些参考实现。此外，JimWebber 在他的演讲[Webber，REST & DDD]中提供了更详尽的讨论。StefanTilkov 在 InfoQ 上发表的文章[Tilkov，RESTful Doubts]是较早讨论 REST 事件通知的资料之一。你也可以参考我的演讲[Vernon，RESTful DDD]。

### 8.6.2 Publishing Notifications through Messaging Middleware 通过消息中间件发布事件通知

Not surprisingly, a messaging middleware product such as RabbitMQ manages details for you that the REST style forces you to deal with on your own. The messaging system also allows you to fairly easily support both Publish-Subscribe and Queues, whichever better fits your needs. In both cases the messaging system uses a push model to send messages of Event notifications to registered subscribers or listeners.

> 在采用 REST 发布事件通知时，我们需要自己处理很多细节，而在采用消息中间件时，比如 RabbitMQ，我们便不用去处理这些细节了，消息中间件将为我们处理。此外，消息系统同时支持发布-订阅的事件通知方式和消息队列方式。在这两种方式中，消息系统都是通过“推送”的方式来发送事件通知消息的。

Consider the requirements for publishing Events from our Event Store via a messaging middleware product. We are going to stick with Publish-Subscribe, using what RabbitMQ calls a fanout exchange. We will need a set of components that together do the following in order:

> 考虑一下将事件存储中的事件通过消息中间件发布出去的情形。我们将采用发布-订阅的方式，RabbitMQ 称为扇出交换器（Fanout Exchange）。我们需要一系列的组件依次完成以下操作：

1. Query all Domain Event objects from the Event Store that have not yet been published to the specific exchange. Order the queried objects in ascending order by their sequenced unique identity.
2. Iterate over the queried objects in ascending order, sending each to the exchange.
3. When the messaging system indicates that the message was successfully published, track that Domain Event as having been published through that exchange.

---

> 1. 对于某个扇出交换器来说，从事件存储中查找出所有还没有被发布的领域事件对象，再将这些对象按照唯一标识升序排列。
> 2. 依次遍历这些领域事件对象，并将它们发送给扇出交换器。
> 3. 当消息系统成功发布事件通知之后，在扇出交换器中对该领域事件进行跟踪。

We do not wait to see if subscribers confirm receipt. Subscriber systems may not even be running when the publisher sends messages through the exchange. Each subscriber is responsible for handling messages in its own time frame, ensuring that it properly carries out any necessary domain behavior on its own model. We simply allow the messaging mechanism to guarantee delivery.

> 我们不会等待订阅方的接收确认信号。当消息系统通过扇出交换器发布消息时，订阅系统有可能处于停机状态。每一个订阅系统都需要自己负责处理所接收到的消息，并保证其自身模型中的领域行为得到了正确的调用。对于消息系统来说，我们只是确保对消息的投递。

Whiteboard Time 白板时间

- Draw a Context Map of the Bounded Context you work on and the others you integrate with. Make sure you show connections between the Contexts that interact.
- Make notations of the kinds of relationships between them, such as Anticorruption Layer (3).
- Now indicate how you would integrate these Contexts. Would you use RPC, RESTful notifications, or a messaging infrastructure? Draw those in.

---

> - 为两个需要集成的限界上下文绘制一份上下文映射图，请确保该映射图能够显示出两个上下文之间的连接关系。
> - 标注出这两个上下文之间的集成关系，比如防腐层（3）。
> - 看看你将如何集成这两个限界上下文。你会使用 RPC、REST 事件通知还是消息设施？

Remember, you might not have much choice when integrating with a legacy system.

> 请记住，当与遗留系统集成时，我们的选择是非常少的。

## 8.7 IMPLEMENTATION 实现

Having decided on the architectural styles used for publishing Events, the SaaSOvation team is now focused on the implementation of components to accomplish that . . .

> 在决定了发布事件的架构风格之后，SaaSOvation 团队开始将重点转向实现上……

Image

The core of notification publishing behavior is placed behind an Application Service, the NotificationService. That allowed the team to manage the transactional scope of changes in their own data source. It also emphasized that notification is an application concern, not a domain concern, even though the Events being published as notifications originated in the model.

> 发布事件通知的核心行为位于应用服务 NotificationService 中。这样团队可以自己管理事务。此外，需要强调的是，事件通知是一个应用程序级别上的关注点，而不是领域的关注点，即便这些事件通知是源自于领域模型的也是如此。

There was no need for the NotificationService to have a Separated Interface [Fowler, P of EAA]. At this time there would be just one implementation of the Application Service, so the team would keep things simple. Still, every simple class has a public interface, so here it is presented as stubbed-out methods:

> 没有必要为 NotificationService 创建一个独立接口[Fowler，P of EAA]。此时，对事件通知的发布只有一个实现，因此 SaaSOvation 的团队成员们决定采用尽量简单的方式。另外，每一个简单的类都有一个公有的接口：

```java
package com.saasovation.identityaccess.application;
...
public class NotificationService {
    ...
    @Transactional(readOnly=true)
    public NotificationLog currentNotificationLog() {
        ...
    }

    @Transactional(readOnly=true)
    public NotificationLog notificationLog(String aNotificationLogId) {
        ...
    }

    @Transactional
    public void publishNotifications() {
        ...
    }
    ...
}
```

The first two methods will be used for querying NotificationLog instances that are provided to clients as RESTful resources, and the third will be used to publish individual Notification instances over a messaging mechanism. The team will first tackle the query methods for getting NotificationLog instances, then turn their attention to the one that interacts with the messaging infrastructure.

> 前两个方法用于查找 NotificationLog 实例，这些实例将以 REST 资源的方式提供给客户方。第三个方法将单个 Notification 实例通过消息机制发布出去。团队成员们首先将实现前两个查询方法，再实现第三个方法。

There are some interesting implementations ahead.

### 8.7.1 Publishing the NotificationLog 发布 NotificationLog

Recall that there are two kinds of notification logs, a current log and an archived log. Thus, the NotificationService interface provides a query method for each type:

> 回想一下，存在两种类型的通知日志——当前日志和存档日志。因此，NotificationService 为每种类型的日志都提供了查询方法：

```java
public class NotificationService {
    @Transactional(readOnly=true)
    public NotificationLog currentNotificationLog() {
        EventStore eventStore = EventStore.instance();
        return this.findNotificationLog(
                this.calculateCurrentNotificationLogId(eventStore),
                eventStore);
    }

    @Transactional(readOnly=true)
    public NotificationLog notificationLog(String aNotificationLogId) {
        EventStore eventStore = EventStore.instance();
        return this.findNotificationLog(
                new NotificationLogId(aNotificationLogId),
                eventStore);
    }
    ...
}
```

Ultimately both of these methods must “find” a NotificationLog. What that really means is finding a section of DomainEvent instances that have been serialized in the Event Store, encapsulating each one with a Notification, and collecting all those into a NotificationLog. Once a NotificationLog instance is created, it can be represented as a RESTful resource and provided to a requesting client.

> 两个方法都返回一个 NotificationLog 对象，它们首先从事件存储中找到一系列的 DomainEvent 实例，再将每个实例包装成 Notification，然后将不同的 Notification 组装到同一个 NotificationLog 中。当一个 NotificationLog 实例创建成功之后，它便可以通过 REST 资源的方式提供给客户方了。

Since the current log may be a constantly moving target, its identity must be calculated every time it is requested. Here’s the calculation:

> 由于当前日志可能一直处于改变状态，在每次请求时都需要重新计算日志标识。计算代码如下：

```java
public class NotificationService {
    ...
    protected NotificationLogId calculateCurrentNotificationLogId(
            EventStore anEventStore) {
        long count = anEventStore.countStoredEvents();
        long remainder = count % LOG_NOTIFICATION_COUNT;
        if (remainder == 0) {
            remainder = LOG_NOTIFICATION_COUNT;
        }
        long low = count - remainder + 1;

        // ensures a minted id value even though there may
        // not be a full set of notifications at present
        long high = low + LOG_NOTIFICATION_COUNT - 1;
        return new NotificationLogId(low, high);
    }
    ...
}
```

Otherwise, for an archived log all that is needed is a NotificationLogId to encapsulate the low and high range of the identifier. Remember that the identifier is encoded as a textual representation of a range between low and high values, such as 21–40. Thus, the constructor for an encoded identity looks like this:

> 另一方面，对于存档日志来说，我们只需要一个 NotificationLogId 用于表示通知的标识范围即可。回想一下，事件通知的标识是通过文本的方式来表示的，并且表示了一个范围，比如 21-40。因此，NotificationLogId 的构造函数可以通过以下方式实现：

```java
public class NotificationLogId {
    ...
    public NotificationLogId(String aNotificationLogId) {
        super();
        String[] textIds = aNotificationLogId.split(",");
        this.setLow(Long.parseLong(textIds[0]));
        this.setHigh(Long.parseLong(textIds[1]));
    }
    ...
}
```

Whether querying for the current log or an archived log, we now have a NotificationLogId that describes what method findNotificationLog() will query for:

> 无论是查询当前日志还是存档日志，我们现在都有了相应的 NotificationLogId，该 NotificationLogId 将用于 findNotificationLog（）方法：

```java
public class NotificationService {
    ...
    protected NotificationLog findNotificationLog(
            NotificationLogId aNotificationLogId,
            EventStore anEventStore) {
        List<StoredEvent> storedEvents =
            anEventStore.allStoredEventsBetween(
                    aNotificationLogId.low(),
                    aNotificationLogId.high());
        long count = anEventStore.countStoredEvents();
        boolean archivedIndicator = aNotificationLogId.high() < count;
        NotificationLog notificationLog =
            new NotificationLog(
                    aNotificationLogId.encoded(),
                    NotificationLogId.encoded(
                            aNotificationLogId.next(
                                    LOG_NOTIFICATION_COUNT)),
                    NotificationLogId.encoded(
                            aNotificationLogId.previous(
                                    LOG_NOTIFICATION_COUNT)),
                    this.notificationsFrom(storedEvents),
                    archivedIndicator);
        return notificationLog;
    }
    ...

    protected List<Notification> notificationsFrom(
            List<StoredEvent> aStoredEvents) {
        List<Notification> notifications =
            new ArrayList<Notification>(aStoredEvents.size());
        for (StoredEvent storedEvent : aStoredEvents) {
            DomainEvent domainEvent =
                    EventStore.toDomainEvent(storedEvent);
            Notification notification =
                new Notification(
                        domainEvent.getClass().getSimpleName(),
                        storedEvent.eventId(),
                        domainEvent.occurredOn(),
                        domainEvent);
            notifications.add(notification);
        }
        return notifications;
    }
    ...
}
```

It’s quite interesting that there is no need to actually persist any Notification instances or whole logs. We can just manufacture them each time they are needed. Obviously, for that reason, it helps with performance and scalability to cache NotificationLog resources at the points of request.

> 有趣的是，这里我们没有必要持久化 Notification 或者整个日志，而是在每次需要的时候新建这些对象实例。这样带来的好处是显然的，即我们可以在请求时对 NotificationLog 进行缓存，从而有助于提高系统的性能和可伸缩性。

Method findNotificationLog() uses the EventStore component to query the StoredEvent instances it needs for a given log. Here’s how the EventStore finds them:

> 上面的 findNotificationLog（）方法使用 EventStore 组件来查询 StoredEvent 实例，下面的代码展示了 EventStore 对 StoredEvent 的查找：

```java
package com.saasovation.identityaccess.application.eventStore;
...
public class EventStore ... {
    ...
    public List<StoredEvent> allStoredEventsBetween(
            long aLowStoredEventId,
            long aHighStoredEventId) {
        Query query =
            this.session().createQuery(
                    "from StoredEvent as _obj_ "
                    + "where _obj_.eventId between ? and ? "
                    + "order by _obj_.eventId");
        query.setParameter(0, aLowStoredEventId);
        query.setParameter(1, aHighStoredEventId);
        List<StoredEvent> storedEvents = query.list();
        return storedEvents;
    }
    ...
}
```

Finally, at the Web tier we publish the current log and archived logs:

> 最后，在 Web 层，我们发布当前日志和存档日志：

```java
@Path("/notifications")
public class NotificationResource {
    ...
    @GET
    @Produces({ OvationsMediaType.NAME })
    public Response getCurrentNotificationLog(
            @Context UriInfo aUriInfo) {
        NotificationLog currentNotificationLog =
            this.notificationService()
                .currentNotificationLog();
        if (currentNotificationLog == null) {
            throw new WebApplicationException(
                    Response.Status.NOT_FOUND);
        }
        Response response =
            this.currentNotificationLogResponse(
                    currentNotificationLog,
                    aUriInfo);
        return response;
    }

    @GET
    @Path("{notificationId}")
    @Produces({ OvationsMediaType.ID_OVATION_NAME })
    public Response getNotificationLog(
            @PathParam("notificationId") String aNotificationId,
            @Context UriInfo aUriInfo) {
        NotificationLog notificationLog =
            this.notificationService()
                .notificationLog(aNotificationId);
        if (notificationLog == null) {
            throw new WebApplicationException(
                    Response.Status.NOT_FOUND);
        }
        Response response =
            this.notificationLogResponse(
                    notificationLog,
                    aUriInfo);
        return response;
    }
    ...
}
```

The team could have used a MessageBodyWriter to generate the response, but there are some necessary minor complexities that are managed in response builder methods.

> 当然，我们也可以使用 MessageBodyWriter 来生成返回结果，但是这种方法会稍微复杂一些。

That covers the important bits used to publish both current and archived notification logs to RESTful clients.

> 以上我们便讨论了以 REST 资源的方式发布当前日志和存档日志。

### 8.7.2 Publishing Message-Based Notifications 发布基于消息的事件通知

The NotificationService provides a single method for publishing DomainEvent instances over a messaging infrastructure. Here is the service method:

> NotificationService 提供一个单一的方法来通过消息设施发布 DomainEvent：

```java
public class NotificationService {
    ...
    @Transactional
    public void publishNotifications() {
        PublishedMessageTracker publishedMessageTracker =
            this.publishedMessageTracker();
        List<Notification> notifications =
            this.listUnpublishedNotifications(
                    publishedMessageTracker
                            .mostRecentPublishedMessageId());
        MessageProducer messageProducer = this.messageProducer();
        try {
            for (Notification notification : notifications) {
                this.publish(notification, messageProducer);
            }
            this.trackMostRecentPublishedMessage(
                    publishedMessageTracker,
                    notifications);
        } finally {
            messageProducer.close();
        }
    }
    ...
}
```

Method publishNotifications() first gets its PublishedMessage-Tracker. This is the object that persists the record of which Events have already been published:

> 上面的 publishNotification（）方法首先获取到一个 PublishedMessageTracker 对象。该对象的作用是持久化已经被发布的事件：

```java
package com.saasovation.identityaccess.application.notifications;
...
public class PublishedMessageTracker {
    private long mostRecentPublishedMessageId;
    private long trackerId;
    private String type;
    ...
}
```

Note that this class is not part of the domain model but rather belongs to the application. The trackerId is just this object’s unique identity (essentially an Entity). The type attribute holds the String description of the type of topic/channel that the Events were published on. The attribute mostRecentPublishedMessageId corresponds to the unique identity of the individual DomainEvent that was serialized and persisted as a StoreEvent. Thus, it holds the value of the StoredEvent eventId of the most recently published instance. After all new Notification messages have been sent, the service method ensures that the PublishedMessageTracker is saved with the identity of the now most recently published Event.

> 请注意，PublishedMessageTracker 并不属于领域模型，而是属于应用程序。该对象拥有一个唯一标识 trackerId。属性 type 描述了事件所要发布到的话题/通道（topic/channel）。而 mostRecentPublishedMessageId 则表示了所发布 DomainEvent 的唯一标识，该 DomainEvent 将被序列化成 StoredEvent，然后再进行持久化。因此，它维护了最近发布的事件实例的 eventId。在所有的 Notification 消息发送完毕之后，publishNotifications（）方法将保存 PublishedMessageTracker，其中含有最近发布事件的唯一标识。

The Event identity along with the type attribute allows us to publish the same notifications at different times to any number of topics/channels. We just create a new instance of the PublishedMessageTracker with the name of the topic/channel as its type and start again with the first StoredEvent. In fact, here’s how method publishedMessageTracker() does it:

> 事件标识 eventId 和 type 属性使得我们可以在不同时间将同一个事件通知发布到任意数量的话题/通道中。我们只需要创建一个新的 PublishedMessageTracker，其中的 type 属性表示了话题/通道的名称，然后从第一个 StoredEvent 开始发布。以下是 publishedMessageTracker（）方法：

```java
public class NotificationService {
    private static final String EXCHANGE_NAME =
            "saasovation.identity_access";
    ...
    private PublishedMessageTracker publishedMessageTracker() {
        Query query =
            this.session().createQuery(
                    "from PublishedMessageTracker as _obj_ "
                    + "where _obj_.type = ?");
        query.setParameter(0, EXCHANGE_NAME);
        PublishedMessageTracker publishedMessageTracker =
            (PublishedMessageTracker) query.uniqueResult();
        if (publishedMessageTracker == null) {
            publishedMessageTracker =
                new PublishedMessageTracker(EXCHANGE_NAME);
        }
        return publishedMessageTracker;
    }
    ...
}
```

Multichannel publishing is not yet supported, but it could be added easily with a little refactoring.

> 当前的实现并不支持多通道（Multichannel），但是通过简单的重构，我们便可以达到支持多通道的目的。

Next, method listUnpublishedNotifications() is responsible for querying a sorted list of all unpublished Notification instances:

> 接下来，listUnpublishedNotification（）方法用于查询所有尚未被发布的 Notification 实例：

```java
public class NotificationService {
    ...
    protected List<Notification> listUnpublishedNotifications(
            long aMostRecentPublishedMessageId) {
        EventStore eventStore = EventStore.instance();
        List<StoredEvent> storedEvents =
                eventStore.allStoredEventsSince(
                        aMostRecentPublishedMessageId);
        List<Notification> notifications =
            this.notificationsFrom(storedEvents);
        return notifications;
    }
    ...
}
```

In reality it’s querying the EventStore for StoredEvent instances with eventId values greater than the one held by parameter aMostRecentPublishedMessageId. Those returned from the EventStore are used to create a new collection of Notification instances.

> 在现实情况下，该方法将返回那些 eventId 大于 aMostRecentPublishedMessageId 的 StoredEvent，返回结果将用于创建一个新的 Notification 实例集合。

Now, back to the main service method publishNotifications(). With the collection of DomainEvent wrapper Notification instances, it iterates and dispatches to method publish():

> 现在，我们回到主要的 publishNotifications（）方法。对于封装了 DomainEvent 的 Notification 实例集合来说，publishNotifications（）方法将遍历该集合，然后分别调用 publish（）方法来逐一发布 Notification：

```java
...
for (Notification notification : notifications) {
    this.publish(notification, messageProducer);
}
```

This method that publishes individual Notification instances does so through RabbitMQ, but using a very simple object library to make its interface seem more object-oriented:

> 该方法通过 RabbitMQ 来发布单个 Notification 实例，但是它使用了一个简单的类库使其接口更加具有面向对象的特征：

```java
public class NotificationService {
    ...
    protected void publish(
            Notification aNotification,
            MessageProducer aMessageProducer) {
        MessageParameters messageParameters =
            MessageParameters.durableTextParameters(
                    aNotification.type(),
                    Long.toString(aNotification.notificationId()),
                    aNotification.occurredOn());
        String notification =
            NotificationService
                .objectSerializer()
                .serialize(aNotification);
        aMessageProducer.send(notification, messageParameters);
    }
    ...
}
```

This publish() method creates MessageParameters and then sends the JSON serialized DomainEvent by way of a MessageProducer.3 The MessageParameters include select properties to send along with the message body. Among these special parameters are the Event type string, the notification identity used as a unique message ID, and the occurredOn timestamp of the Event. These parameters allow subscribers to determine important facts about each message without the need to parse the JSON message body, which is the serialized Event. And the unique message ID (notification identity) supports message de-duplication, which is explained later.

> 这里的 publish（）方法首先创建一个 MessageParameters 实例，然后将 JSON 格式的 DomainEvent 通过 MessageProducer[3]发送出去。MessageParameters 包含了一些需要和消息体一起发送的参数值，其中包含了事件的 type 属性、消息 ID 和领域事件的时间戳 occuredOn。这些参数使得订阅方可以在不解析 JSON 消息体的情况下获取到该事件通知的一些重要信息。这里的消息 ID 为消息消重提供了支持，对此我们将在本章后面进行讨论。

3. Classes Exchange, ConnectionSettings, MessageProducer, Message-Parameters, and others are part of a library that serves as an abstraction layer around RabbitMQ. I provide this library, which makes using RabbitMQ much more object friendly, along with the other sample code for the book.

Consider one more method used to fully implement publishing:

> 再考虑以下用于消息发布的方法：

```java
public class NotificationService {
    ...
    private MessageProducer messageProducer() {
        // create my exchange if nonexistent
        Exchange exchange =
            Exchange.fanOutInstance(
                    ConnectionSettings.instance(),
                    EXCHANGE_NAME,
                    true);
        // create a message producer used to forward Events
        MessageProducer messageProducer =
            MessageProducer.instance(exchange);
        return messageProducer;
    }
    ...
}
```

Method publishNotifications() uses messageProducer() to ensure that the exchange exists and then gets the instance of MessageProducer used to publish. RabbitMQ supports exchange idempotence, so the first time you ask for the exchange it is created, and all subsequent times you are given the preexisting one. We don’t retain an open instance of the Message-Producer in case a problem with the backing broker channel somehow develops. Reestablishing the connection each time publish is executed helps prevent a completely inoperable publisher. We may need to look out for possible performance issues if constant reconnection becomes a bottleneck. But for now we will count on the configured pauses between publish operations to alleviate reconnection overhead.

> 上面的 messageProducer（）被 publishNotifications（）方法所调用，它的作用在于确保扇出交换器是存在的，并且获取一个用于发布消息的 MessageProducer 实例。RabbitMQ 支持扇出交换器的幂等性，即在第一次使用扇出交换器时，RabbitMQ 将为我们创建一个新的扇出交换器，后续使用时我们将使用先前创建的那个扇出交换器。我们并不会保留处于打开状态的 MessageProducer 实例，而是在每次发布时重新创建一个连接，这样可以避免整体性的发布失败。当然，如果不断地重复连接造成了性能上的瓶颈，那么我们就得注意了。但是，就现在而言，我们可以依赖于两次发布操作之间的暂停时间来解决由不断连接所导致的问题。

Speaking of pauses between publish operations, none of the preceding code indicates how Events are published to the exchange on a regular, recurring basis. That can be accomplished in a few different ways and may depend on your operational environment. For one, a JMX TimerMBean can be used to manage recurring time intervals.

> 说到发布操作之间的暂停时间，在以上代码中我们并没有看到这是如何实现的。有几种不同的方式都可以实现这样的功能，比如，可以使用一个 JMX 的 TimerMBean。

Before presenting the following timer solution, it’s important to note an important context. The Java MBean standard also uses the term notification, but this is not the same used by our own publishing process. In this case, a listener receives notification of each occurrence of the timer firing. Just be prepared to sort that out in your mind.

> 在展示定时功能之前，有一点我们需要注意。Java 的 MBean 标准也使用了“通知”一词，但是这和我们发布领域事件时所用到的“通知”是不同的。在 Java 的 MBean 中，在每次定时事件发生时，一个监听器都将得到通知。对于这两种不同的“通知”，读者要心中有数。

Whatever suitable interval is determined and configured for a given timer, a NotificationListener is registered so the MBeanServer can notify on each occasion when an interval is reached:

> 在设定好定时器的时间间隔之后，我们向 M BeanServer 注册一个 NotificationListener：

```java
mbeanServer.addNotificationListener(
        timer.getObjectName(),
        new NotificationListener() {
            public void handleNotification(
                    Notification aTimerNotification,
                    Object aHandback) {
                ApplicationServiceRegistry
                        .notificationService()
                        .publishNotifications();
            }
        },
        null,
        null);
```

In this example, when method handleNotification() is invoked due to the timer firing, it requests the NotificationService to perform its publishNotifications() operation. That’s all that’s necessary. For as long as the TimerMBean continues to fire at regular, recurring intervals, Domain Events will continue to be published through the exchange and consumed by subscribers across the enterprise.

> 在上例中，handleNotification（）方法将调用 NotificationService 上的 publishNotifications（）方法。只要 TimerMBean 不断地触发，那么领域事件便会不断地通过扇出交换器发布出去。

Using an application-server-managed timer has the added advantage that you don’t have to create a component to monitor the life cycle of your publishing process. If, for example, the publishNotifications() should for some reason on any given execution encounter problems and terminate with an exception, the TimerMBean would continue to run and fire on subsequent intervals. Administrators may need to address infrastructure errors, perhaps with RabbitMQ, but once problems are out of the way, messages would continue to be published. That said, there are other timer facilities available, such as [Quartz].

> 使用由应用服务器所管理的定时器还有额外的好处：我们不用单独创建一个组件来监视事件发布的整个过程。比如，如果 publishNotifications（）方法的某次执行由于种种原因而失败，TimerMBean 依然会继续运行，然后在定时间隔到达时重新触发 publishNotifications（）方法。系统管理员会照看那些由基础设施（比如 RabbitMQ）导致的错误，一旦问题解除，消息将得以继续发送。除了以上提到的 TimberMBean 之外，还有其他的定时工具，比如[Quartz]。

But we are still left with questions about message de-duplication. What is message de-duplication? And why is it necessary for messaging subscribers to support it?

> 到现在为止，我们依然没有处理消息消重的问题。什么是消息消重？消息订阅方为什么需要支持消息消重？

Event De-duplication 事件消重

De-duplication is a necessity in environments where a single message published through a messaging system could possibly be delivered to subscribers more than once. There are various causes of duplicate messages. One way this can happen is the following:

> 在有些环境中，消息系统可能多次向订阅方发送消息，在这种情况下，我们便需要对事件进行消重。有多种原因可能导致消息的重复发送。其中一种是：

1. RabbitMQ delivers the newly sent messages to one or more subscribers.
2. The subscribers process the messages.
3. Before subscribers can acknowledge that the messages were received and processed, they fail.
4. RabbitMQ delivers the unacknowledged messages again.

---

> 1. RabbitMQ 将一条新建的消息发送到一个或多个订阅方。
> 2. 订阅方处理该消息。
> 3. 在订阅方发回确认信号之前，订阅方失败。
> 4. RabbitMQ 重新发送消息。

The possibility also exists when publishing out of an Event Store, and the messaging system doesn’t share the Event Store’s persistence mechanism, and global, XA transactions are not controlling atomic commits of Event Store and messaging persistence changes. As discussed earlier under “Publishing Notifications through Messaging Middleware,” that is exactly our situation. Consider a scenario that highlights how a message could be sent more than once:

> 另一可能便是：当从事件存储中发送消息时，消息系统并不与事件存储共享持久化机制，而全局的 XA 事务又没有控制事件存储和消息系统之间的原子提交。本章前面的“通过消息中间件发布事件通知”一节便是这种情形。以下描述了重复发送消息的情形：

1. The NotificationService queries and publishes three unpublished Notification instances. It updates the record of this with PublishedMessageTracker.
2. The RabbitMQ broker receives all three messages and prepares to send them to all subscribers.
3. However, due to some exceptional condition on the application server, there is a failure of the NotificationService. The modification to the PublishedMessageTracker is not committed.
4. RabbitMQ delivers the newly sent messages to subscribers.
5. The exceptional condition on the application server is corrected. The process of publishing begins again and the NotificationService successfully sends messages for all unpublished Events. This includes sending (again!) messages for all Events that were previously published but unknown to the PublishedMessageTracker.
6. RabbitMQ delivers the newly sent messages to subscribers, at least three of which are duplicate deliveries.

---

> 1. NotificationService 查找并发布 3 个先前未被发布的 Notification 实例，然后通过 PublishedMessageTracker 更新发送记录。
> 2. RabbitMQ 接收到所有 3 条消息，并准备将它们发送给订阅方。
> 3. 但是，应用服务器出现故障，NotificationServcie 出现问题，造成对 PublishedMessageTracker 的修改并未得到提交。
> 4. RabbitMQ 将消息发送给订阅方。
> 5. 应用服务器的故障解除，消息发布过程重新启动，NotificationService 继续发送未发布的事件，其中也包括那 3 条未被 PublishedMessageTracker 记录的事件。
> 6. RabbitMQ 将所接收到的事件发送给订阅方，于是先前那 3 条消息便出现了重复。

In this scenario I arbitrarily use three Events. I could have used one, two, four, or many more. The number is not significant, only the fact that problems like these could cause redelivery. When you face this and other reasons for message duplication, de-duplication is necessary. See Idempotent Receiver [Hohpe & Woolf] for more elaborate treatment.

> 在以上场景中，我随机性地使用了 3 个事件，当然我们也可以使用 1 条、2 条或者更多数量的消息。这里的重复消息的数量并不多，重点是为了向大家展示对消息的重复投递是有可能发生的。当由于种种原因而导致消息重复时，对消息的消重便是有必要的了，对此，请参考幂等接收器[Hohpe & Woolf]。

An Idempotent Operation 幂等操作

An idempotent operation is one that can be executed two or more times in succession with results identical to those of executing the same operation only once.

> 幂等操作即进行多次重复操作和只进行一次操作所产生的结果相同。

One way to deal with the possibility of duplicate message delivery is for subscriber model operation to be idempotent. The subscriber’s response to all messages could be idempotent operations against its own domain model. The problem is that designing a domain object, or any object for that matter, to be idempotent can be difficult, impractical, or even impossible. And if we attempt to design the Event itself to carry information that reflects an idempotent action to be taken, that can also be troublesome. For one, the sender must fully understand the current business situation of all receivers relative to the Event state they will send. Further, receipt of Events that are out of sequence due to latency, retries, and so on could cause errors.

> 处理重复消息的一种方式便是将订阅方的处理过程变成幂等操作过程。订阅方对消息的处理对于其自己的领域模型来说应该是幂等的。设计幂等领域对象的问题在于：太困难、太不实用、甚至是不可能的。另外，如果我们试图将事件本身设计成幂等操作，这也会给我们带来很多麻烦。首先，消息的发送方必须完全了解所有消息接收方的业务场景，其次，如果接收方由于延迟、重试等原因而导致了错误的消息接收顺序，那么这也将带来问题。

When domain object idempotence is not a viable option, you can instead design the subscriber/receiver itself to be idempotent. The receiver can be designed to refuse to execute an operation in response to a duplicate message. First, you should check to see if your messaging product supports this as a feature. If not, your receiver will need to track which messages have already been handled. One way to accomplish that is to allocate an area in the subscriber’s persistence mechanism to save the name of the topic/exchange along with the unique message ID of all handled messages—yes, similar to a PublishedMessageTracker. Then you can query for duplicates before handling each message. If the query finds that a message was already handled, the subscriber simply ignores it. The handled message tracking is not part of the domain model. It should be viewed only as a technical work-around for common messaging idiosyncrasies.

> 当领域对象无法满足幂等操作的要求时，我们可以转而将订阅方/接收方设计成幂等的。比如，消息接收方在接收到重复的消息时可以拒绝处理。首先，我们必须确认所使用的消息系统是否支持这样的功能。如果不是，接收方必须自己跟踪哪些消息已经被处理过了。一种方式便是在订阅方的持久化机制中保存消息的话题/交换器名称和一个唯一的消息 ID——就像 PublishedMessageTracker 所采用的方式一样。然后，在处理消息之前，我们首先对已经处理的消息进行查询。如果发现所接收到的消息已经被处理过，那么订阅方可以简单地将其忽略掉。对消息的跟踪并不是领域模型的一部分，而只是一个技术上的解决方案。

When using a typical messaging middleware product, it is not enough to save only a record of the latest handled message because messages can be received out of order. Thus, a de-duplication query that checks for message IDs less than the most recent one would cause you to ignore some messages that were received out of order. Also to be considered is that sometimes you will want to discard all handled message tracking entries that are obsolete, as in database garbage collection.

> 在使用常用的消息中间件产品时，只保存最近处理的消息是不够的，因为消息的到达可能是无序的。因此，如果一个消重查询在检查那些 ID 小于最近一次所处理消息的 ID 的消息时，它有可能忽略掉一部分消息。另外，我们需要考虑的是，有时我们可能会忽略掉那些已经处理过的并且过期的消息，比如那些位于数据库垃圾回收过程中的消息。

When using the REST-based notification approach, de-duplication is not really a factor. Client receivers need to save only the most recently applied notification identity since they will always be applying only the notifications of events that occurred after it. Each notification log will always be in reverse chronological order (descending) by notification identity.

> 在使用基于 REST 的事件通知时，消重并不是一个多大的问题。接收方只需要保存最近处理的消息通知标识，因为此时的接收方只会处理那些发生在最近处理消息之后的消息。每一个通知日志中的消息顺序和通知标识顺序是相反的。

In both cases—messaging middleware subscribers and REST-based notification clients—it is important that the tracking of handled message identity be committed along with any changes to the local domain model state. Otherwise, you will be unable to maintain tracking consistency in conjunction with the modifications made in response to Events.

> 在两种情况下——消息中间件订阅方和基于 REST 的消息客户方——我们都应该保证：对跟踪信息的修改和本地模型状态的修改必须一同提交。否则，对模型的修改和对跟踪信息的修改将无法达到一致。

Image

## 8.8 WRAP-UP 本章小结

In this chapter we looked at the definition of Domain Events and how they determine when modeling an Event would be to your advantage.

> 在本章中，我们学习了领域事件的定义，以及何时应该采用领域事件。

- You’ve learned what Domain Events are, and when and why to use them.
- You looked into how Events are modeled as objects, and when they must be uniquely identified.
- You considered when an Event should have Aggregate characteristics, and when a simple Value-based Event works best.
- You saw how lightweight Publish-Subscribe components are used in the model.
- You discovered which components publish Events and which ones subscribe to them.
- You grasped why you’d want to develop an Event Store, how it can be done, and how one is used.
- You learned about two approaches to Event publishing outside the Bounded Context: REST-based notifications and the use of messaging middleware.
- You learned some ways to de-duplicate messages in subscribing systems.

---

> - 你学到了什么是领域事件，什么时候并且为什么要使用领域事件。
> - 你学到了如何将领域事件建模成对象，何时应该为领域事件创建唯一标识。
> - 你学到了什么时候一个领域事件应该具有聚合特征，以及何时应该使用基于值对象的领域事件。
> - 你学到了在模型中如何使用轻量级的发布-订阅组件。
> - 你学到了哪些组件用于发布消息，哪些组件用于订阅消息。
> - 你学到了为什么需要一个事件存储，如何实现并使用事件存储。
> - 你学到了将领域事件发布到外部限界上下文的两种方式：基于 REST 的消息通知和消息中间件的方式。
> - 你学到了如何在订阅系统中对消息进行消重处理。

Next, we are going to change directions quite a bit and look into how domain model objects can be well organized by using Modules.

接下来，我们将转移学习方向，我们将在下一章中学习如何将领域对象组织在模块中。
